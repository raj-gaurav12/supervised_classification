2023-04-03 18:23:19,726:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-03 18:23:19,726:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-03 18:23:19,726:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-03 18:23:19,726:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-03 18:23:20,271:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-03 18:25:23,021:INFO:PyCaret ClassificationExperiment
2023-04-03 18:25:23,021:INFO:Logging name: clf-default-name
2023-04-03 18:25:23,021:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-03 18:25:23,021:INFO:version 3.0.0
2023-04-03 18:25:23,021:INFO:Initializing setup()
2023-04-03 18:25:23,022:INFO:self.USI: 3180
2023-04-03 18:25:23,022:INFO:self._variable_keys: {'html_param', 'fix_imbalance', 'y', '_available_plots', 'y_test', 'exp_name_log', 'X_train', '_ml_usecase', 'logging_param', 'n_jobs_param', 'exp_id', 'pipeline', 'gpu_n_jobs_param', 'target_param', 'memory', 'X', 'seed', 'gpu_param', 'fold_groups_param', 'USI', 'X_test', 'log_plots_param', 'fold_shuffle_param', 'data', 'is_multiclass', 'fold_generator', 'y_train', 'idx'}
2023-04-03 18:25:23,022:INFO:Checking environment
2023-04-03 18:25:23,022:INFO:python_version: 3.9.13
2023-04-03 18:25:23,022:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-04-03 18:25:23,022:INFO:machine: x86_64
2023-04-03 18:25:23,022:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-04-03 18:25:23,022:INFO:Memory: svmem(total=17179869184, available=1159335936, percent=93.3, used=1932509184, free=28717056, active=1132048384, inactive=1129967616, wired=800460800)
2023-04-03 18:25:23,022:INFO:Physical Core: 10
2023-04-03 18:25:23,022:INFO:Logical Core: 10
2023-04-03 18:25:23,022:INFO:Checking libraries
2023-04-03 18:25:23,022:INFO:System:
2023-04-03 18:25:23,022:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-04-03 18:25:23,022:INFO:executable: /opt/anaconda3/bin/python
2023-04-03 18:25:23,022:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-04-03 18:25:23,022:INFO:PyCaret required dependencies:
2023-04-03 18:25:23,022:INFO:                 pip: 22.2.2
2023-04-03 18:25:23,022:INFO:          setuptools: 63.4.1
2023-04-03 18:25:23,022:INFO:             pycaret: 3.0.0
2023-04-03 18:25:23,022:INFO:             IPython: 7.31.1
2023-04-03 18:25:23,022:INFO:          ipywidgets: 7.6.5
2023-04-03 18:25:23,022:INFO:                tqdm: 4.64.1
2023-04-03 18:25:23,022:INFO:               numpy: 1.21.5
2023-04-03 18:25:23,022:INFO:              pandas: 1.4.4
2023-04-03 18:25:23,022:INFO:              jinja2: 2.11.3
2023-04-03 18:25:23,022:INFO:               scipy: 1.9.1
2023-04-03 18:25:23,023:INFO:              joblib: 1.2.0
2023-04-03 18:25:23,023:INFO:             sklearn: 1.0.2
2023-04-03 18:25:23,023:INFO:                pyod: 1.0.9
2023-04-03 18:25:23,023:INFO:            imblearn: 0.10.1
2023-04-03 18:25:23,023:INFO:   category_encoders: 2.6.0
2023-04-03 18:25:23,023:INFO:            lightgbm: 3.3.5
2023-04-03 18:25:23,023:INFO:               numba: 0.55.1
2023-04-03 18:25:23,023:INFO:            requests: 2.28.1
2023-04-03 18:25:23,023:INFO:          matplotlib: 3.5.2
2023-04-03 18:25:23,023:INFO:          scikitplot: 0.3.7
2023-04-03 18:25:23,023:INFO:         yellowbrick: 1.5
2023-04-03 18:25:23,023:INFO:              plotly: 5.9.0
2023-04-03 18:25:23,023:INFO:             kaleido: 0.2.1
2023-04-03 18:25:23,023:INFO:         statsmodels: 0.13.2
2023-04-03 18:25:23,023:INFO:              sktime: 0.16.1
2023-04-03 18:25:23,023:INFO:               tbats: 1.1.2
2023-04-03 18:25:23,023:INFO:            pmdarima: 2.0.3
2023-04-03 18:25:23,023:INFO:              psutil: 5.9.0
2023-04-03 18:25:23,023:INFO:PyCaret optional dependencies:
2023-04-03 18:25:23,039:INFO:                shap: Not installed
2023-04-03 18:25:23,039:INFO:           interpret: Not installed
2023-04-03 18:25:23,039:INFO:                umap: Not installed
2023-04-03 18:25:23,039:INFO:    pandas_profiling: Not installed
2023-04-03 18:25:23,039:INFO:  explainerdashboard: Not installed
2023-04-03 18:25:23,039:INFO:             autoviz: Not installed
2023-04-03 18:25:23,039:INFO:           fairlearn: Not installed
2023-04-03 18:25:23,039:INFO:             xgboost: Not installed
2023-04-03 18:25:23,039:INFO:            catboost: Not installed
2023-04-03 18:25:23,040:INFO:              kmodes: Not installed
2023-04-03 18:25:23,040:INFO:             mlxtend: Not installed
2023-04-03 18:25:23,040:INFO:       statsforecast: Not installed
2023-04-03 18:25:23,040:INFO:        tune_sklearn: Not installed
2023-04-03 18:25:23,040:INFO:                 ray: Not installed
2023-04-03 18:25:23,040:INFO:            hyperopt: Not installed
2023-04-03 18:25:23,040:INFO:              optuna: Not installed
2023-04-03 18:25:23,040:INFO:               skopt: Not installed
2023-04-03 18:25:23,040:INFO:              mlflow: Not installed
2023-04-03 18:25:23,040:INFO:              gradio: Not installed
2023-04-03 18:25:23,040:INFO:             fastapi: Not installed
2023-04-03 18:25:23,040:INFO:             uvicorn: Not installed
2023-04-03 18:25:23,040:INFO:              m2cgen: Not installed
2023-04-03 18:25:23,040:INFO:           evidently: Not installed
2023-04-03 18:25:23,040:INFO:               fugue: Not installed
2023-04-03 18:25:23,040:INFO:           streamlit: Not installed
2023-04-03 18:25:23,040:INFO:             prophet: Not installed
2023-04-03 18:25:23,040:INFO:None
2023-04-03 18:25:23,040:INFO:Set up data.
2023-04-03 18:25:24,780:INFO:Set up train/test split.
2023-04-03 18:25:25,517:INFO:Set up index.
2023-04-03 18:25:25,536:INFO:Set up folding strategy.
2023-04-03 18:25:25,536:INFO:Assigning column types.
2023-04-03 18:25:26,335:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-03 18:25:26,367:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-03 18:25:26,370:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-03 18:25:26,394:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:25:26,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:25:26,447:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-03 18:25:26,447:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-03 18:25:26,467:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:25:26,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:25:26,468:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-03 18:25:26,500:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-03 18:25:26,519:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:25:26,519:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:25:26,551:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-03 18:25:26,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:25:26,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:25:26,571:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-03 18:25:26,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:25:26,624:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:25:26,678:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:25:26,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:25:26,681:INFO:Preparing preprocessing pipeline...
2023-04-03 18:25:26,765:INFO:Set up simple imputation.
2023-04-03 18:25:26,997:INFO:Set up encoding of categorical features.
2023-04-03 18:25:27,004:INFO:Set up removing outliers.
2023-04-03 18:25:27,004:INFO:Set up imbalanced handling.
2023-04-03 18:25:27,004:INFO:Set up feature normalization.
2023-04-03 18:25:53,513:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 18:26:41,665:INFO:Finished creating preprocessing pipeline.
2023-04-03 18:26:41,671:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['hour_of_day',
                                             'avg_last_rrc_measurement_earfcn',
                                             'num_distinct_imsi',
                                             'mute_call_gap_indicator',
                                             'num_mute_calls', 'avg_cqi',
                                             'min_cqi', 'max_cqi', 'p05_cqi',
                                             'p10_cqi', 'p50_cqi', 'p90_cqi',
                                             'p95_cq...
                                                               n_jobs=1,
                                                               random_state=1436,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2023-04-03 18:26:41,671:INFO:Creating final display dataframe.
2023-04-03 18:27:05,280:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 18:27:57,535:INFO:Setup _display_container:                     Description             Value
0                    Session id              1436
1                        Target   Target_Variable
2                   Target type            Binary
3           Original data shape     (343124, 217)
4        Transformed data shape     (301110, 211)
5   Transformed train set shape     (198172, 211)
6    Transformed test set shape     (102938, 211)
7               Ignore features                 8
8              Numeric features               207
9          Categorical features                 1
10     Rows with missing values              0.0%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold               0.5
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            minmax
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              3180
2023-04-03 18:27:57,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:27:57,603:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:27:57,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:27:57,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:27:57,659:INFO:setup() successfully completed in 154.67s...............
2023-04-03 18:35:04,634:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-03 18:35:04,634:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-03 18:35:04,634:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-03 18:35:04,634:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-03 18:35:05,059:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-03 18:35:09,078:INFO:PyCaret ClassificationExperiment
2023-04-03 18:35:09,078:INFO:Logging name: clf-default-name
2023-04-03 18:35:09,078:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-03 18:35:09,078:INFO:version 3.0.0
2023-04-03 18:35:09,078:INFO:Initializing setup()
2023-04-03 18:35:09,078:INFO:self.USI: 04d6
2023-04-03 18:35:09,078:INFO:self._variable_keys: {'fold_groups_param', 'pipeline', 'X_train', 'exp_name_log', 'idx', 'X_test', '_ml_usecase', 'fold_shuffle_param', 'y_train', 'n_jobs_param', 'X', 'target_param', 'fold_generator', 'y_test', 'gpu_n_jobs_param', 'log_plots_param', 'gpu_param', 'y', 'exp_id', 'is_multiclass', '_available_plots', 'html_param', 'logging_param', 'fix_imbalance', 'USI', 'memory', 'data', 'seed'}
2023-04-03 18:35:09,078:INFO:Checking environment
2023-04-03 18:35:09,078:INFO:python_version: 3.9.13
2023-04-03 18:35:09,078:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-04-03 18:35:09,078:INFO:machine: x86_64
2023-04-03 18:35:09,078:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-04-03 18:35:09,078:INFO:Memory: svmem(total=17179869184, available=1255780352, percent=92.7, used=2083143680, free=18042880, active=1240858624, inactive=1218113536, wired=842285056)
2023-04-03 18:35:09,078:INFO:Physical Core: 10
2023-04-03 18:35:09,078:INFO:Logical Core: 10
2023-04-03 18:35:09,078:INFO:Checking libraries
2023-04-03 18:35:09,078:INFO:System:
2023-04-03 18:35:09,078:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-04-03 18:35:09,078:INFO:executable: /opt/anaconda3/bin/python
2023-04-03 18:35:09,078:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-04-03 18:35:09,078:INFO:PyCaret required dependencies:
2023-04-03 18:35:09,078:INFO:                 pip: 22.2.2
2023-04-03 18:35:09,078:INFO:          setuptools: 63.4.1
2023-04-03 18:35:09,078:INFO:             pycaret: 3.0.0
2023-04-03 18:35:09,078:INFO:             IPython: 7.31.1
2023-04-03 18:35:09,078:INFO:          ipywidgets: 7.6.5
2023-04-03 18:35:09,078:INFO:                tqdm: 4.64.1
2023-04-03 18:35:09,079:INFO:               numpy: 1.21.5
2023-04-03 18:35:09,079:INFO:              pandas: 1.4.4
2023-04-03 18:35:09,079:INFO:              jinja2: 2.11.3
2023-04-03 18:35:09,079:INFO:               scipy: 1.9.1
2023-04-03 18:35:09,079:INFO:              joblib: 1.2.0
2023-04-03 18:35:09,079:INFO:             sklearn: 1.0.2
2023-04-03 18:35:09,079:INFO:                pyod: 1.0.9
2023-04-03 18:35:09,079:INFO:            imblearn: 0.10.1
2023-04-03 18:35:09,079:INFO:   category_encoders: 2.6.0
2023-04-03 18:35:09,079:INFO:            lightgbm: 3.3.5
2023-04-03 18:35:09,079:INFO:               numba: 0.55.1
2023-04-03 18:35:09,079:INFO:            requests: 2.28.1
2023-04-03 18:35:09,079:INFO:          matplotlib: 3.5.2
2023-04-03 18:35:09,079:INFO:          scikitplot: 0.3.7
2023-04-03 18:35:09,079:INFO:         yellowbrick: 1.5
2023-04-03 18:35:09,079:INFO:              plotly: 5.9.0
2023-04-03 18:35:09,079:INFO:             kaleido: 0.2.1
2023-04-03 18:35:09,079:INFO:         statsmodels: 0.13.2
2023-04-03 18:35:09,079:INFO:              sktime: 0.16.1
2023-04-03 18:35:09,079:INFO:               tbats: 1.1.2
2023-04-03 18:35:09,079:INFO:            pmdarima: 2.0.3
2023-04-03 18:35:09,079:INFO:              psutil: 5.9.0
2023-04-03 18:35:09,079:INFO:PyCaret optional dependencies:
2023-04-03 18:35:09,092:INFO:                shap: Not installed
2023-04-03 18:35:09,092:INFO:           interpret: Not installed
2023-04-03 18:35:09,092:INFO:                umap: Not installed
2023-04-03 18:35:09,092:INFO:    pandas_profiling: Not installed
2023-04-03 18:35:09,092:INFO:  explainerdashboard: Not installed
2023-04-03 18:35:09,092:INFO:             autoviz: Not installed
2023-04-03 18:35:09,092:INFO:           fairlearn: Not installed
2023-04-03 18:35:09,092:INFO:             xgboost: Not installed
2023-04-03 18:35:09,093:INFO:            catboost: Not installed
2023-04-03 18:35:09,093:INFO:              kmodes: Not installed
2023-04-03 18:35:09,093:INFO:             mlxtend: Not installed
2023-04-03 18:35:09,093:INFO:       statsforecast: Not installed
2023-04-03 18:35:09,093:INFO:        tune_sklearn: Not installed
2023-04-03 18:35:09,093:INFO:                 ray: Not installed
2023-04-03 18:35:09,093:INFO:            hyperopt: Not installed
2023-04-03 18:35:09,093:INFO:              optuna: Not installed
2023-04-03 18:35:09,093:INFO:               skopt: Not installed
2023-04-03 18:35:09,093:INFO:              mlflow: Not installed
2023-04-03 18:35:09,093:INFO:              gradio: Not installed
2023-04-03 18:35:09,093:INFO:             fastapi: Not installed
2023-04-03 18:35:09,093:INFO:             uvicorn: Not installed
2023-04-03 18:35:09,093:INFO:              m2cgen: Not installed
2023-04-03 18:35:09,093:INFO:           evidently: Not installed
2023-04-03 18:35:09,093:INFO:               fugue: Not installed
2023-04-03 18:35:09,093:INFO:           streamlit: Not installed
2023-04-03 18:35:09,093:INFO:             prophet: Not installed
2023-04-03 18:35:09,093:INFO:None
2023-04-03 18:35:09,093:INFO:Set up data.
2023-04-03 18:35:10,854:INFO:Set up train/test split.
2023-04-03 18:35:11,631:INFO:Set up index.
2023-04-03 18:35:11,652:INFO:Set up folding strategy.
2023-04-03 18:35:11,652:INFO:Assigning column types.
2023-04-03 18:35:12,490:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-03 18:35:12,525:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-03 18:35:12,527:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-03 18:35:12,554:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:35:12,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:35:12,608:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-03 18:35:12,608:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-03 18:35:12,631:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:35:12,632:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:35:12,632:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-03 18:35:12,668:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-03 18:35:12,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:35:12,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:35:12,727:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-03 18:35:12,748:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:35:12,749:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:35:12,749:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-03 18:35:12,807:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:35:12,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:35:12,866:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:35:12,866:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:35:12,868:INFO:Preparing preprocessing pipeline...
2023-04-03 18:35:12,954:INFO:Set up simple imputation.
2023-04-03 18:35:13,186:INFO:Set up encoding of categorical features.
2023-04-03 18:35:13,191:INFO:Set up removing outliers.
2023-04-03 18:35:13,191:INFO:Set up imbalanced handling.
2023-04-03 18:35:13,191:INFO:Set up feature normalization.
2023-04-03 18:35:39,760:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 18:36:27,263:INFO:Finished creating preprocessing pipeline.
2023-04-03 18:36:27,270:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['hour_of_day',
                                             'avg_last_rrc_measurement_earfcn',
                                             'num_distinct_imsi',
                                             'mute_call_gap_indicator',
                                             'num_mute_calls', 'avg_cqi',
                                             'min_cqi', 'max_cqi', 'p05_cqi',
                                             'p10_cqi', 'p50_cqi', 'p90_cqi',
                                             'p95_cq...
                                                               n_jobs=1,
                                                               random_state=5016,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2023-04-03 18:36:27,270:INFO:Creating final display dataframe.
2023-04-03 18:36:50,368:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 18:37:41,741:INFO:Setup _display_container:                     Description             Value
0                    Session id              5016
1                        Target   Target_Variable
2                   Target type            Binary
3           Original data shape     (343124, 217)
4        Transformed data shape     (297708, 211)
5   Transformed train set shape     (194770, 211)
6    Transformed test set shape     (102938, 211)
7               Ignore features                 8
8              Numeric features               207
9          Categorical features                 1
10     Rows with missing values              0.0%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold               0.5
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            minmax
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              04d6
2023-04-03 18:37:41,807:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:37:41,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:37:41,866:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:37:41,866:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:37:41,867:INFO:setup() successfully completed in 152.82s...............
2023-04-03 18:41:06,403:INFO:gpu_param set to False
2023-04-03 18:41:06,487:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:41:06,487:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:41:06,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:41:06,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-03 18:46:53,181:INFO:Initializing compare_models()
2023-04-03 18:46:53,181:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, include=['lr', 'dt', 'svm', 'rf', 'ada', 'gbc', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, 'include': ['lr', 'dt', 'svm', 'rf', 'ada', 'gbc', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-03 18:46:53,181:INFO:Checking exceptions
2023-04-03 18:46:53,609:INFO:Preparing display monitor
2023-04-03 18:46:53,677:INFO:Initializing Logistic Regression
2023-04-03 18:46:53,678:INFO:Total runtime is 5.745887756347657e-06 minutes
2023-04-03 18:46:53,680:INFO:SubProcess create_model() called ==================================
2023-04-03 18:46:53,680:INFO:Initializing create_model()
2023-04-03 18:46:53,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fceea915c10>, model_only=True, return_train_score=False, kwargs={})
2023-04-03 18:46:53,680:INFO:Checking exceptions
2023-04-03 18:46:53,680:INFO:Importing libraries
2023-04-03 18:46:53,681:INFO:Copying training dataset
2023-04-03 18:46:54,346:INFO:Defining folds
2023-04-03 18:46:54,346:INFO:Declaring metric variables
2023-04-03 18:46:54,349:INFO:Importing untrained model
2023-04-03 18:46:54,351:INFO:Logistic Regression Imported successfully
2023-04-03 18:46:54,355:INFO:Starting cross validation
2023-04-03 18:46:54,383:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-03 18:47:06,666:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:47:24,910:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:25,067:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:25,996:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:26,009:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:26,038:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:26,594:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:26,599:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:26,620:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:26,627:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:26,905:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:28,206:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:47:29,158:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:30,648:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:47:30,934:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:47:31,011:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:33,221:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:33,293:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:47:34,913:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:47:38,180:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:47:40,092:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:40,991:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:41,033:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:41,084:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:41,089:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:41,145:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:41,169:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:41,612:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:42,781:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:42,807:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:43,371:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:47:44,365:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:47:44,434:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:47:47,217:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:47:47,612:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:47:47,892:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:47:57,145:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:57,883:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:57,917:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:58,027:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:58,289:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:58,872:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:47:58,939:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:48:00,570:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:50:42,191:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 18:50:48,582:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 18:50:54,093:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 18:50:56,185:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 18:50:59,027:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 18:51:24,365:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 18:51:26,763:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 18:51:48,029:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 18:51:56,663:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 18:51:57,049:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 18:56:22,580:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:56:23,964:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:56:56,703:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:56:58,665:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:57:41,256:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:57:43,221:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:57:55,892:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:57:57,925:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:58:11,713:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:58:11,793:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:58:13,136:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:58:18,948:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:58:29,981:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:58:30,277:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:58:31,844:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:58:32,363:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:58:33,198:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:58:34,153:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:58:40,345:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 18:58:41,343:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:58:45,896:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:58:52,019:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 6.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:58:54,003:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:59:05,650:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:59:06,199:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:59:11,119:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 18:59:13,974:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:59:19,216:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:59:19,437:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:59:21,048:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:59:21,727:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:59:21,907:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:59:23,259:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 18:59:23,534:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 18:59:53,279:INFO:Calculating mean and std
2023-04-03 18:59:53,309:INFO:Creating metrics dataframe
2023-04-03 18:59:53,373:INFO:Uploading results into container
2023-04-03 18:59:53,375:INFO:Uploading model into container now
2023-04-03 18:59:53,378:INFO:_master_model_container: 1
2023-04-03 18:59:53,378:INFO:_display_container: 2
2023-04-03 18:59:53,383:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5016, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-03 18:59:53,383:INFO:create_model() successfully completed......................................
2023-04-03 18:59:53,826:INFO:SubProcess create_model() end ==================================
2023-04-03 18:59:53,827:INFO:Creating metrics dataframe
2023-04-03 18:59:53,836:INFO:Initializing Decision Tree Classifier
2023-04-03 18:59:53,836:INFO:Total runtime is 13.002645683288575 minutes
2023-04-03 18:59:53,838:INFO:SubProcess create_model() called ==================================
2023-04-03 18:59:53,838:INFO:Initializing create_model()
2023-04-03 18:59:53,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fceea915c10>, model_only=True, return_train_score=False, kwargs={})
2023-04-03 18:59:53,838:INFO:Checking exceptions
2023-04-03 18:59:53,838:INFO:Importing libraries
2023-04-03 18:59:53,839:INFO:Copying training dataset
2023-04-03 18:59:55,178:INFO:Defining folds
2023-04-03 18:59:55,179:INFO:Declaring metric variables
2023-04-03 18:59:55,181:INFO:Importing untrained model
2023-04-03 18:59:55,183:INFO:Decision Tree Classifier Imported successfully
2023-04-03 18:59:55,187:INFO:Starting cross validation
2023-04-03 18:59:55,289:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-03 18:59:59,671:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:04,273:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:05,081:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:16,111:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:16,583:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:16,694:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:16,739:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:17,095:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:17,181:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:18,754:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:19,014:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:19,451:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:21,837:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:22,144:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:24,147:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:24,496:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 4.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:24,524:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:24,766:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:25,651:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:26,106:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:26,214:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:26,572:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:27,178:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:28,393:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:28,937:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:29,326:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:29,589:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:29,600:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:29,779:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:30,269:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:30,718:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:32,679:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:33,192:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:33,919:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:33,925:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:34,795:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:37,883:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:38,539:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:39,066:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:39,865:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:40,123:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:40,190:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:41,484:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:42,017:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:42,425:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:44,597:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:44,998:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:45,791:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:46,074:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:47,476:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:47,622:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:00:49,369:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:51,623:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:51,837:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:53,629:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:53,660:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:55,779:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:00:56,299:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:01:08,544:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:01:08,869:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:01:09,595:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:01:21,535:INFO:Calculating mean and std
2023-04-03 19:01:21,545:INFO:Creating metrics dataframe
2023-04-03 19:01:21,579:INFO:Uploading results into container
2023-04-03 19:01:21,580:INFO:Uploading model into container now
2023-04-03 19:01:21,581:INFO:_master_model_container: 2
2023-04-03 19:01:21,581:INFO:_display_container: 2
2023-04-03 19:01:21,582:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5016, splitter='best')
2023-04-03 19:01:21,582:INFO:create_model() successfully completed......................................
2023-04-03 19:01:21,876:INFO:SubProcess create_model() end ==================================
2023-04-03 19:01:21,876:INFO:Creating metrics dataframe
2023-04-03 19:01:21,885:INFO:Initializing SVM - Linear Kernel
2023-04-03 19:01:21,885:INFO:Total runtime is 14.47012362877528 minutes
2023-04-03 19:01:21,887:INFO:SubProcess create_model() called ==================================
2023-04-03 19:01:21,887:INFO:Initializing create_model()
2023-04-03 19:01:21,887:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fceea915c10>, model_only=True, return_train_score=False, kwargs={})
2023-04-03 19:01:21,887:INFO:Checking exceptions
2023-04-03 19:01:21,887:INFO:Importing libraries
2023-04-03 19:01:21,887:INFO:Copying training dataset
2023-04-03 19:01:23,164:INFO:Defining folds
2023-04-03 19:01:23,164:INFO:Declaring metric variables
2023-04-03 19:01:23,167:INFO:Importing untrained model
2023-04-03 19:01:23,170:INFO:SVM - Linear Kernel Imported successfully
2023-04-03 19:01:23,174:INFO:Starting cross validation
2023-04-03 19:01:23,257:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-03 19:01:30,115:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:01:30,643:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:01:31,824:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:01:34,989:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:01:36,334:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:01:44,629:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:01:51,066:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:01:51,736:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:01:51,758:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:01:52,115:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:01:52,148:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:01:52,429:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:01:53,466:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:01:54,296:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 6.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:01:54,548:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:01:56,935:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 4.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:01:58,234:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:01:59,827:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:02:10,184:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:02:10,854:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:02:11,506:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:02:11,735:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:02:12,008:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:04:23,211:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:04:35,827:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:04:38,208:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:04:40,654:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:05:05,956:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:05:07,670:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:05:13,632:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:05:39,306:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:05:45,094:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:05:50,395:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:07:58,618:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:07:59,972:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:09:47,061:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:09:49,438:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:09:50,051:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:09:51,592:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:09:52,812:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:09:55,017:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:09:55,337:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:09:59,491:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:10:04,032:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:10:06,165:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-03 19:10:26,297:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:10:31,288:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:10:45,093:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:10:46,778:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:10:55,620:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:10:59,391:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:11:00,624:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:11:00,861:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:11:02,648:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:11:21,812:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:11:25,574:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:11:27,467:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:11:27,629:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:11:28,657:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:11:29,566:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:11:30,733:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:11:31,168:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:11:31,373:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-03 19:11:32,453:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:11:33,905:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-03 19:11:35,085:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:11:37,500:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-03 19:11:38,472:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-03 19:11:45,165:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:11:46,104:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:11:46,990:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:11:49,830:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:11:49,998:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-03 19:11:50,354:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-03 19:11:51,699:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:11:52,772:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:11:53,866:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-03 19:11:55,537:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-03 19:11:56,464:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-03 19:11:56,619:INFO:Calculating mean and std
2023-04-03 19:11:56,642:INFO:Creating metrics dataframe
2023-04-03 19:11:56,691:INFO:Uploading results into container
2023-04-03 19:11:56,694:INFO:Uploading model into container now
2023-04-03 19:11:56,696:INFO:_master_model_container: 3
2023-04-03 19:11:56,696:INFO:_display_container: 2
2023-04-03 19:11:56,703:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5016, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-03 19:11:56,703:INFO:create_model() successfully completed......................................
2023-04-03 19:11:57,167:INFO:SubProcess create_model() end ==================================
2023-04-03 19:11:57,167:INFO:Creating metrics dataframe
2023-04-03 19:11:57,179:INFO:Initializing Random Forest Classifier
2023-04-03 19:11:57,179:INFO:Total runtime is 25.058356897036234 minutes
2023-04-03 19:11:57,181:INFO:SubProcess create_model() called ==================================
2023-04-03 19:11:57,181:INFO:Initializing create_model()
2023-04-03 19:11:57,181:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fceea915c10>, model_only=True, return_train_score=False, kwargs={})
2023-04-03 19:11:57,182:INFO:Checking exceptions
2023-04-03 19:11:57,182:INFO:Importing libraries
2023-04-03 19:11:57,182:INFO:Copying training dataset
2023-04-03 19:11:58,413:INFO:Defining folds
2023-04-03 19:11:58,413:INFO:Declaring metric variables
2023-04-03 19:11:58,415:INFO:Importing untrained model
2023-04-03 19:11:58,417:INFO:Random Forest Classifier Imported successfully
2023-04-03 19:11:58,421:INFO:Starting cross validation
2023-04-03 19:11:58,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-03 19:12:05,113:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:07,469:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:15,752:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:21,244:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:21,919:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:22,308:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:22,356:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:22,369:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:22,375:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:22,662:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:22,668:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:22,717:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:25,300:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:25,504:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:25,833:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:25,854:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:25,887:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:25,953:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:27,421:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:29,546:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:29,603:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:31,974:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:32,141:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:32,389:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:32,429:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:35,093:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:36,286:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:36,356:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:37,492:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:37,515:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:37,542:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:37,728:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:37,784:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:38,032:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:38,830:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:39,063:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:39,103:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:39,539:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:41,381:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:42,632:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:42,645:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:45,770:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:50,205:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:50,252:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:50,292:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:50,487:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:50,935:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:52,077:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:52,937:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:52,938:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:53,680:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:54,125:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:12:55,302:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:12:55,990:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:13:02,606:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:13:03,725:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:13:03,727:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:13:04,109:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:13:04,175:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:13:42,827:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:14:23,492:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:14:25,970:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:14:28,199:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:14:52,466:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:14:56,641:INFO:Calculating mean and std
2023-04-03 19:14:56,655:INFO:Creating metrics dataframe
2023-04-03 19:14:56,685:INFO:Uploading results into container
2023-04-03 19:14:56,687:INFO:Uploading model into container now
2023-04-03 19:14:56,688:INFO:_master_model_container: 4
2023-04-03 19:14:56,688:INFO:_display_container: 2
2023-04-03 19:14:56,690:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5016, verbose=0, warm_start=False)
2023-04-03 19:14:56,690:INFO:create_model() successfully completed......................................
2023-04-03 19:14:57,003:INFO:SubProcess create_model() end ==================================
2023-04-03 19:14:57,003:INFO:Creating metrics dataframe
2023-04-03 19:14:57,012:INFO:Initializing Ada Boost Classifier
2023-04-03 19:14:57,012:INFO:Total runtime is 28.05557921330134 minutes
2023-04-03 19:14:57,014:INFO:SubProcess create_model() called ==================================
2023-04-03 19:14:57,014:INFO:Initializing create_model()
2023-04-03 19:14:57,014:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fceea915c10>, model_only=True, return_train_score=False, kwargs={})
2023-04-03 19:14:57,014:INFO:Checking exceptions
2023-04-03 19:14:57,014:INFO:Importing libraries
2023-04-03 19:14:57,015:INFO:Copying training dataset
2023-04-03 19:14:58,126:INFO:Defining folds
2023-04-03 19:14:58,126:INFO:Declaring metric variables
2023-04-03 19:14:58,128:INFO:Importing untrained model
2023-04-03 19:14:58,130:INFO:Ada Boost Classifier Imported successfully
2023-04-03 19:14:58,135:INFO:Starting cross validation
2023-04-03 19:14:58,226:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-03 19:15:04,586:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:15:08,930:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:15:11,370:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:15:12,729:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 4.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:15:17,198:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:15:17,547:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:15:20,666:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:15:21,318:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:15:21,999:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:15:22,260:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:15:22,438:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:15:22,467:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:15:22,573:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:15:22,737:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:15:23,304:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:15:23,519:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:15:25,880:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 4.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:15:27,139:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:15:27,637:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 5.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:15:32,922:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:15:35,964:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:15:36,868:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:15:37,949:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:15:38,436:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:15:38,743:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:15:40,832:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:15:42,333:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:15:43,196:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:15:49,069:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:15:52,344:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:15:55,389:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:17:50,674:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:17:58,393:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:17:58,533:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:18:08,373:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:18:29,900:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:18:30,010:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:18:53,832:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:19:17,180:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:19:20,331:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:19:52,364:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:20:51,508:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:20:54,098:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:21:38,167:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:21:38,475:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:21:40,547:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:21:52,682:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:21:54,631:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:22:01,967:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:22:23,406:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:22:29,614:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:22:31,529:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:22:42,768:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:22:43,556:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:22:46,359:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:22:58,924:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:22:59,904:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:23:03,348:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:23:05,216:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:23:05,473:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:23:06,477:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:23:07,683:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:23:08,781:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:23:14,376:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:23:15,577:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:23:17,812:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:23:25,074:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:23:28,214:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:23:28,954:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:23:31,856:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:23:32,308:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:23:40,910:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:23:49,411:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:23:53,088:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:25:42,637:INFO:Calculating mean and std
2023-04-03 19:25:42,652:INFO:Creating metrics dataframe
2023-04-03 19:25:42,693:INFO:Uploading results into container
2023-04-03 19:25:42,694:INFO:Uploading model into container now
2023-04-03 19:25:42,696:INFO:_master_model_container: 5
2023-04-03 19:25:42,696:INFO:_display_container: 2
2023-04-03 19:25:42,699:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=5016)
2023-04-03 19:25:42,699:INFO:create_model() successfully completed......................................
2023-04-03 19:25:43,124:INFO:SubProcess create_model() end ==================================
2023-04-03 19:25:43,124:INFO:Creating metrics dataframe
2023-04-03 19:25:43,132:INFO:Initializing Gradient Boosting Classifier
2023-04-03 19:25:43,132:INFO:Total runtime is 38.82425079743067 minutes
2023-04-03 19:25:43,134:INFO:SubProcess create_model() called ==================================
2023-04-03 19:25:43,134:INFO:Initializing create_model()
2023-04-03 19:25:43,134:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fceea915c10>, model_only=True, return_train_score=False, kwargs={})
2023-04-03 19:25:43,135:INFO:Checking exceptions
2023-04-03 19:25:43,135:INFO:Importing libraries
2023-04-03 19:25:43,135:INFO:Copying training dataset
2023-04-03 19:25:44,465:INFO:Defining folds
2023-04-03 19:25:44,465:INFO:Declaring metric variables
2023-04-03 19:25:44,491:INFO:Importing untrained model
2023-04-03 19:25:44,494:INFO:Gradient Boosting Classifier Imported successfully
2023-04-03 19:25:44,497:INFO:Starting cross validation
2023-04-03 19:25:44,580:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-03 19:25:48,919:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:25:52,249:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:26:03,214:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:05,939:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:08,015:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:08,025:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:08,329:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:09,277:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:09,309:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:09,315:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:09,318:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:09,329:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:12,006:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:12,144:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:12,709:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:26:12,721:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:26:13,338:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:13,957:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:14,469:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:26:15,119:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:26:15,732:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:16,117:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:16,938:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:26:17,133:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:19,150:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:26:20,580:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:26:20,583:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:23,864:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:23,930:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:26:25,185:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:25,279:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:25,460:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:26,570:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:26:26,667:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:26:27,041:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:27,278:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:27,984:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:28,560:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:26:28,705:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:29,443:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:31,516:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:38,690:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:39,738:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:40,233:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:40,814:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:40,951:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:41,120:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:41,129:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:26:41,482:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:44:09,553:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:44:15,496:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:44:15,878:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:44:18,546:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:44:20,997:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:44:23,532:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:44:30,063:INFO:Calculating mean and std
2023-04-03 19:44:30,079:INFO:Creating metrics dataframe
2023-04-03 19:44:30,131:INFO:Uploading results into container
2023-04-03 19:44:30,132:INFO:Uploading model into container now
2023-04-03 19:44:30,134:INFO:_master_model_container: 6
2023-04-03 19:44:30,134:INFO:_display_container: 2
2023-04-03 19:44:30,138:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5016, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-03 19:44:30,139:INFO:create_model() successfully completed......................................
2023-04-03 19:44:30,569:INFO:SubProcess create_model() end ==================================
2023-04-03 19:44:30,569:INFO:Creating metrics dataframe
2023-04-03 19:44:30,582:INFO:Initializing Light Gradient Boosting Machine
2023-04-03 19:44:30,582:INFO:Total runtime is 57.61507651408513 minutes
2023-04-03 19:44:30,584:INFO:SubProcess create_model() called ==================================
2023-04-03 19:44:30,584:INFO:Initializing create_model()
2023-04-03 19:44:30,584:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fceea915c10>, model_only=True, return_train_score=False, kwargs={})
2023-04-03 19:44:30,584:INFO:Checking exceptions
2023-04-03 19:44:30,585:INFO:Importing libraries
2023-04-03 19:44:30,585:INFO:Copying training dataset
2023-04-03 19:44:32,240:INFO:Defining folds
2023-04-03 19:44:32,240:INFO:Declaring metric variables
2023-04-03 19:44:32,243:INFO:Importing untrained model
2023-04-03 19:44:32,246:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-03 19:44:32,251:INFO:Starting cross validation
2023-04-03 19:44:32,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-03 19:44:49,518:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 4.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:44:59,104:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:44:59,348:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:44:59,518:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:44:59,838:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:44:59,971:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:45:00,782:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:45:01,443:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:45:01,826:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:45:01,950:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:45:02,118:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:45:02,305:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:45:05,522:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:45:07,462:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 4.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:45:09,033:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:45:12,408:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 5.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:45:13,873:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:45:15,791:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:45:17,172:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:45:17,217:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:45:19,170:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 7.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:45:19,515:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:45:19,596:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:45:20,020:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:45:22,823:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:47:00,775:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:47:11,891:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:47:34,470:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:47:49,077:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:47:57,433:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:48:00,312:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:48:13,624:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:48:21,873:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:49:12,215:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:49:38,547:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:49:56,681:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:49:58,359:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:50:00,549:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:50:46,035:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:50:47,998:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:50:57,348:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:50:58,679:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:51:00,189:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 6.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:51:01,671:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:51:09,882:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:51:10,845:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:51:11,961:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:51:12,194:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:51:25,295:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:51:28,001:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:51:37,171:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:51:38,712:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:51:44,485:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:51:46,663:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:51:48,960:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:51:50,354:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:52:00,124:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:52:03,001:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:52:08,149:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:52:09,695:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-03 19:52:12,567:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:52:13,982:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:52:15,418:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:52:20,662:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:52:20,691:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:52:20,762:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:52:21,108:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:52:22,231:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:52:22,489:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:52:23,806:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:52:26,967:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:52:28,578:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-03 19:52:34,399:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-03 19:52:48,285:INFO:Calculating mean and std
2023-04-03 19:52:48,303:INFO:Creating metrics dataframe
2023-04-03 19:52:48,351:INFO:Uploading results into container
2023-04-03 19:52:48,353:INFO:Uploading model into container now
2023-04-03 19:52:48,355:INFO:_master_model_container: 7
2023-04-03 19:52:48,355:INFO:_display_container: 2
2023-04-03 19:52:48,362:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-03 19:52:48,362:INFO:create_model() successfully completed......................................
2023-04-03 19:52:48,755:INFO:SubProcess create_model() end ==================================
2023-04-03 19:52:48,756:INFO:Creating metrics dataframe
2023-04-03 19:52:48,774:INFO:Initializing create_model()
2023-04-03 19:52:48,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-03 19:52:48,774:INFO:Checking exceptions
2023-04-03 19:52:48,776:INFO:Importing libraries
2023-04-03 19:52:48,777:INFO:Copying training dataset
2023-04-03 19:52:50,221:INFO:Defining folds
2023-04-03 19:52:50,221:INFO:Declaring metric variables
2023-04-03 19:52:50,221:INFO:Importing untrained model
2023-04-03 19:52:50,221:INFO:Declaring custom model
2023-04-03 19:52:50,222:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-03 19:52:50,316:INFO:Cross validation set to False
2023-04-03 19:52:50,317:INFO:Fitting Model
2023-04-03 19:53:17,102:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-03 19:54:14,498:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-03 19:54:14,498:INFO:create_model() successfully completed......................................
2023-04-03 19:54:14,627:INFO:_master_model_container: 7
2023-04-03 19:54:14,628:INFO:_display_container: 2
2023-04-03 19:54:14,628:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-03 19:54:14,628:INFO:compare_models() successfully completed......................................
2023-04-04 11:35:14,200:INFO:Initializing create_model()
2023-04-04 11:35:14,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-04 11:35:14,201:INFO:Checking exceptions
2023-04-04 11:35:14,250:INFO:Importing libraries
2023-04-04 11:35:14,251:INFO:Copying training dataset
2023-04-04 11:35:15,063:INFO:Defining folds
2023-04-04 11:35:15,063:INFO:Declaring metric variables
2023-04-04 11:35:15,066:INFO:Importing untrained model
2023-04-04 11:35:15,068:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-04 11:35:15,071:INFO:Starting cross validation
2023-04-04 11:35:15,108:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-04 11:35:34,572:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:35:34,606:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:35:36,323:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:35:36,389:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:36:13,212:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:36:13,452:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:36:13,464:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:36:14,907:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:36:15,543:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:36:53,140:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:37:26,806:INFO:Calculating mean and std
2023-04-04 11:37:26,826:INFO:Creating metrics dataframe
2023-04-04 11:37:26,855:INFO:Finalizing model
2023-04-04 11:37:34,769:INFO:Uploading results into container
2023-04-04 11:37:34,778:INFO:Uploading model into container now
2023-04-04 11:37:34,799:INFO:_master_model_container: 8
2023-04-04 11:37:34,799:INFO:_display_container: 3
2023-04-04 11:37:34,800:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-04 11:37:34,800:INFO:create_model() successfully completed......................................
2023-04-04 11:49:14,375:INFO:Initializing tune_model()
2023-04-04 11:49:14,376:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>)
2023-04-04 11:49:14,377:INFO:Checking exceptions
2023-04-04 11:49:15,240:INFO:Copying training dataset
2023-04-04 11:49:15,627:INFO:Checking base model
2023-04-04 11:49:15,628:INFO:Base model : Light Gradient Boosting Machine
2023-04-04 11:49:15,630:INFO:Declaring metric variables
2023-04-04 11:49:15,632:INFO:Defining Hyperparameters
2023-04-04 11:49:15,772:INFO:Tuning with n_jobs=-1
2023-04-04 11:49:15,772:INFO:Initializing RandomizedSearchCV
2023-04-04 11:49:24,425:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:49:24,616:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:49:25,485:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:49:25,578:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:49:25,607:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:49:35,890:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:35,957:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:36,028:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:36,083:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:36,135:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:36,143:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:36,338:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:37,575:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:37,621:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:37,659:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:41,726:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:43,859:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:44,678:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:46,146:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:48,096:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:48,127:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:48,438:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:48,513:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:49,515:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:49:58,128:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:49:59,419:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:49:59,530:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:49:59,667:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:50:07,633:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:50:10,546:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:50:15,396:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:50:15,529:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 3.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:50:15,535:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:50:16,782:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 3.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:50:16,814:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:50:17,395:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:50:17,805:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 4.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:50:18,422:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 11:50:18,511:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:50:19,289:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:50:19,344:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:50:19,430:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 4.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:50:19,966:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 5.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:50:20,332:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 11:50:21,188:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 11:50:22,245:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:50:22,264:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 11:50:22,382:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:50:22,833:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 11:50:31,671:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:50:31,828:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:50:32,983:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:50:36,770:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:50:37,029:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:50:40,287:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:51:43,442:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:51:44,972:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:51:45,366:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:51:46,109:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:51:46,590:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:51:47,851:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:51:48,084:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:51:51,255:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:51:51,344:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:51:53,965:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:51:57,346:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:51:59,301:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:52:19,048:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:54:38,223:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:54:41,194:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:54:57,853:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:54:58,854:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:55:00,748:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:55:01,235:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:55:02,921:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:55:21,848:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 7.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:55:23,035:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:55:26,023:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 6.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:55:30,425:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:55:35,221:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:55:51,864:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:56:05,214:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:56:07,359:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:56:12,473:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:56:25,024:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:56:25,877:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:56:28,618:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:56:30,275:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:56:30,939:WARNING:/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2023-04-04 11:56:31,808:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:56:32,564:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:56:33,348:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:56:33,694:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:56:34,539:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:56:36,954:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:56:36,993:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:56:37,353:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:56:39,755:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:56:39,792:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:56:40,107:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:56:41,636:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:56:41,702:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:56:42,280:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:56:45,290:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:56:50,337:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:56:51,415:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:56:53,973:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:56:55,168:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:56:56,398:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:56:59,449:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:57:03,840:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:57:06,420:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 11:57:07,613:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:57:09,763:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 11:57:11,109:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:57:11,297:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:12,653:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:14,653:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:57:17,106:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:18,192:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:57:18,714:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:19,960:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 11:57:20,205:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:20,519:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:57:21,332:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:22,176:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 11:57:22,732:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:23,403:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:23,430:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:57:23,496:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:57:23,529:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:24,424:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:24,583:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 11:57:27,085:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:57:27,638:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:57:28,115:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:57:33,690:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:33,700:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:57:37,124:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:57:37,656:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:37,786:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:39,405:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:39,763:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:39,811:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:39,863:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 5.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:57:39,874:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:42,105:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:57:44,331:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 6.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:50,904:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 11:57:53,593:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:54,761:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:57:54,795:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 11:58:16,226:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:58:21,238:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 11:58:32,401:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 11:59:17,207:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:59:18,091:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:59:19,025:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:59:23,862:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:59:28,458:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:59:36,331:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 11:59:56,181:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 12:00:22,583:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 12:01:31,548:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 12:01:49,149:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:01:50,429:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:02:06,719:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 12:02:13,902:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:02:15,797:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:02:18,743:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:02:25,197:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:02:26,227:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:02:26,531:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:02:27,940:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:02:37,345:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:02:56,966:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:03:06,684:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:03:09,605:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:03:12,882:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:03:14,090:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:03:15,935:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:03:16,400:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:03:17,258:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:03:18,057:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:03:18,595:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:03:18,609:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:03:20,407:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:03:20,964:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:03:23,167:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 12:03:23,688:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:03:23,762:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:03:25,378:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:03:28,532:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:03:32,424:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:03:35,648:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:03:45,181:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:03:46,602:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 12:03:49,442:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 12:03:54,626:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 12:03:55,240:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 12:03:59,095:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:04:00,307:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 12:04:00,479:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:04:01,177:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:04:02,268:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:04:02,839:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:04:09,730:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:04:14,038:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:04:15,429:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:04:15,836:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:04:15,938:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:04:15,945:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:04:16,122:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:04:16,667:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 3.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 12:04:16,759:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:04:17,627:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:04:18,526:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:04:19,044:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:04:19,145:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:04:32,315:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:04:32,427:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:04:33,467:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:04:33,792:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 4.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:04:39,086:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 4.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 12:04:39,156:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:04:42,887:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 12:04:49,203:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 12:04:51,338:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:04:55,886:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:04:59,002:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:04:59,753:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:05:00,780:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:05:02,659:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:05:03,485:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:05:04,929:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:05:06,082:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:05:24,667:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 12:05:24,918:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:05:27,683:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 3.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 12:05:29,662:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:05:29,738:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 12:05:33,320:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 12:05:34,431:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 4.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 12:05:35,317:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:05:37,161:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 12:05:40,676:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 12:05:42,373:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 12:05:44,453:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 12:05:48,379:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 12:05:57,953:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 12:06:03,279:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 12:06:06,770:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 12:06:25,250:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:07:23,594:INFO:best_params: {'actual_estimator__reg_lambda': 0.01, 'actual_estimator__reg_alpha': 0.4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 290, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 21, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 0.8}
2023-04-04 12:07:23,610:INFO:Hyperparameter search completed
2023-04-04 12:07:23,610:INFO:SubProcess create_model() called ==================================
2023-04-04 12:07:23,622:INFO:Initializing create_model()
2023-04-04 12:07:23,622:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcee5e50a00>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.01, 'reg_alpha': 0.4, 'num_leaves': 80, 'n_estimators': 290, 'min_split_gain': 0.1, 'min_child_samples': 21, 'learning_rate': 0.2, 'feature_fraction': 1.0, 'bagging_freq': 5, 'bagging_fraction': 0.8})
2023-04-04 12:07:23,622:INFO:Checking exceptions
2023-04-04 12:07:23,624:INFO:Importing libraries
2023-04-04 12:07:23,625:INFO:Copying training dataset
2023-04-04 12:07:24,983:INFO:Defining folds
2023-04-04 12:07:24,984:INFO:Declaring metric variables
2023-04-04 12:07:25,002:INFO:Importing untrained model
2023-04-04 12:07:25,002:INFO:Declaring custom model
2023-04-04 12:07:25,013:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-04 12:07:25,018:INFO:Starting cross validation
2023-04-04 12:07:25,139:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-04 12:07:28,171:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:07:28,669:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:07:54,511:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 12:08:42,931:INFO:Calculating mean and std
2023-04-04 12:08:42,934:INFO:Creating metrics dataframe
2023-04-04 12:08:42,947:INFO:Finalizing model
2023-04-04 12:09:07,813:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 12:10:10,248:INFO:Uploading results into container
2023-04-04 12:10:10,248:INFO:Uploading model into container now
2023-04-04 12:10:10,249:INFO:_master_model_container: 9
2023-04-04 12:10:10,249:INFO:_display_container: 4
2023-04-04 12:10:10,250:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-04 12:10:10,250:INFO:create_model() successfully completed......................................
2023-04-04 12:10:10,568:INFO:SubProcess create_model() end ==================================
2023-04-04 12:10:10,568:INFO:choose_better activated
2023-04-04 12:10:10,570:INFO:SubProcess create_model() called ==================================
2023-04-04 12:10:10,571:INFO:Initializing create_model()
2023-04-04 12:10:10,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-04 12:10:10,571:INFO:Checking exceptions
2023-04-04 12:10:10,572:INFO:Importing libraries
2023-04-04 12:10:10,572:INFO:Copying training dataset
2023-04-04 12:10:11,255:INFO:Defining folds
2023-04-04 12:10:11,255:INFO:Declaring metric variables
2023-04-04 12:10:11,256:INFO:Importing untrained model
2023-04-04 12:10:11,256:INFO:Declaring custom model
2023-04-04 12:10:11,256:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-04 12:10:11,256:INFO:Starting cross validation
2023-04-04 12:10:11,284:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-04 12:10:14,433:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:10:17,717:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:10:17,739:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:10:18,799:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 12:10:21,978:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:10:21,999:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 12:10:37,966:INFO:Calculating mean and std
2023-04-04 12:10:37,968:INFO:Creating metrics dataframe
2023-04-04 12:10:37,973:INFO:Finalizing model
2023-04-04 12:10:49,849:INFO:Uploading results into container
2023-04-04 12:10:49,850:INFO:Uploading model into container now
2023-04-04 12:10:49,850:INFO:_master_model_container: 10
2023-04-04 12:10:49,850:INFO:_display_container: 5
2023-04-04 12:10:49,851:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-04 12:10:49,851:INFO:create_model() successfully completed......................................
2023-04-04 12:10:49,985:INFO:SubProcess create_model() end ==================================
2023-04-04 12:10:49,986:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5016, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9914
2023-04-04 12:10:49,986:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9934
2023-04-04 12:10:49,987:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-04-04 12:10:49,987:INFO:choose_better completed
2023-04-04 12:10:49,996:INFO:_master_model_container: 10
2023-04-04 12:10:49,996:INFO:_display_container: 4
2023-04-04 12:10:49,997:INFO:LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-04 12:10:49,997:INFO:tune_model() successfully completed......................................
2023-04-04 12:32:57,672:INFO:Initializing plot_model()
2023-04-04 12:32:57,673:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, system=True)
2023-04-04 12:32:57,673:INFO:Checking exceptions
2023-04-04 12:32:58,041:INFO:Preloading libraries
2023-04-04 12:32:58,053:INFO:Copying training dataset
2023-04-04 12:32:58,053:INFO:Plot type: feature
2023-04-04 12:32:58,055:WARNING:No coef_ found. Trying feature_importances_
2023-04-04 12:33:20,469:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 12:34:08,361:INFO:Visual Rendered Successfully
2023-04-04 12:34:08,452:INFO:plot_model() successfully completed......................................
2023-04-04 12:35:08,803:INFO:Initializing plot_model()
2023-04-04 12:35:08,804:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, system=True)
2023-04-04 12:35:08,805:INFO:Checking exceptions
2023-04-04 12:35:09,057:INFO:Preloading libraries
2023-04-04 12:35:09,066:INFO:Copying training dataset
2023-04-04 12:35:09,067:INFO:Plot type: feature
2023-04-04 12:35:09,067:WARNING:No coef_ found. Trying feature_importances_
2023-04-04 12:35:09,867:INFO:Saving 'Feature Importance.png'
2023-04-04 12:35:09,944:INFO:Visual Rendered Successfully
2023-04-04 12:35:10,002:INFO:plot_model() successfully completed......................................
2023-04-04 12:36:02,391:INFO:Initializing plot_model()
2023-04-04 12:36:02,391:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, system=True)
2023-04-04 12:36:02,392:INFO:Checking exceptions
2023-04-04 12:36:02,787:INFO:Preloading libraries
2023-04-04 12:36:02,797:INFO:Copying training dataset
2023-04-04 12:36:02,797:INFO:Plot type: feature
2023-04-04 12:36:02,798:WARNING:No coef_ found. Trying feature_importances_
2023-04-04 12:36:03,743:INFO:Visual Rendered Successfully
2023-04-04 12:36:03,841:INFO:plot_model() successfully completed......................................
2023-04-04 12:36:07,210:INFO:Initializing plot_model()
2023-04-04 12:36:07,211:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, system=True)
2023-04-04 12:36:07,211:INFO:Checking exceptions
2023-04-04 12:36:07,451:INFO:Preloading libraries
2023-04-04 12:36:07,462:INFO:Copying training dataset
2023-04-04 12:36:07,462:INFO:Plot type: feature
2023-04-04 12:36:07,462:WARNING:No coef_ found. Trying feature_importances_
2023-04-04 12:36:08,356:INFO:Visual Rendered Successfully
2023-04-04 12:36:08,416:INFO:plot_model() successfully completed......................................
2023-04-04 12:39:16,027:INFO:Initializing plot_model()
2023-04-04 12:39:16,027:INFO:plot_model(plot=parameter, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, system=True)
2023-04-04 12:39:16,027:INFO:Checking exceptions
2023-04-04 12:39:16,284:INFO:Preloading libraries
2023-04-04 12:39:16,293:INFO:Copying training dataset
2023-04-04 12:39:16,293:INFO:Plot type: parameter
2023-04-04 12:39:16,296:INFO:Visual Rendered Successfully
2023-04-04 12:39:16,359:INFO:plot_model() successfully completed......................................
2023-04-04 12:40:23,401:INFO:Initializing plot_model()
2023-04-04 12:40:23,401:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, system=True)
2023-04-04 12:40:23,401:INFO:Checking exceptions
2023-04-04 12:40:23,666:INFO:Preloading libraries
2023-04-04 12:40:23,675:INFO:Copying training dataset
2023-04-04 12:40:23,675:INFO:Plot type: feature
2023-04-04 12:40:23,675:WARNING:No coef_ found. Trying feature_importances_
2023-04-04 12:40:24,538:INFO:Saving 'Feature Importance.png'
2023-04-04 12:40:24,616:INFO:Visual Rendered Successfully
2023-04-04 12:40:24,676:INFO:plot_model() successfully completed......................................
2023-04-04 12:40:24,676:INFO:Initializing plot_model()
2023-04-04 12:40:24,676:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, system=True)
2023-04-04 12:40:24,677:INFO:Checking exceptions
2023-04-04 12:40:24,899:INFO:Preloading libraries
2023-04-04 12:40:24,908:INFO:Copying training dataset
2023-04-04 12:40:24,908:INFO:Plot type: auc
2023-04-04 12:40:29,292:INFO:Fitting Model
2023-04-04 12:40:29,296:INFO:Scoring test/hold-out set
2023-04-04 12:40:30,156:INFO:Saving 'AUC.png'
2023-04-04 12:40:30,255:INFO:Visual Rendered Successfully
2023-04-04 12:40:30,337:INFO:plot_model() successfully completed......................................
2023-04-04 12:40:30,338:INFO:Initializing plot_model()
2023-04-04 12:40:30,338:INFO:plot_model(plot=confusion_mtrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, system=True)
2023-04-04 12:40:30,338:INFO:Checking exceptions
2023-04-04 12:41:33,630:INFO:Initializing plot_model()
2023-04-04 12:41:33,631:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, system=True)
2023-04-04 12:41:33,631:INFO:Checking exceptions
2023-04-04 12:41:34,030:INFO:Preloading libraries
2023-04-04 12:41:34,041:INFO:Copying training dataset
2023-04-04 12:41:34,041:INFO:Plot type: confusion_matrix
2023-04-04 12:41:36,390:INFO:Fitting Model
2023-04-04 12:41:36,393:INFO:Scoring test/hold-out set
2023-04-04 12:41:37,287:INFO:Visual Rendered Successfully
2023-04-04 12:41:37,406:INFO:plot_model() successfully completed......................................
2023-04-04 12:42:04,379:INFO:Initializing plot_model()
2023-04-04 12:42:04,380:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, system=True)
2023-04-04 12:42:04,380:INFO:Checking exceptions
2023-04-04 12:42:04,656:INFO:Preloading libraries
2023-04-04 12:42:04,665:INFO:Copying training dataset
2023-04-04 12:42:04,665:INFO:Plot type: feature
2023-04-04 12:42:04,666:WARNING:No coef_ found. Trying feature_importances_
2023-04-04 12:42:05,531:INFO:Saving 'Feature Importance.png'
2023-04-04 12:42:05,607:INFO:Visual Rendered Successfully
2023-04-04 12:42:05,670:INFO:plot_model() successfully completed......................................
2023-04-04 12:42:05,671:INFO:Initializing plot_model()
2023-04-04 12:42:05,671:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, system=True)
2023-04-04 12:42:05,671:INFO:Checking exceptions
2023-04-04 12:42:05,896:INFO:Preloading libraries
2023-04-04 12:42:05,910:INFO:Copying training dataset
2023-04-04 12:42:05,910:INFO:Plot type: auc
2023-04-04 12:42:08,172:INFO:Fitting Model
2023-04-04 12:42:08,176:INFO:Scoring test/hold-out set
2023-04-04 12:42:09,065:INFO:Saving 'AUC.png'
2023-04-04 12:42:09,166:INFO:Visual Rendered Successfully
2023-04-04 12:42:09,241:INFO:plot_model() successfully completed......................................
2023-04-04 12:42:09,242:INFO:Initializing plot_model()
2023-04-04 12:42:09,242:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, system=True)
2023-04-04 12:42:09,242:INFO:Checking exceptions
2023-04-04 12:42:09,465:INFO:Preloading libraries
2023-04-04 12:42:09,481:INFO:Copying training dataset
2023-04-04 12:42:09,481:INFO:Plot type: confusion_matrix
2023-04-04 12:42:11,731:INFO:Fitting Model
2023-04-04 12:42:11,733:INFO:Scoring test/hold-out set
2023-04-04 12:42:12,564:INFO:Saving 'Confusion Matrix.png'
2023-04-04 12:42:12,620:INFO:Visual Rendered Successfully
2023-04-04 12:42:12,704:INFO:plot_model() successfully completed......................................
2023-04-04 12:58:07,211:INFO:Initializing finalize_model()
2023-04-04 12:58:07,212:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-04 12:58:07,213:INFO:Finalizing LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-04 12:58:07,850:INFO:Initializing create_model()
2023-04-04 12:58:07,850:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcee4bd7c70>, estimator=LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-04 12:58:07,850:INFO:Checking exceptions
2023-04-04 12:58:07,854:INFO:Importing libraries
2023-04-04 12:58:07,855:INFO:Copying training dataset
2023-04-04 12:58:07,957:INFO:Defining folds
2023-04-04 12:58:07,957:INFO:Declaring metric variables
2023-04-04 12:58:07,958:INFO:Importing untrained model
2023-04-04 12:58:07,958:INFO:Declaring custom model
2023-04-04 12:58:07,959:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-04 12:58:07,997:INFO:Cross validation set to False
2023-04-04 12:58:07,997:INFO:Fitting Model
2023-04-04 12:58:49,042:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 13:00:03,003:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2023-04-04 13:00:03,003:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2023-04-04 13:00:03,003:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
2023-04-04 13:00:28,608:INFO:Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['hour_of_day',
                                             'avg_last_rrc_measurement_earfcn',
                                             'num_distinct_imsi',
                                             'mute_call_gap_indicator',
                                             'num_mute_calls', 'avg_cqi',
                                             'min_cqi', 'max_cqi', 'p05_cqi',
                                             'p10_cqi', 'p50_cqi', 'p90_cqi',
                                             'p95_cq...
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.2,
                                max_depth=-1, min_child_samples=21,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=290, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=5016,
                                reg_alpha=0.4, reg_lambda=0.01, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-04-04 13:00:28,608:INFO:create_model() successfully completed......................................
2023-04-04 13:00:28,738:INFO:_master_model_container: 10
2023-04-04 13:00:28,738:INFO:_display_container: 4
2023-04-04 13:00:28,746:INFO:Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['hour_of_day',
                                             'avg_last_rrc_measurement_earfcn',
                                             'num_distinct_imsi',
                                             'mute_call_gap_indicator',
                                             'num_mute_calls', 'avg_cqi',
                                             'min_cqi', 'max_cqi', 'p05_cqi',
                                             'p10_cqi', 'p50_cqi', 'p90_cqi',
                                             'p95_cq...
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.2,
                                max_depth=-1, min_child_samples=21,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=290, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=5016,
                                reg_alpha=0.4, reg_lambda=0.01, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-04-04 13:00:28,746:INFO:finalize_model() successfully completed......................................
2023-04-04 13:14:49,706:INFO:Initializing save_model()
2023-04-04 13:14:49,706:INFO:save_model(model=LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), model_name=/Users/raj2.gaurav/Desktop/Git/Causal_Model/07. Model/Light Gradient Boosting Machine/Model_Results/Model_objects/lightgbm, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['hour_of_day',
                                             'avg_last_rrc_measurement_earfcn',
                                             'num_distinct_imsi',
                                             'mute_call_gap_indicator',
                                             'num_mute_calls', 'avg_cqi',
                                             'min_cqi', 'max_cqi', 'p05_cqi',
                                             'p10_cqi', 'p50_cqi', 'p90_cqi',
                                             'p95_cq...
                                                               n_jobs=1,
                                                               random_state=5016,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-04 13:14:49,707:INFO:Adding model into prep_pipe
2023-04-04 13:14:49,789:INFO:/Users/raj2.gaurav/Desktop/Git/Causal_Model/07. Model/Light Gradient Boosting Machine/Model_Results/Model_objects/lightgbm.pkl saved in current working directory
2023-04-04 13:14:49,797:INFO:Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['hour_of_day',
                                             'avg_last_rrc_measurement_earfcn',
                                             'num_distinct_imsi',
                                             'mute_call_gap_indicator',
                                             'num_mute_calls', 'avg_cqi',
                                             'min_cqi', 'max_cqi', 'p05_cqi',
                                             'p10_cqi', 'p50_cqi', 'p90_cqi',
                                             'p95_cq...
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.2,
                                max_depth=-1, min_child_samples=21,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=290, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=5016,
                                reg_alpha=0.4, reg_lambda=0.01, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-04-04 13:14:49,797:INFO:save_model() successfully completed......................................
2023-04-04 13:51:50,286:INFO:Initializing save_model()
2023-04-04 13:51:50,286:INFO:save_model(model=LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=290, n_jobs=-1, num_leaves=80, objective=None,
               random_state=5016, reg_alpha=0.4, reg_lambda=0.01, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), model_name=config.save_model_path/lightgbm, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['hour_of_day',
                                             'avg_last_rrc_measurement_earfcn',
                                             'num_distinct_imsi',
                                             'mute_call_gap_indicator',
                                             'num_mute_calls', 'avg_cqi',
                                             'min_cqi', 'max_cqi', 'p05_cqi',
                                             'p10_cqi', 'p50_cqi', 'p90_cqi',
                                             'p95_cq...
                                                               n_jobs=1,
                                                               random_state=5016,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-04 13:51:50,286:INFO:Adding model into prep_pipe
2023-04-04 14:06:39,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 14:06:39,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 14:06:39,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 14:06:39,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 14:06:40,326:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-04 14:06:48,173:INFO:PyCaret ClassificationExperiment
2023-04-04 14:06:48,174:INFO:Logging name: clf-default-name
2023-04-04 14:06:48,174:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-04 14:06:48,174:INFO:version 3.0.0
2023-04-04 14:06:48,174:INFO:Initializing setup()
2023-04-04 14:06:48,174:INFO:self.USI: 9c7b
2023-04-04 14:06:48,174:INFO:self._variable_keys: {'is_multiclass', '_available_plots', 'y_test', 'fold_groups_param', 'fix_imbalance', 'y_train', 'pipeline', 'idx', 'logging_param', 'seed', 'n_jobs_param', 'y', 'fold_generator', 'gpu_n_jobs_param', 'X', 'fold_shuffle_param', 'exp_id', 'memory', 'html_param', 'log_plots_param', 'gpu_param', 'X_train', 'USI', 'data', 'X_test', '_ml_usecase', 'target_param', 'exp_name_log'}
2023-04-04 14:06:48,174:INFO:Checking environment
2023-04-04 14:06:48,174:INFO:python_version: 3.9.13
2023-04-04 14:06:48,174:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-04-04 14:06:48,175:INFO:machine: x86_64
2023-04-04 14:06:48,175:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-04-04 14:06:48,175:INFO:Memory: svmem(total=17179869184, available=1353441280, percent=92.1, used=2193559552, free=26497024, active=1343123456, inactive=1311621120, wired=850436096)
2023-04-04 14:06:48,175:INFO:Physical Core: 10
2023-04-04 14:06:48,175:INFO:Logical Core: 10
2023-04-04 14:06:48,175:INFO:Checking libraries
2023-04-04 14:06:48,176:INFO:System:
2023-04-04 14:06:48,176:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-04-04 14:06:48,176:INFO:executable: /opt/anaconda3/bin/python
2023-04-04 14:06:48,176:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-04-04 14:06:48,176:INFO:PyCaret required dependencies:
2023-04-04 14:06:48,177:INFO:                 pip: 22.2.2
2023-04-04 14:06:48,177:INFO:          setuptools: 63.4.1
2023-04-04 14:06:48,177:INFO:             pycaret: 3.0.0
2023-04-04 14:06:48,177:INFO:             IPython: 7.31.1
2023-04-04 14:06:48,177:INFO:          ipywidgets: 7.6.5
2023-04-04 14:06:48,177:INFO:                tqdm: 4.64.1
2023-04-04 14:06:48,177:INFO:               numpy: 1.21.5
2023-04-04 14:06:48,177:INFO:              pandas: 1.4.4
2023-04-04 14:06:48,177:INFO:              jinja2: 2.11.3
2023-04-04 14:06:48,177:INFO:               scipy: 1.9.1
2023-04-04 14:06:48,177:INFO:              joblib: 1.2.0
2023-04-04 14:06:48,177:INFO:             sklearn: 1.0.2
2023-04-04 14:06:48,177:INFO:                pyod: 1.0.9
2023-04-04 14:06:48,178:INFO:            imblearn: 0.10.1
2023-04-04 14:06:48,178:INFO:   category_encoders: 2.6.0
2023-04-04 14:06:48,178:INFO:            lightgbm: 3.3.5
2023-04-04 14:06:48,178:INFO:               numba: 0.55.1
2023-04-04 14:06:48,178:INFO:            requests: 2.28.1
2023-04-04 14:06:48,178:INFO:          matplotlib: 3.5.2
2023-04-04 14:06:48,178:INFO:          scikitplot: 0.3.7
2023-04-04 14:06:48,178:INFO:         yellowbrick: 1.5
2023-04-04 14:06:48,178:INFO:              plotly: 5.9.0
2023-04-04 14:06:48,178:INFO:             kaleido: 0.2.1
2023-04-04 14:06:48,178:INFO:         statsmodels: 0.13.2
2023-04-04 14:06:48,179:INFO:              sktime: 0.16.1
2023-04-04 14:06:48,179:INFO:               tbats: 1.1.2
2023-04-04 14:06:48,179:INFO:            pmdarima: 2.0.3
2023-04-04 14:06:48,179:INFO:              psutil: 5.9.0
2023-04-04 14:06:48,179:INFO:PyCaret optional dependencies:
2023-04-04 14:06:48,234:INFO:                shap: Not installed
2023-04-04 14:06:48,234:INFO:           interpret: Not installed
2023-04-04 14:06:48,234:INFO:                umap: Not installed
2023-04-04 14:06:48,234:INFO:    pandas_profiling: Not installed
2023-04-04 14:06:48,234:INFO:  explainerdashboard: Not installed
2023-04-04 14:06:48,234:INFO:             autoviz: Not installed
2023-04-04 14:06:48,234:INFO:           fairlearn: Not installed
2023-04-04 14:06:48,234:INFO:             xgboost: Not installed
2023-04-04 14:06:48,234:INFO:            catboost: Not installed
2023-04-04 14:06:48,234:INFO:              kmodes: Not installed
2023-04-04 14:06:48,234:INFO:             mlxtend: Not installed
2023-04-04 14:06:48,234:INFO:       statsforecast: Not installed
2023-04-04 14:06:48,235:INFO:        tune_sklearn: Not installed
2023-04-04 14:06:48,235:INFO:                 ray: Not installed
2023-04-04 14:06:48,235:INFO:            hyperopt: Not installed
2023-04-04 14:06:48,235:INFO:              optuna: Not installed
2023-04-04 14:06:48,235:INFO:               skopt: Not installed
2023-04-04 14:06:48,235:INFO:              mlflow: Not installed
2023-04-04 14:06:48,235:INFO:              gradio: Not installed
2023-04-04 14:06:48,235:INFO:             fastapi: Not installed
2023-04-04 14:06:48,235:INFO:             uvicorn: Not installed
2023-04-04 14:06:48,235:INFO:              m2cgen: Not installed
2023-04-04 14:06:48,235:INFO:           evidently: Not installed
2023-04-04 14:06:48,235:INFO:               fugue: Not installed
2023-04-04 14:06:48,235:INFO:           streamlit: Not installed
2023-04-04 14:06:48,235:INFO:             prophet: Not installed
2023-04-04 14:06:48,235:INFO:None
2023-04-04 14:06:48,235:INFO:Set up data.
2023-04-04 14:06:50,107:INFO:Set up train/test split.
2023-04-04 14:06:50,862:INFO:Set up index.
2023-04-04 14:06:50,882:INFO:Set up folding strategy.
2023-04-04 14:06:50,882:INFO:Assigning column types.
2023-04-04 14:06:51,665:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-04 14:06:51,700:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-04 14:06:51,704:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-04 14:06:51,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-04 14:06:51,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-04 14:06:51,784:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-04 14:06:51,785:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-04 14:06:51,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-04 14:06:51,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-04 14:06:51,806:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-04 14:06:51,840:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-04 14:06:51,860:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-04 14:06:51,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-04 14:06:51,895:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-04 14:06:51,915:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-04 14:06:51,916:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-04 14:06:51,916:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-04 14:06:51,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-04 14:06:51,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-04 14:06:52,025:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-04 14:06:52,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-04 14:06:52,028:INFO:Preparing preprocessing pipeline...
2023-04-04 14:06:52,109:INFO:Set up simple imputation.
2023-04-04 14:06:52,339:INFO:Set up encoding of categorical features.
2023-04-04 14:06:52,343:INFO:Set up removing outliers.
2023-04-04 14:06:52,343:INFO:Set up imbalanced handling.
2023-04-04 14:06:52,343:INFO:Set up feature normalization.
2023-04-04 14:07:19,325:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:08:07,464:INFO:Finished creating preprocessing pipeline.
2023-04-04 14:08:07,471:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['hour_of_day',
                                             'avg_last_rrc_measurement_earfcn',
                                             'num_distinct_imsi',
                                             'mute_call_gap_indicator',
                                             'num_mute_calls', 'avg_cqi',
                                             'min_cqi', 'max_cqi', 'p05_cqi',
                                             'p10_cqi', 'p50_cqi', 'p90_cqi',
                                             'p95_cq...
                                                               n_jobs=1,
                                                               random_state=2593,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2023-04-04 14:08:07,471:INFO:Creating final display dataframe.
2023-04-04 14:08:31,380:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:09:25,115:INFO:Setup _display_container:                     Description             Value
0                    Session id              2593
1                        Target   Target_Variable
2                   Target type            Binary
3           Original data shape     (343124, 217)
4        Transformed data shape     (300214, 211)
5   Transformed train set shape     (197276, 211)
6    Transformed test set shape     (102938, 211)
7               Ignore features                 8
8              Numeric features               207
9          Categorical features                 1
10     Rows with missing values              0.0%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold               0.5
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            minmax
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              9c7b
2023-04-04 14:09:25,185:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-04 14:09:25,185:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-04 14:09:25,241:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-04 14:09:25,241:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-04 14:09:25,241:INFO:setup() successfully completed in 157.29s...............
2023-04-04 14:09:25,264:INFO:Initializing compare_models()
2023-04-04 14:09:25,264:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, include=['lr', 'dt', 'svm', 'rf', 'ada', 'gbc', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, 'include': ['lr', 'dt', 'svm', 'rf', 'ada', 'gbc', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-04 14:09:25,265:INFO:Checking exceptions
2023-04-04 14:09:25,664:INFO:Preparing display monitor
2023-04-04 14:09:25,726:INFO:Initializing Logistic Regression
2023-04-04 14:09:25,726:INFO:Total runtime is 5.817413330078125e-06 minutes
2023-04-04 14:09:25,728:INFO:SubProcess create_model() called ==================================
2023-04-04 14:09:25,729:INFO:Initializing create_model()
2023-04-04 14:09:25,729:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7ef3c299d0>, model_only=True, return_train_score=False, kwargs={})
2023-04-04 14:09:25,729:INFO:Checking exceptions
2023-04-04 14:09:25,729:INFO:Importing libraries
2023-04-04 14:09:25,729:INFO:Copying training dataset
2023-04-04 14:09:26,358:INFO:Defining folds
2023-04-04 14:09:26,358:INFO:Declaring metric variables
2023-04-04 14:09:26,361:INFO:Importing untrained model
2023-04-04 14:09:26,363:INFO:Logistic Regression Imported successfully
2023-04-04 14:09:26,366:INFO:Starting cross validation
2023-04-04 14:09:26,387:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-04 14:09:53,304:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:09:54,292:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:09:54,302:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:09:54,306:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:09:54,311:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:09:55,434:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:09:55,501:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:09:55,524:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:09:55,560:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:09:56,951:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:09:57,363:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:09:57,931:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:10:01,600:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:04,210:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:10:06,824:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:07,105:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:07,171:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:07,241:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:07,447:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:07,456:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:07,464:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:07,481:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:08,184:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:08,671:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:10:09,084:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:10:09,217:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:10:10,696:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:10:10,817:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:10:13,134:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:10:15,559:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:20,377:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:20,446:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:20,907:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:20,930:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:20,937:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:21,016:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:21,042:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:21,142:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:10:22,879:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:10:24,857:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:10:24,891:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:10:24,897:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:12:49,113:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:13:13,218:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:13:28,701:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:13:36,176:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:13:44,658:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:13:44,658:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:13:52,652:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:13:55,577:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:13:55,580:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:14:10,822:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:17:32,385:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:17:34,545:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:18:27,289:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:18:29,568:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:19:18,374:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:19:32,584:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:19:38,832:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:19:44,778:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:19:44,828:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:20:00,752:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:20:01,260:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:20:02,160:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:20:03,495:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:20:03,806:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:20:08,680:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 14:20:19,394:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:20:22,443:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:20:24,745:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:20:25,828:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:20:28,145:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:20:28,595:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:20:36,228:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:20:37,495:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:20:48,814:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:20:50,193:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 14:20:53,573:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:20:55,502:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-04 14:20:57,089:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 14:21:09,269:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:21:10,473:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:21:12,076:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:21:13,880:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 14:21:14,094:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:21:19,135:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:21:20,217:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:21:20,740:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:21:21,544:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:21:21,639:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:21:21,705:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:21:22,981:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:21:23,302:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:21:23,756:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:21:35,055:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 14:21:53,301:INFO:Calculating mean and std
2023-04-04 14:21:53,327:INFO:Creating metrics dataframe
2023-04-04 14:21:53,388:INFO:Uploading results into container
2023-04-04 14:21:53,389:INFO:Uploading model into container now
2023-04-04 14:21:53,393:INFO:_master_model_container: 1
2023-04-04 14:21:53,393:INFO:_display_container: 2
2023-04-04 14:21:53,395:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2593, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-04 14:21:53,395:INFO:create_model() successfully completed......................................
2023-04-04 14:21:53,860:INFO:SubProcess create_model() end ==================================
2023-04-04 14:21:53,860:INFO:Creating metrics dataframe
2023-04-04 14:21:53,867:INFO:Initializing Decision Tree Classifier
2023-04-04 14:21:53,867:INFO:Total runtime is 12.469025985399881 minutes
2023-04-04 14:21:53,870:INFO:SubProcess create_model() called ==================================
2023-04-04 14:21:53,870:INFO:Initializing create_model()
2023-04-04 14:21:53,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7ef3c299d0>, model_only=True, return_train_score=False, kwargs={})
2023-04-04 14:21:53,870:INFO:Checking exceptions
2023-04-04 14:21:53,870:INFO:Importing libraries
2023-04-04 14:21:53,871:INFO:Copying training dataset
2023-04-04 14:21:55,305:INFO:Defining folds
2023-04-04 14:21:55,306:INFO:Declaring metric variables
2023-04-04 14:21:55,308:INFO:Importing untrained model
2023-04-04 14:21:55,310:INFO:Decision Tree Classifier Imported successfully
2023-04-04 14:21:55,315:INFO:Starting cross validation
2023-04-04 14:21:55,405:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-04 14:22:03,419:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:22:04,063:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:22:04,105:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:22:15,700:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:15,767:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:15,778:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:16,019:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:16,296:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:16,562:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:17,665:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:17,819:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:18,506:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:18,510:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:20,823:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:22:20,873:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:22:21,028:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 4.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:22:24,280:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:24,897:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:26,700:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:27,376:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:27,434:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:27,528:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:27,597:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:29,321:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:29,361:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:29,421:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:22:30,592:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:22:30,589:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:22:31,186:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:33,455:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:22:34,220:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:22:34,380:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:22:35,439:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:22:38,821:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:39,483:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:39,920:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:40,542:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:41,976:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:42,663:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:42,702:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:45,601:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:22:45,625:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:22:48,513:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:48,709:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:48,733:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:22:48,908:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:49,414:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:49,630:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:49,650:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:22:52,691:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:23:06,063:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 14:23:10,975:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 14:23:15,474:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 14:23:18,601:INFO:Calculating mean and std
2023-04-04 14:23:18,611:INFO:Creating metrics dataframe
2023-04-04 14:23:18,643:INFO:Uploading results into container
2023-04-04 14:23:18,644:INFO:Uploading model into container now
2023-04-04 14:23:18,645:INFO:_master_model_container: 2
2023-04-04 14:23:18,645:INFO:_display_container: 2
2023-04-04 14:23:18,647:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2593, splitter='best')
2023-04-04 14:23:18,647:INFO:create_model() successfully completed......................................
2023-04-04 14:23:19,014:INFO:SubProcess create_model() end ==================================
2023-04-04 14:23:19,014:INFO:Creating metrics dataframe
2023-04-04 14:23:19,026:INFO:Initializing SVM - Linear Kernel
2023-04-04 14:23:19,026:INFO:Total runtime is 13.888340747356414 minutes
2023-04-04 14:23:19,028:INFO:SubProcess create_model() called ==================================
2023-04-04 14:23:19,029:INFO:Initializing create_model()
2023-04-04 14:23:19,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7ef3c299d0>, model_only=True, return_train_score=False, kwargs={})
2023-04-04 14:23:19,029:INFO:Checking exceptions
2023-04-04 14:23:19,029:INFO:Importing libraries
2023-04-04 14:23:19,029:INFO:Copying training dataset
2023-04-04 14:23:20,580:INFO:Defining folds
2023-04-04 14:23:20,581:INFO:Declaring metric variables
2023-04-04 14:23:20,583:INFO:Importing untrained model
2023-04-04 14:23:20,586:INFO:SVM - Linear Kernel Imported successfully
2023-04-04 14:23:20,591:INFO:Starting cross validation
2023-04-04 14:23:20,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-04 14:23:28,845:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:23:28,885:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:23:33,672:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:23:34,609:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:23:35,024:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:23:35,256:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:23:41,669:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:23:41,740:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:23:47,503:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:23:48,242:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:23:49,119:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:23:50,270:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:23:50,968:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:23:53,301:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:23:55,882:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 4.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:23:56,298:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:23:56,875:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:23:58,556:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:24:03,171:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 6.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:24:05,551:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 7.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:24:05,878:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:24:07,199:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:24:08,464:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:24:09,544:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:24:20,072:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:26:36,437:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:26:43,598:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:26:45,910:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:27:03,724:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:27:04,540:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:28:58,700:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:29:01,474:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:29:01,523:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:29:04,092:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:30:00,726:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:34:22,899:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:34:24,994:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:34:33,581:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:34:35,337:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:34:38,124:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:34:40,546:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:34:55,170:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:34:57,582:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:35:01,022:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:35:03,777:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:35:39,111:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:35:42,358:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:35:52,405:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 6.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:35:53,357:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:35:54,610:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:35:59,485:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:36:01,072:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:36:18,619:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:36:22,297:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:36:25,747:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 14:36:28,344:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-04 14:36:34,300:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:36:37,492:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:36:38,356:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:36:39,265:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:36:40,171:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:36:44,134:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-04 14:36:44,321:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:36:44,774:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-04 14:36:46,480:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:36:50,338:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:36:51,056:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-04 14:36:52,900:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:36:55,863:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:36:56,142:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-04 14:36:58,135:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-04 14:36:58,695:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:36:59,450:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:36:59,946:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-04 14:37:00,416:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:03,135:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-04 14:37:03,590:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-04 14:37:04,423:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 71, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 130, in _score
    return super()._score(
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 298, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 73, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/metaestimators.py", line 109, in __get__
    if not self.check(obj):
  File "/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py", line 1199, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-04 14:37:04,561:INFO:Calculating mean and std
2023-04-04 14:37:04,577:INFO:Creating metrics dataframe
2023-04-04 14:37:04,617:INFO:Uploading results into container
2023-04-04 14:37:04,620:INFO:Uploading model into container now
2023-04-04 14:37:04,623:INFO:_master_model_container: 3
2023-04-04 14:37:04,623:INFO:_display_container: 2
2023-04-04 14:37:04,625:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2593, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-04 14:37:04,625:INFO:create_model() successfully completed......................................
2023-04-04 14:37:05,043:INFO:SubProcess create_model() end ==================================
2023-04-04 14:37:05,043:INFO:Creating metrics dataframe
2023-04-04 14:37:05,055:INFO:Initializing Random Forest Classifier
2023-04-04 14:37:05,055:INFO:Total runtime is 27.65548592011134 minutes
2023-04-04 14:37:05,057:INFO:SubProcess create_model() called ==================================
2023-04-04 14:37:05,057:INFO:Initializing create_model()
2023-04-04 14:37:05,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7ef3c299d0>, model_only=True, return_train_score=False, kwargs={})
2023-04-04 14:37:05,057:INFO:Checking exceptions
2023-04-04 14:37:05,058:INFO:Importing libraries
2023-04-04 14:37:05,058:INFO:Copying training dataset
2023-04-04 14:37:06,434:INFO:Defining folds
2023-04-04 14:37:06,435:INFO:Declaring metric variables
2023-04-04 14:37:06,438:INFO:Importing untrained model
2023-04-04 14:37:06,439:INFO:Random Forest Classifier Imported successfully
2023-04-04 14:37:06,445:INFO:Starting cross validation
2023-04-04 14:37:06,527:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-04 14:37:10,118:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:11,045:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:11,142:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:11,719:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:11,959:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:24,845:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:25,202:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:25,458:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:26,149:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:26,337:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:26,487:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:26,923:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:26,934:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:27,488:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:27,873:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:28,330:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:31,647:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:31,700:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:32,426:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 4.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:32,977:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:33,444:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:34,952:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:35,872:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:36,224:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:36,365:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:37,559:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:37,740:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:37,827:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:37,998:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 7.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:38,049:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:39,624:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 6.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:40,210:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:40,758:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:41,453:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:41,637:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:41,867:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:45,080:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:45,818:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:47,951:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:50,045:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:50,322:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:50,936:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:51,040:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:51,373:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 8.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:51,489:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:51,606:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:53,283:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:53,984:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:54,015:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:37:55,004:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:56,074:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:56,110:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:37:58,043:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:38:04,511:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:38:05,142:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:38:06,387:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 6.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:38:06,576:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:38:06,828:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:38:07,749:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:38:07,910:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:38:08,443:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:38:10,994:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:38:13,280:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:38:50,969:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 14:39:09,180:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 14:39:41,059:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 14:40:03,620:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 14:40:04,906:INFO:Calculating mean and std
2023-04-04 14:40:04,925:INFO:Creating metrics dataframe
2023-04-04 14:40:04,959:INFO:Uploading results into container
2023-04-04 14:40:04,960:INFO:Uploading model into container now
2023-04-04 14:40:04,961:INFO:_master_model_container: 4
2023-04-04 14:40:04,961:INFO:_display_container: 2
2023-04-04 14:40:04,963:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2593, verbose=0, warm_start=False)
2023-04-04 14:40:04,963:INFO:create_model() successfully completed......................................
2023-04-04 14:40:05,444:INFO:SubProcess create_model() end ==================================
2023-04-04 14:40:05,444:INFO:Creating metrics dataframe
2023-04-04 14:40:05,455:INFO:Initializing Ada Boost Classifier
2023-04-04 14:40:05,455:INFO:Total runtime is 30.662148002783457 minutes
2023-04-04 14:40:05,457:INFO:SubProcess create_model() called ==================================
2023-04-04 14:40:05,457:INFO:Initializing create_model()
2023-04-04 14:40:05,457:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7ef3c299d0>, model_only=True, return_train_score=False, kwargs={})
2023-04-04 14:40:05,457:INFO:Checking exceptions
2023-04-04 14:40:05,457:INFO:Importing libraries
2023-04-04 14:40:05,458:INFO:Copying training dataset
2023-04-04 14:40:07,106:INFO:Defining folds
2023-04-04 14:40:07,106:INFO:Declaring metric variables
2023-04-04 14:40:07,108:INFO:Importing untrained model
2023-04-04 14:40:07,111:INFO:Ada Boost Classifier Imported successfully
2023-04-04 14:40:07,114:INFO:Starting cross validation
2023-04-04 14:40:07,209:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-04 14:40:11,460:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:40:14,983:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:40:15,582:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:40:21,452:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:40:21,502:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:40:21,841:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:40:30,049:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 7.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:31,905:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:32,040:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:32,103:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:32,124:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:33,600:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:34,209:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:34,212:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:34,214:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:35,084:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:38,440:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:40:39,317:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:40:39,317:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:40:40,687:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 6.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:41,744:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 4.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:40:42,688:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:40:45,497:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:45,584:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:45,674:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:49,596:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:51,842:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:40:52,950:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:53,349:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:54,231:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:54,256:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:54,842:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:40:57,450:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:40:57,470:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:43:11,175:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:43:13,656:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:43:58,704:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:44:01,710:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:44:03,810:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:44:12,249:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:44:17,788:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:44:17,786:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:44:23,864:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:44:39,445:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 14:51:49,761:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:51:51,331:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:52:22,635:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:52:24,139:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:53:41,987:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:53:45,047:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:53:48,559:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:53:50,472:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 6.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:53:52,489:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:54:20,285:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:54:26,107:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:54:28,635:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:54:30,003:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:54:30,084:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:54:31,505:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:54:31,748:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:54:37,849:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:54:38,976:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:54:39,174:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:54:40,496:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:54:41,930:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:54:43,153:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:54:49,539:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 6.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:54:50,911:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 6.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:54:51,604:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:55:31,214:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:55:31,402:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:55:32,637:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:55:34,356:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:55:34,807:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:55:34,893:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:55:36,906:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:55:36,959:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:55:36,992:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:55:38,334:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:55:38,466:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:55:38,734:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:55:39,488:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:55:41,061:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:55:41,217:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:55:43,275:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:56:24,535:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 14:56:48,783:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 14:57:42,476:INFO:Calculating mean and std
2023-04-04 14:57:42,502:INFO:Creating metrics dataframe
2023-04-04 14:57:42,549:INFO:Uploading results into container
2023-04-04 14:57:42,551:INFO:Uploading model into container now
2023-04-04 14:57:42,554:INFO:_master_model_container: 5
2023-04-04 14:57:42,554:INFO:_display_container: 2
2023-04-04 14:57:42,556:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=2593)
2023-04-04 14:57:42,556:INFO:create_model() successfully completed......................................
2023-04-04 14:57:43,018:INFO:SubProcess create_model() end ==================================
2023-04-04 14:57:43,018:INFO:Creating metrics dataframe
2023-04-04 14:57:43,032:INFO:Initializing Gradient Boosting Classifier
2023-04-04 14:57:43,033:INFO:Total runtime is 48.28844518264135 minutes
2023-04-04 14:57:43,035:INFO:SubProcess create_model() called ==================================
2023-04-04 14:57:43,035:INFO:Initializing create_model()
2023-04-04 14:57:43,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7ef3c299d0>, model_only=True, return_train_score=False, kwargs={})
2023-04-04 14:57:43,035:INFO:Checking exceptions
2023-04-04 14:57:43,035:INFO:Importing libraries
2023-04-04 14:57:43,036:INFO:Copying training dataset
2023-04-04 14:57:44,804:INFO:Defining folds
2023-04-04 14:57:44,805:INFO:Declaring metric variables
2023-04-04 14:57:44,807:INFO:Importing untrained model
2023-04-04 14:57:44,810:INFO:Gradient Boosting Classifier Imported successfully
2023-04-04 14:57:44,815:INFO:Starting cross validation
2023-04-04 14:57:44,904:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-04 14:57:52,447:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:58:06,442:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:06,581:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:06,617:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:06,622:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:06,662:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:06,905:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:07,505:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:12,347:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 4.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:58:13,361:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 4.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:58:14,839:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 4.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:58:15,330:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 4.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:58:18,967:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:18,969:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:18,969:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:19,029:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:19,080:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:19,761:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:19,832:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:19,856:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:19,912:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:19,934:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:22,354:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:58:23,192:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:58:23,514:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 14:58:31,863:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:32,257:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:32,517:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:32,787:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:32,872:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:33,085:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:33,108:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:33,142:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:33,327:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:33,335:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:42,017:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:42,831:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:43,789:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:43,813:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:43,819:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:43,938:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:44,119:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 14:58:44,222:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:08:11,550:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:08:16,152:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:08:18,805:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:08:28,726:INFO:Calculating mean and std
2023-04-04 15:08:28,738:INFO:Creating metrics dataframe
2023-04-04 15:08:28,791:INFO:Uploading results into container
2023-04-04 15:08:28,794:INFO:Uploading model into container now
2023-04-04 15:08:28,796:INFO:_master_model_container: 6
2023-04-04 15:08:28,796:INFO:_display_container: 2
2023-04-04 15:08:28,800:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='deviance', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2593, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-04 15:08:28,800:INFO:create_model() successfully completed......................................
2023-04-04 15:08:29,227:INFO:SubProcess create_model() end ==================================
2023-04-04 15:08:29,228:INFO:Creating metrics dataframe
2023-04-04 15:08:29,236:INFO:Initializing Light Gradient Boosting Machine
2023-04-04 15:08:29,236:INFO:Total runtime is 59.05850870211919 minutes
2023-04-04 15:08:29,238:INFO:SubProcess create_model() called ==================================
2023-04-04 15:08:29,238:INFO:Initializing create_model()
2023-04-04 15:08:29,239:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7ef3c299d0>, model_only=True, return_train_score=False, kwargs={})
2023-04-04 15:08:29,239:INFO:Checking exceptions
2023-04-04 15:08:29,239:INFO:Importing libraries
2023-04-04 15:08:29,239:INFO:Copying training dataset
2023-04-04 15:08:30,921:INFO:Defining folds
2023-04-04 15:08:30,921:INFO:Declaring metric variables
2023-04-04 15:08:30,924:INFO:Importing untrained model
2023-04-04 15:08:30,926:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-04 15:08:30,932:INFO:Starting cross validation
2023-04-04 15:08:31,025:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-04 15:08:41,135:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:08:41,141:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:08:42,691:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:08:55,717:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:08:55,836:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:08:55,935:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:08:56,336:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:08:56,351:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:08:56,358:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:08:56,609:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:08:56,730:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:08:57,981:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:08:59,316:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:09:00,538:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 4.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:09:01,423:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 4.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:09:01,775:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 5.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:09:03,591:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:09:12,852:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:09:12,957:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:09:12,985:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:09:13,010:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:09:13,112:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:09:13,161:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:09:13,161:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:09:13,262:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:09:14,022:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 7.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:11:43,195:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:11:45,264:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:11:50,901:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:11:55,881:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:12:05,920:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:12:09,762:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:12:23,036:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:12:27,957:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:12:54,940:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:13:09,658:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:15:14,271:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:15:15,611:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:15:33,687:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:15:50,985:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:16:20,007:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 7.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:16:27,902:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 6.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:16:27,932:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:16:29,471:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:16:29,728:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:16:43,966:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:16:48,505:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 7.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:16:50,020:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:16:54,061:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:17:01,981:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 9.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:17:20,767:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:17:21,838:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:17:23,710:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:17:25,351:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:17:26,142:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:17:29,078:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:17:31,852:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:17:32,756:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:17:34,790:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:17:35,279:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:17:39,293:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:17:51,728:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:17:51,911:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:17:58,152:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:17:59,959:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:18:01,703:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:18:03,179:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:18:05,494:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:18:05,540:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:18:06,197:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:18:07,621:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:18:08,763:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:18:09,411:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:18:11,706:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:18:14,771:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:18:29,315:INFO:Calculating mean and std
2023-04-04 15:18:29,337:INFO:Creating metrics dataframe
2023-04-04 15:18:29,384:INFO:Uploading results into container
2023-04-04 15:18:29,388:INFO:Uploading model into container now
2023-04-04 15:18:29,416:INFO:_master_model_container: 7
2023-04-04 15:18:29,417:INFO:_display_container: 2
2023-04-04 15:18:29,420:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2593, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-04 15:18:29,420:INFO:create_model() successfully completed......................................
2023-04-04 15:18:29,767:INFO:SubProcess create_model() end ==================================
2023-04-04 15:18:29,768:INFO:Creating metrics dataframe
2023-04-04 15:18:29,787:INFO:Initializing create_model()
2023-04-04 15:18:29,787:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2593, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-04 15:18:29,787:INFO:Checking exceptions
2023-04-04 15:18:29,789:INFO:Importing libraries
2023-04-04 15:18:29,790:INFO:Copying training dataset
2023-04-04 15:18:31,084:INFO:Defining folds
2023-04-04 15:18:31,085:INFO:Declaring metric variables
2023-04-04 15:18:31,085:INFO:Importing untrained model
2023-04-04 15:18:31,085:INFO:Declaring custom model
2023-04-04 15:18:31,085:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-04 15:18:31,187:INFO:Cross validation set to False
2023-04-04 15:18:31,187:INFO:Fitting Model
2023-04-04 15:18:57,632:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:19:55,717:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2593, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-04 15:19:55,718:INFO:create_model() successfully completed......................................
2023-04-04 15:19:55,850:INFO:_master_model_container: 7
2023-04-04 15:19:55,850:INFO:_display_container: 2
2023-04-04 15:19:55,850:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2593, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-04 15:19:55,851:INFO:compare_models() successfully completed......................................
2023-04-04 15:34:56,308:INFO:Initializing create_model()
2023-04-04 15:34:56,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-04 15:34:56,310:INFO:Checking exceptions
2023-04-04 15:34:56,342:INFO:Importing libraries
2023-04-04 15:34:56,343:INFO:Copying training dataset
2023-04-04 15:34:57,173:INFO:Defining folds
2023-04-04 15:34:57,173:INFO:Declaring metric variables
2023-04-04 15:34:57,175:INFO:Importing untrained model
2023-04-04 15:34:57,177:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-04 15:34:57,181:INFO:Starting cross validation
2023-04-04 15:34:57,210:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-04 15:35:13,806:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:35:14,876:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:35:42,456:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:35:42,471:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:35:42,718:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:35:42,852:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:35:43,300:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:36:25,496:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:36:25,660:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:37:03,583:INFO:Calculating mean and std
2023-04-04 15:37:03,604:INFO:Creating metrics dataframe
2023-04-04 15:37:03,645:INFO:Finalizing model
2023-04-04 15:37:10,740:INFO:Uploading results into container
2023-04-04 15:37:10,741:INFO:Uploading model into container now
2023-04-04 15:37:10,757:INFO:_master_model_container: 8
2023-04-04 15:37:10,757:INFO:_display_container: 3
2023-04-04 15:37:10,757:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2593, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-04 15:37:10,757:INFO:create_model() successfully completed......................................
2023-04-04 15:37:34,385:INFO:Initializing tune_model()
2023-04-04 15:37:34,386:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2593, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>)
2023-04-04 15:37:34,386:INFO:Checking exceptions
2023-04-04 15:37:35,238:INFO:Copying training dataset
2023-04-04 15:37:35,656:INFO:Checking base model
2023-04-04 15:37:35,656:INFO:Base model : Light Gradient Boosting Machine
2023-04-04 15:37:35,659:INFO:Declaring metric variables
2023-04-04 15:37:35,661:INFO:Defining Hyperparameters
2023-04-04 15:37:35,797:INFO:Tuning with n_jobs=-1
2023-04-04 15:37:35,797:INFO:Initializing RandomizedSearchCV
2023-04-04 15:37:44,942:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:37:45,752:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:37:45,826:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:37:45,960:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:37:46,193:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:37:48,780:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:37:57,211:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:37:57,231:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:38:04,906:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:38:05,504:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:38:08,498:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:38:09,303:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:38:09,590:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 7.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:38:10,296:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 11.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:38:10,703:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 8.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:38:10,798:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 10.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:38:15,598:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:38:15,880:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:38:28,444:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:38:34,318:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:38:35,372:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:38:36,456:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:38:39,846:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:38:39,964:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:38:41,287:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 4.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:38:41,404:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-04 15:38:42,424:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 4.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:38:43,813:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:38:45,384:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:38:46,911:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:38:47,054:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:38:48,702:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 5.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:38:50,618:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:38:50,896:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:38:51,878:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 4.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:38:51,895:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:38:54,152:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:38:55,754:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:38:59,081:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:39:05,302:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:39:06,616:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:39:08,273:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:39:08,340:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:39:08,863:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:39:08,948:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:39:09,418:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:39:10,853:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:39:13,087:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:39:13,193:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:39:14,620:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:39:16,459:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:39:16,919:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:39:20,187:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:39:20,194:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:39:20,224:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:39:20,349:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:39:22,330:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:39:23,118:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:39:23,136:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:39:23,599:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:39:25,638:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:39:25,653:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:39:25,665:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:39:40,514:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 6.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:40:46,582:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:40:56,973:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:41:04,479:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:41:08,272:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:41:09,247:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:41:09,478:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:41:14,504:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:41:27,677:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:41:54,340:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:42:02,063:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:43:24,099:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:43:44,000:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:43:45,073:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:43:48,600:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:43:49,440:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:43:51,478:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:43:53,736:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:44:03,297:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:44:13,107:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:44:32,819:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:44:40,505:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:44:42,518:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:44:46,519:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:44:47,743:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:44:48,757:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:44:49,166:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:44:50,571:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:44:50,798:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:44:53,599:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:44:55,342:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:44:57,826:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:44:59,102:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:01,051:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:45:03,154:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:03,284:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:12,653:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:16,080:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:16,973:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:17,620:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:45:17,684:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:45:18,737:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:45:21,215:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-04 15:45:22,091:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:45:24,494:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:25,217:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:45:25,260:WARNING:/opt/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(

2023-04-04 15:45:25,468:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:45:30,373:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:45:30,602:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:45:31,344:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:45:33,908:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:45:36,039:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:37,029:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:45:40,797:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-04 15:45:41,114:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:45:41,894:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:42,680:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-04 15:45:42,971:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:43,894:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:45,248:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:45:45,945:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:47,128:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:47,244:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:47,363:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:45:47,803:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-04 15:45:48,425:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:50,798:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:45:52,535:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:45:54,130:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:54,660:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:45:55,672:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:55,878:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:57,365:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:45:57,930:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:45:59,245:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:46:00,094:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:46:00,614:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 3.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:46:00,695:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:46:03,359:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:46:05,062:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:46:05,839:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:46:05,870:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:46:06,329:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:46:11,555:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-04 15:46:13,254:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:46:14,855:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:46:15,040:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:46:16,865:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 5.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:46:20,103:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:46:22,007:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 8.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:46:22,430:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:46:27,403:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 6.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:46:27,799:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:46:27,842:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 5.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:46:31,932:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:46:34,000:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 3.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:46:38,763:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 7.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:46:38,876:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:46:42,039:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:46:45,619:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-04 15:46:45,857:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:46:47,012:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:48:06,448:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:48:11,944:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:48:14,794:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:48:15,124:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:48:15,150:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:48:16,285:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:48:16,289:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:48:16,428:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:48:16,694:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:48:17,343:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:49:41,579:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:49:51,675:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:49:52,524:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:49:53,482:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:49:53,781:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:49:55,007:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:49:55,035:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:49:56,442:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:49:57,063:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:50:05,289:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 6.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:50:08,512:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 8.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:50:29,798:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:50:31,488:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:50:44,954:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:50:47,681:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:50:50,438:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:50:53,587:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:50:59,488:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 3.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:51:05,133:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:51:05,840:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:51:06,818:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:51:08,072:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:51:11,848:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:51:13,936:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:51:16,426:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:51:17,929:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:51:22,128:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:51:25,159:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-04 15:51:26,528:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:51:29,096:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:51:29,376:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:51:30,758:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:51:34,620:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:51:37,277:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:51:37,678:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-04 15:51:43,835:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 5.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:51:45,705:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 4.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:51:48,339:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:51:48,528:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:51:48,609:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:51:49,856:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:52:00,430:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:01,559:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:02,012:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:02,191:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:03,434:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:03,541:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:04,351:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:52:04,383:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:52:04,826:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:04,862:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:04,902:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:52:07,218:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:52:08,032:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:52:08,427:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:52:08,885:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 2.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:52:10,366:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:52:14,017:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:16,864:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:52:22,530:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-04 15:52:22,666:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:24,789:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:52:25,418:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:52:25,589:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:52:28,349:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:52:35,034:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:52:35,765:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:52:37,888:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:52:37,910:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:39,804:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:39,873:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:52:42,252:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 1.33s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:52:43,037:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:52:44,569:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:52:44,992:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:49,018:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:49,437:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:50,137:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:52:52,594:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 7.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:53,769:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 4.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:57,028:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:59,001:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:52:59,215:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:53:00,080:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 6.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:53:07,923:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-04 15:53:08,994:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:53:09,680:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:53:09,880:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 4.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:53:10,696:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:53:12,484:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 2.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:53:15,593:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-04 15:53:17,298:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:53:18,881:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-04 15:53:22,304:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-04 15:54:17,754:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:54:21,591:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:54:22,457:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:54:23,713:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:54:37,394:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:54:41,724:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:54:52,177:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:55:04,153:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:55:48,459:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:55:50,774:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 2.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:55:52,238:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:55:52,635:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 3.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:55:53,713:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:55:56,828:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:56:01,386:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:56:02,892:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:56:07,068:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:56:13,869:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:56:14,682:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-04 15:56:14,697:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:56:22,024:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:56:48,865:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 0.1, 'actual_estimator__num_leaves': 40, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 61, 'actual_estimator__learning_rate': 0.2, 'actual_estimator__feature_fraction': 0.7, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.9}
2023-04-04 15:56:48,891:INFO:Hyperparameter search completed
2023-04-04 15:56:48,894:INFO:SubProcess create_model() called ==================================
2023-04-04 15:56:48,903:INFO:Initializing create_model()
2023-04-04 15:56:48,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2593, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f7ed0725a00>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 0.1, 'num_leaves': 40, 'n_estimators': 150, 'min_split_gain': 0.1, 'min_child_samples': 61, 'learning_rate': 0.2, 'feature_fraction': 0.7, 'bagging_freq': 0, 'bagging_fraction': 0.9})
2023-04-04 15:56:48,903:INFO:Checking exceptions
2023-04-04 15:56:48,904:INFO:Importing libraries
2023-04-04 15:56:48,906:INFO:Copying training dataset
2023-04-04 15:56:50,449:INFO:Defining folds
2023-04-04 15:56:50,450:INFO:Declaring metric variables
2023-04-04 15:56:50,462:INFO:Importing untrained model
2023-04-04 15:56:50,462:INFO:Declaring custom model
2023-04-04 15:56:50,472:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-04 15:56:50,477:INFO:Starting cross validation
2023-04-04 15:56:50,585:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-04 15:56:53,256:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:56:54,099:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-04 15:56:59,543:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:57:00,294:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:57:03,620:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:57:03,824:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:57:03,969:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:57:06,115:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:57:07,852:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:57:36,548:INFO:Calculating mean and std
2023-04-04 15:57:36,566:INFO:Creating metrics dataframe
2023-04-04 15:57:36,586:INFO:Finalizing model
2023-04-04 15:58:02,604:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:59:04,263:INFO:Uploading results into container
2023-04-04 15:59:04,264:INFO:Uploading model into container now
2023-04-04 15:59:04,265:INFO:_master_model_container: 9
2023-04-04 15:59:04,265:INFO:_display_container: 4
2023-04-04 15:59:04,266:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=40, objective=None,
               random_state=2593, reg_alpha=0.1, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-04 15:59:04,266:INFO:create_model() successfully completed......................................
2023-04-04 15:59:04,600:INFO:SubProcess create_model() end ==================================
2023-04-04 15:59:04,600:INFO:choose_better activated
2023-04-04 15:59:04,602:INFO:SubProcess create_model() called ==================================
2023-04-04 15:59:04,603:INFO:Initializing create_model()
2023-04-04 15:59:04,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2593, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-04 15:59:04,603:INFO:Checking exceptions
2023-04-04 15:59:04,604:INFO:Importing libraries
2023-04-04 15:59:04,605:INFO:Copying training dataset
2023-04-04 15:59:05,303:INFO:Defining folds
2023-04-04 15:59:05,304:INFO:Declaring metric variables
2023-04-04 15:59:05,304:INFO:Importing untrained model
2023-04-04 15:59:05,304:INFO:Declaring custom model
2023-04-04 15:59:05,304:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-04 15:59:05,304:INFO:Starting cross validation
2023-04-04 15:59:05,333:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-04 15:59:11,428:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:59:13,535:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:59:14,120:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:59:16,176:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:59:18,690:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:238: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-04 15:59:40,198:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 15:59:43,811:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 16:00:41,404:INFO:Calculating mean and std
2023-04-04 16:00:41,405:INFO:Creating metrics dataframe
2023-04-04 16:00:41,410:INFO:Finalizing model
2023-04-04 16:00:54,737:INFO:Uploading results into container
2023-04-04 16:00:54,737:INFO:Uploading model into container now
2023-04-04 16:00:54,738:INFO:_master_model_container: 10
2023-04-04 16:00:54,738:INFO:_display_container: 5
2023-04-04 16:00:54,738:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2593, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-04 16:00:54,738:INFO:create_model() successfully completed......................................
2023-04-04 16:00:54,866:INFO:SubProcess create_model() end ==================================
2023-04-04 16:00:54,867:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2593, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9915
2023-04-04 16:00:54,867:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=40, objective=None,
               random_state=2593, reg_alpha=0.1, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.9938
2023-04-04 16:00:54,868:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=40, objective=None,
               random_state=2593, reg_alpha=0.1, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-04-04 16:00:54,868:INFO:choose_better completed
2023-04-04 16:00:54,880:INFO:_master_model_container: 10
2023-04-04 16:00:54,880:INFO:_display_container: 4
2023-04-04 16:00:54,880:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=40, objective=None,
               random_state=2593, reg_alpha=0.1, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-04 16:00:54,880:INFO:tune_model() successfully completed......................................
2023-04-04 16:27:22,668:INFO:Initializing plot_model()
2023-04-04 16:27:22,673:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=40, objective=None,
               random_state=2593, reg_alpha=0.1, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, system=True)
2023-04-04 16:27:22,674:INFO:Checking exceptions
2023-04-04 16:27:23,083:INFO:Preloading libraries
2023-04-04 16:27:23,098:INFO:Copying training dataset
2023-04-04 16:27:23,098:INFO:Plot type: feature
2023-04-04 16:27:23,100:WARNING:No coef_ found. Trying feature_importances_
2023-04-04 16:27:45,856:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 16:28:33,522:INFO:Saving 'Feature Importance.png'
2023-04-04 16:28:33,644:INFO:Visual Rendered Successfully
2023-04-04 16:28:33,738:INFO:plot_model() successfully completed......................................
2023-04-04 16:28:33,739:INFO:Initializing plot_model()
2023-04-04 16:28:33,739:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=40, objective=None,
               random_state=2593, reg_alpha=0.1, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, system=True)
2023-04-04 16:28:33,739:INFO:Checking exceptions
2023-04-04 16:28:33,944:INFO:Preloading libraries
2023-04-04 16:28:33,955:INFO:Copying training dataset
2023-04-04 16:28:33,955:INFO:Plot type: auc
2023-04-04 16:28:37,899:INFO:Fitting Model
2023-04-04 16:28:37,903:INFO:Scoring test/hold-out set
2023-04-04 16:28:38,857:INFO:Saving 'AUC.png'
2023-04-04 16:28:38,957:INFO:Visual Rendered Successfully
2023-04-04 16:28:39,033:INFO:plot_model() successfully completed......................................
2023-04-04 16:28:39,033:INFO:Initializing plot_model()
2023-04-04 16:28:39,033:INFO:plot_model(plot=confsuion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=40, objective=None,
               random_state=2593, reg_alpha=0.1, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, system=True)
2023-04-04 16:28:39,033:INFO:Checking exceptions
2023-04-04 16:32:10,929:INFO:Initializing plot_model()
2023-04-04 16:32:10,930:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=40, objective=None,
               random_state=2593, reg_alpha=0.1, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, system=True)
2023-04-04 16:32:10,930:INFO:Checking exceptions
2023-04-04 16:32:11,202:INFO:Preloading libraries
2023-04-04 16:32:11,209:INFO:Copying training dataset
2023-04-04 16:32:11,209:INFO:Plot type: feature
2023-04-04 16:32:11,210:WARNING:No coef_ found. Trying feature_importances_
2023-04-04 16:32:12,055:INFO:Saving 'Feature Importance.png'
2023-04-04 16:32:12,139:INFO:Visual Rendered Successfully
2023-04-04 16:32:12,200:INFO:plot_model() successfully completed......................................
2023-04-04 16:32:12,201:INFO:Initializing plot_model()
2023-04-04 16:32:12,201:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=40, objective=None,
               random_state=2593, reg_alpha=0.1, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, system=True)
2023-04-04 16:32:12,201:INFO:Checking exceptions
2023-04-04 16:32:12,430:INFO:Preloading libraries
2023-04-04 16:32:12,436:INFO:Copying training dataset
2023-04-04 16:32:12,437:INFO:Plot type: auc
2023-04-04 16:32:14,676:INFO:Fitting Model
2023-04-04 16:32:14,680:INFO:Scoring test/hold-out set
2023-04-04 16:32:15,647:INFO:Saving 'AUC.png'
2023-04-04 16:32:15,745:INFO:Visual Rendered Successfully
2023-04-04 16:32:15,821:INFO:plot_model() successfully completed......................................
2023-04-04 16:32:15,821:INFO:Initializing plot_model()
2023-04-04 16:32:15,821:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=40, objective=None,
               random_state=2593, reg_alpha=0.1, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, system=True)
2023-04-04 16:32:15,821:INFO:Checking exceptions
2023-04-04 16:32:16,042:INFO:Preloading libraries
2023-04-04 16:32:16,052:INFO:Copying training dataset
2023-04-04 16:32:16,052:INFO:Plot type: confusion_matrix
2023-04-04 16:32:18,295:INFO:Fitting Model
2023-04-04 16:32:18,297:INFO:Scoring test/hold-out set
2023-04-04 16:32:19,260:INFO:Saving 'Confusion Matrix.png'
2023-04-04 16:32:19,315:INFO:Visual Rendered Successfully
2023-04-04 16:32:19,391:INFO:plot_model() successfully completed......................................
2023-04-04 16:34:22,747:INFO:Initializing finalize_model()
2023-04-04 16:34:22,747:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=40, objective=None,
               random_state=2593, reg_alpha=0.1, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-04-04 16:34:22,748:INFO:Finalizing LGBMClassifier(bagging_fraction=0.9, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=40, objective=None,
               random_state=2593, reg_alpha=0.1, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-04 16:34:23,368:INFO:Initializing create_model()
2023-04-04 16:34:23,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ef3f97ac0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=40, objective=None,
               random_state=2593, reg_alpha=0.1, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-04-04 16:34:23,368:INFO:Checking exceptions
2023-04-04 16:34:23,372:INFO:Importing libraries
2023-04-04 16:34:23,373:INFO:Copying training dataset
2023-04-04 16:34:23,464:INFO:Defining folds
2023-04-04 16:34:23,464:INFO:Declaring metric variables
2023-04-04 16:34:23,465:INFO:Importing untrained model
2023-04-04 16:34:23,465:INFO:Declaring custom model
2023-04-04 16:34:23,466:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-04 16:34:23,502:INFO:Cross validation set to False
2023-04-04 16:34:23,502:INFO:Fitting Model
2023-04-04 16:35:00,852:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-04 16:36:15,711:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-04-04 16:36:15,712:INFO:[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
2023-04-04 16:36:15,712:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-04-04 16:36:30,606:INFO:Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['hour_of_day',
                                             'avg_last_rrc_measurement_earfcn',
                                             'num_distinct_imsi',
                                             'mute_call_gap_indicator',
                                             'num_mute_calls', 'avg_cqi',
                                             'min_cqi', 'max_cqi', 'p05_cqi',
                                             'p10_cqi', 'p50_cqi', 'p90_cqi',
                                             'p95_cq...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.7,
                                importance_type='split', learning_rate=0.2,
                                max_depth=-1, min_child_samples=61,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=150, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=2593,
                                reg_alpha=0.1, reg_lambda=3, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-04-04 16:36:30,606:INFO:create_model() successfully completed......................................
2023-04-04 16:36:30,736:INFO:_master_model_container: 10
2023-04-04 16:36:30,736:INFO:_display_container: 4
2023-04-04 16:36:30,743:INFO:Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['hour_of_day',
                                             'avg_last_rrc_measurement_earfcn',
                                             'num_distinct_imsi',
                                             'mute_call_gap_indicator',
                                             'num_mute_calls', 'avg_cqi',
                                             'min_cqi', 'max_cqi', 'p05_cqi',
                                             'p10_cqi', 'p50_cqi', 'p90_cqi',
                                             'p95_cq...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.7,
                                importance_type='split', learning_rate=0.2,
                                max_depth=-1, min_child_samples=61,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=150, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=2593,
                                reg_alpha=0.1, reg_lambda=3, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-04-04 16:36:30,743:INFO:finalize_model() successfully completed......................................
2023-04-04 16:38:27,647:INFO:Initializing save_model()
2023-04-04 16:38:27,647:INFO:save_model(model=LGBMClassifier(bagging_fraction=0.9, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=40, objective=None,
               random_state=2593, reg_alpha=0.1, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), model_name=f'/Users/raj2.gaurav/Desktop/Git/Causal_Model/07. Model/{model_name}/Model_Results/Model_Objects'/lightgbm, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['hour_of_day',
                                             'avg_last_rrc_measurement_earfcn',
                                             'num_distinct_imsi',
                                             'mute_call_gap_indicator',
                                             'num_mute_calls', 'avg_cqi',
                                             'min_cqi', 'max_cqi', 'p05_cqi',
                                             'p10_cqi', 'p50_cqi', 'p90_cqi',
                                             'p95_cq...
                                                               n_jobs=1,
                                                               random_state=2593,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-04 16:38:27,648:INFO:Adding model into prep_pipe
2023-04-04 16:38:56,196:INFO:Initializing save_model()
2023-04-04 16:38:56,196:INFO:save_model(model=LGBMClassifier(bagging_fraction=0.9, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.7,
               importance_type='split', learning_rate=0.2, max_depth=-1,
               min_child_samples=61, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=150, n_jobs=-1, num_leaves=40, objective=None,
               random_state=2593, reg_alpha=0.1, reg_lambda=3, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), model_name=/Users/raj2.gaurav/Desktop/Git/Causal_Model/07. Model/Light Gradient Boosting Machine/Model_Results/Model_Objects/lightgbm, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['hour_of_day',
                                             'avg_last_rrc_measurement_earfcn',
                                             'num_distinct_imsi',
                                             'mute_call_gap_indicator',
                                             'num_mute_calls', 'avg_cqi',
                                             'min_cqi', 'max_cqi', 'p05_cqi',
                                             'p10_cqi', 'p50_cqi', 'p90_cqi',
                                             'p95_cq...
                                                               n_jobs=1,
                                                               random_state=2593,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-04 16:38:56,196:INFO:Adding model into prep_pipe
2023-04-04 16:38:56,288:INFO:/Users/raj2.gaurav/Desktop/Git/Causal_Model/07. Model/Light Gradient Boosting Machine/Model_Results/Model_Objects/lightgbm.pkl saved in current working directory
2023-04-04 16:38:56,296:INFO:Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['hour_of_day',
                                             'avg_last_rrc_measurement_earfcn',
                                             'num_distinct_imsi',
                                             'mute_call_gap_indicator',
                                             'num_mute_calls', 'avg_cqi',
                                             'min_cqi', 'max_cqi', 'p05_cqi',
                                             'p10_cqi', 'p50_cqi', 'p90_cqi',
                                             'p95_cq...
                                boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, feature_fraction=0.7,
                                importance_type='split', learning_rate=0.2,
                                max_depth=-1, min_child_samples=61,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=150, n_jobs=-1, num_leaves=40,
                                objective=None, random_state=2593,
                                reg_alpha=0.1, reg_lambda=3, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-04-04 16:38:56,296:INFO:save_model() successfully completed......................................
2023-04-04 17:35:32,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:35:32,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:35:32,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:35:32,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:35:32,937:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-04 17:41:16,168:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:41:16,168:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:41:16,168:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:41:16,168:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:41:16,530:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-04 17:42:20,642:INFO:Initializing load_model()
2023-04-04 17:42:20,643:INFO:load_model(model_name=/Users/raj2.gaurav/Desktop/Git/Causal_Model/07. Model/Light Gradient Boosting Machine/Model_Results/Model_Objects/lightgbm.pkl, platform=None, authentication=None, verbose=True)
2023-04-04 17:44:08,669:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:44:08,669:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:44:08,669:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:44:08,669:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:44:09,028:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-04 17:44:11,082:INFO:Initializing load_model()
2023-04-04 17:44:11,083:INFO:load_model(model_name=/Users/raj2.gaurav/Desktop/Git/Causal_Model/07. Model/Light Gradient Boosting Machine/Model_Results/Model_Objects/lightgbm, platform=None, authentication=None, verbose=True)
2023-04-04 17:44:24,079:INFO:Initializing predict_model()
2023-04-04 17:44:24,079:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fba74961940>, estimator=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['hour_of_day',
                                             'avg_last_rrc_measurement_earfcn',
                                             'num_distinct_imsi',
                                             'mute_call_gap_indicator',
                                             'num_mute_calls', 'avg_cqi',
                                             'min_cqi', 'max_cqi', 'p05_cqi',
                                             'p10_cqi', 'p50_cqi', 'p90_cqi',
                                             'p95_cqi',
                                             'sum_qci_1...
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=0,
                                feature_fraction=0.7, learning_rate=0.2,
                                min_child_samples=61, min_split_gain=0.1,
                                n_estimators=150, num_leaves=40,
                                random_state=2593, reg_alpha=0.1,
                                reg_lambda=3))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fba40b92af0>)
2023-04-04 17:44:24,079:INFO:Checking exceptions
2023-04-04 17:44:24,079:INFO:Preloading libraries
2023-04-04 17:44:24,079:INFO:Set up data.
2023-04-04 17:44:24,752:INFO:Set up index.
2023-04-04 17:50:44,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:50:44,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:50:44,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:50:44,453:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:50:44,872:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-04 17:50:46,531:INFO:Initializing load_model()
2023-04-04 17:50:46,531:INFO:load_model(model_name=/Users/raj2.gaurav/Desktop/Git/Causal_Model/07. Model/Light Gradient Boosting Machine/Model_Results/Model_Objects/lightgbm, platform=None, authentication=None, verbose=True)
2023-04-04 17:50:48,801:INFO:Initializing predict_model()
2023-04-04 17:50:48,801:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fac93864d30>, estimator=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['hour_of_day',
                                             'avg_last_rrc_measurement_earfcn',
                                             'num_distinct_imsi',
                                             'mute_call_gap_indicator',
                                             'num_mute_calls', 'avg_cqi',
                                             'min_cqi', 'max_cqi', 'p05_cqi',
                                             'p10_cqi', 'p50_cqi', 'p90_cqi',
                                             'p95_cqi',
                                             'sum_qci_1...
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=0,
                                feature_fraction=0.7, learning_rate=0.2,
                                min_child_samples=61, min_split_gain=0.1,
                                n_estimators=150, num_leaves=40,
                                random_state=2593, reg_alpha=0.1,
                                reg_lambda=3))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fac93b3daf0>)
2023-04-04 17:50:48,802:INFO:Checking exceptions
2023-04-04 17:50:48,802:INFO:Preloading libraries
2023-04-04 17:50:48,802:INFO:Set up data.
2023-04-04 17:50:49,435:INFO:Set up index.
2023-04-04 17:51:48,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:51:48,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:51:48,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:51:48,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-04 17:51:49,075:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-04 17:51:49,364:INFO:Initializing load_model()
2023-04-04 17:51:49,364:INFO:load_model(model_name=/Users/raj2.gaurav/Desktop/Git/Causal_Model/07. Model/Light Gradient Boosting Machine/Model_Results/Model_Objects/lightgbm, platform=None, authentication=None, verbose=True)
2023-04-04 17:51:49,446:INFO:Initializing predict_model()
2023-04-04 17:51:49,446:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff262cb3eb0>, estimator=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['hour_of_day',
                                             'avg_last_rrc_measurement_earfcn',
                                             'num_distinct_imsi',
                                             'mute_call_gap_indicator',
                                             'num_mute_calls', 'avg_cqi',
                                             'min_cqi', 'max_cqi', 'p05_cqi',
                                             'p10_cqi', 'p50_cqi', 'p90_cqi',
                                             'p95_cqi',
                                             'sum_qci_1...
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=0,
                                feature_fraction=0.7, learning_rate=0.2,
                                min_child_samples=61, min_split_gain=0.1,
                                n_estimators=150, num_leaves=40,
                                random_state=2593, reg_alpha=0.1,
                                reg_lambda=3))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7ff262cb2550>)
2023-04-04 17:51:49,446:INFO:Checking exceptions
2023-04-04 17:51:49,446:INFO:Preloading libraries
2023-04-04 17:51:49,446:INFO:Set up data.
2023-04-04 17:51:50,090:INFO:Set up index.
2023-04-05 18:21:49,436:INFO:Initializing load_model()
2023-04-05 18:21:49,438:INFO:load_model(model_name=/Users/raj2.gaurav/Desktop/Git/Causal_Model/07. Model/Light Gradient Boosting Machine/Model_Results/Model_Objects/lightgbm, platform=None, authentication=None, verbose=True)
2023-04-24 15:28:54,618:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 15:28:54,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 15:28:54,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 15:28:54,625:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 15:28:55,180:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-24 15:29:08,611:INFO:PyCaret ClassificationExperiment
2023-04-24 15:29:08,612:INFO:Logging name: clf-default-name
2023-04-24 15:29:08,612:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-24 15:29:08,612:INFO:version 3.0.0
2023-04-24 15:29:08,612:INFO:Initializing setup()
2023-04-24 15:29:08,612:INFO:self.USI: f2ad
2023-04-24 15:29:08,612:INFO:self._variable_keys: {'_ml_usecase', 'exp_name_log', 'fix_imbalance', 'memory', 'seed', 'X_train', 'fold_shuffle_param', 'fold_generator', 'gpu_param', 'y_test', 'target_param', 'html_param', '_available_plots', 'X_test', 'y_train', 'USI', 'data', 'gpu_n_jobs_param', 'y', 'is_multiclass', 'pipeline', 'exp_id', 'n_jobs_param', 'logging_param', 'log_plots_param', 'X', 'fold_groups_param', 'idx'}
2023-04-24 15:29:08,612:INFO:Checking environment
2023-04-24 15:29:08,612:INFO:python_version: 3.9.13
2023-04-24 15:29:08,612:INFO:python_build: ('main', 'Aug 25 2022 18:29:29')
2023-04-24 15:29:08,612:INFO:machine: x86_64
2023-04-24 15:29:08,612:INFO:platform: macOS-10.16-x86_64-i386-64bit
2023-04-24 15:29:08,612:INFO:Memory: svmem(total=17179869184, available=1102577664, percent=93.6, used=2066046976, free=30089216, active=1075400704, inactive=1067868160, wired=990646272)
2023-04-24 15:29:08,612:INFO:Physical Core: 10
2023-04-24 15:29:08,612:INFO:Logical Core: 10
2023-04-24 15:29:08,612:INFO:Checking libraries
2023-04-24 15:29:08,612:INFO:System:
2023-04-24 15:29:08,612:INFO:    python: 3.9.13 (main, Aug 25 2022, 18:29:29)  [Clang 12.0.0 ]
2023-04-24 15:29:08,612:INFO:executable: /opt/anaconda3/bin/python
2023-04-24 15:29:08,612:INFO:   machine: macOS-10.16-x86_64-i386-64bit
2023-04-24 15:29:08,612:INFO:PyCaret required dependencies:
2023-04-24 15:29:08,612:INFO:                 pip: 22.2.2
2023-04-24 15:29:08,612:INFO:          setuptools: 63.4.1
2023-04-24 15:29:08,612:INFO:             pycaret: 3.0.0
2023-04-24 15:29:08,612:INFO:             IPython: 7.31.1
2023-04-24 15:29:08,612:INFO:          ipywidgets: 7.6.5
2023-04-24 15:29:08,612:INFO:                tqdm: 4.64.1
2023-04-24 15:29:08,613:INFO:               numpy: 1.21.5
2023-04-24 15:29:08,613:INFO:              pandas: 1.4.4
2023-04-24 15:29:08,613:INFO:              jinja2: 2.11.3
2023-04-24 15:29:08,613:INFO:               scipy: 1.9.1
2023-04-24 15:29:08,613:INFO:              joblib: 1.2.0
2023-04-24 15:29:08,613:INFO:             sklearn: 1.0.2
2023-04-24 15:29:08,613:INFO:                pyod: 1.0.9
2023-04-24 15:29:08,613:INFO:            imblearn: 0.10.1
2023-04-24 15:29:08,613:INFO:   category_encoders: 2.6.0
2023-04-24 15:29:08,613:INFO:            lightgbm: 3.3.5
2023-04-24 15:29:08,613:INFO:               numba: 0.55.1
2023-04-24 15:29:08,613:INFO:            requests: 2.28.1
2023-04-24 15:29:08,613:INFO:          matplotlib: 3.5.2
2023-04-24 15:29:08,613:INFO:          scikitplot: 0.3.7
2023-04-24 15:29:08,613:INFO:         yellowbrick: 1.5
2023-04-24 15:29:08,613:INFO:              plotly: 5.9.0
2023-04-24 15:29:08,613:INFO:             kaleido: 0.2.1
2023-04-24 15:29:08,613:INFO:         statsmodels: 0.13.2
2023-04-24 15:29:08,613:INFO:              sktime: 0.16.1
2023-04-24 15:29:08,613:INFO:               tbats: 1.1.2
2023-04-24 15:29:08,613:INFO:            pmdarima: 2.0.3
2023-04-24 15:29:08,613:INFO:              psutil: 5.9.0
2023-04-24 15:29:08,613:INFO:PyCaret optional dependencies:
2023-04-24 15:29:08,630:INFO:                shap: Not installed
2023-04-24 15:29:08,630:INFO:           interpret: Not installed
2023-04-24 15:29:08,630:INFO:                umap: Not installed
2023-04-24 15:29:08,630:INFO:    pandas_profiling: Not installed
2023-04-24 15:29:08,630:INFO:  explainerdashboard: Not installed
2023-04-24 15:29:08,630:INFO:             autoviz: Not installed
2023-04-24 15:29:08,630:INFO:           fairlearn: Not installed
2023-04-24 15:29:08,630:INFO:             xgboost: Not installed
2023-04-24 15:29:08,630:INFO:            catboost: Not installed
2023-04-24 15:29:08,630:INFO:              kmodes: Not installed
2023-04-24 15:29:08,630:INFO:             mlxtend: Not installed
2023-04-24 15:29:08,631:INFO:       statsforecast: Not installed
2023-04-24 15:29:08,631:INFO:        tune_sklearn: Not installed
2023-04-24 15:29:08,631:INFO:                 ray: Not installed
2023-04-24 15:29:08,631:INFO:            hyperopt: Not installed
2023-04-24 15:29:08,631:INFO:              optuna: Not installed
2023-04-24 15:29:08,631:INFO:               skopt: Not installed
2023-04-24 15:29:08,631:INFO:              mlflow: Not installed
2023-04-24 15:29:08,631:INFO:              gradio: Not installed
2023-04-24 15:29:08,631:INFO:             fastapi: Not installed
2023-04-24 15:29:08,631:INFO:             uvicorn: Not installed
2023-04-24 15:29:08,631:INFO:              m2cgen: Not installed
2023-04-24 15:29:08,631:INFO:           evidently: Not installed
2023-04-24 15:29:08,631:INFO:               fugue: Not installed
2023-04-24 15:29:08,631:INFO:           streamlit: Not installed
2023-04-24 15:29:08,631:INFO:             prophet: Not installed
2023-04-24 15:29:08,631:INFO:None
2023-04-24 15:29:08,631:INFO:Set up data.
2023-04-24 15:29:08,880:INFO:Set up train/test split.
2023-04-24 15:29:08,949:INFO:Set up index.
2023-04-24 15:29:08,949:INFO:Set up folding strategy.
2023-04-24 15:29:08,949:INFO:Assigning column types.
2023-04-24 15:29:08,959:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-24 15:29:08,992:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 15:29:08,995:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-24 15:29:09,021:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 15:29:09,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 15:29:09,074:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-24 15:29:09,075:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-24 15:29:09,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 15:29:09,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 15:29:09,095:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-24 15:29:09,127:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-24 15:29:09,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 15:29:09,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 15:29:09,180:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-24 15:29:09,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 15:29:09,201:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 15:29:09,201:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-24 15:29:09,254:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 15:29:09,254:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 15:29:09,367:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 15:29:09,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 15:29:09,369:INFO:Preparing preprocessing pipeline...
2023-04-24 15:29:09,372:INFO:Set up simple imputation.
2023-04-24 15:29:09,382:INFO:Set up encoding of categorical features.
2023-04-24 15:29:09,382:INFO:Set up removing outliers.
2023-04-24 15:29:09,382:INFO:Set up imbalanced handling.
2023-04-24 15:29:09,382:INFO:Set up feature normalization.
2023-04-24 15:29:11,139:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-24 15:29:14,403:INFO:Finished creating preprocessing pipeline.
2023-04-24 15:29:14,410:INFO:Pipeline: Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                                                               n_jobs=1,
                                                               random_state=8216,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False)
2023-04-24 15:29:14,411:INFO:Creating final display dataframe.
2023-04-24 15:29:15,338:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-24 15:29:19,154:INFO:Setup _display_container:                     Description             Value
0                    Session id              8216
1                        Target      Credit_Score
2                   Target type            Binary
3           Original data shape      (100000, 28)
4        Transformed data shape       (87558, 49)
5   Transformed train set shape       (57558, 49)
6    Transformed test set shape       (30000, 49)
7               Ignore features                 5
8              Numeric features                13
9          Categorical features                 9
10     Rows with missing values             36.4%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17              Remove outliers              True
18           Outliers threshold               0.5
19                Fix imbalance              True
20         Fix imbalance method             SMOTE
21                    Normalize              True
22             Normalize method            minmax
23               Fold Generator   StratifiedKFold
24                  Fold Number                10
25                     CPU Jobs                -1
26                      Use GPU             False
27               Log Experiment             False
28              Experiment Name  clf-default-name
29                          USI              f2ad
2023-04-24 15:29:19,214:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 15:29:19,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 15:29:19,269:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 15:29:19,269:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-24 15:29:19,269:INFO:setup() successfully completed in 10.68s...............
2023-04-24 15:29:54,898:INFO:Initializing compare_models()
2023-04-24 15:29:54,899:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, include=['lr', 'dt', 'rf', 'ada', 'lightgbm'], fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, 'include': ['lr', 'dt', 'rf', 'ada', 'lightgbm'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-24 15:29:54,899:INFO:Checking exceptions
2023-04-24 15:29:54,925:INFO:Preparing display monitor
2023-04-24 15:29:54,984:INFO:Initializing Logistic Regression
2023-04-24 15:29:54,984:INFO:Total runtime is 4.74850336710612e-06 minutes
2023-04-24 15:29:54,987:INFO:SubProcess create_model() called ==================================
2023-04-24 15:29:54,987:INFO:Initializing create_model()
2023-04-24 15:29:54,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd73595efd0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 15:29:54,987:INFO:Checking exceptions
2023-04-24 15:29:54,988:INFO:Importing libraries
2023-04-24 15:29:54,988:INFO:Copying training dataset
2023-04-24 15:29:55,008:INFO:Defining folds
2023-04-24 15:29:55,008:INFO:Declaring metric variables
2023-04-24 15:29:55,010:INFO:Importing untrained model
2023-04-24 15:29:55,013:INFO:Logistic Regression Imported successfully
2023-04-24 15:29:55,018:INFO:Starting cross validation
2023-04-24 15:29:55,032:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:30:01,951:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-24 15:30:02,159:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-24 15:30:02,272:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-24 15:30:02,317:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-24 15:30:02,404:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-24 15:30:02,685:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-24 15:30:02,707:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-24 15:30:02,863:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-24 15:30:03,000:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-24 15:30:03,063:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-24 15:30:10,585:INFO:Calculating mean and std
2023-04-24 15:30:10,589:INFO:Creating metrics dataframe
2023-04-24 15:30:10,624:INFO:Uploading results into container
2023-04-24 15:30:10,625:INFO:Uploading model into container now
2023-04-24 15:30:10,626:INFO:_master_model_container: 1
2023-04-24 15:30:10,626:INFO:_display_container: 2
2023-04-24 15:30:10,626:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 15:30:10,627:INFO:create_model() successfully completed......................................
2023-04-24 15:30:10,750:INFO:SubProcess create_model() end ==================================
2023-04-24 15:30:10,750:INFO:Creating metrics dataframe
2023-04-24 15:30:10,756:INFO:Initializing Decision Tree Classifier
2023-04-24 15:30:10,756:INFO:Total runtime is 0.2628689130147298 minutes
2023-04-24 15:30:10,759:INFO:SubProcess create_model() called ==================================
2023-04-24 15:30:10,759:INFO:Initializing create_model()
2023-04-24 15:30:10,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd73595efd0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 15:30:10,759:INFO:Checking exceptions
2023-04-24 15:30:10,759:INFO:Importing libraries
2023-04-24 15:30:10,759:INFO:Copying training dataset
2023-04-24 15:30:10,783:INFO:Defining folds
2023-04-24 15:30:10,783:INFO:Declaring metric variables
2023-04-24 15:30:10,785:INFO:Importing untrained model
2023-04-24 15:30:10,788:INFO:Decision Tree Classifier Imported successfully
2023-04-24 15:30:10,793:INFO:Starting cross validation
2023-04-24 15:30:10,804:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:30:14,926:INFO:Calculating mean and std
2023-04-24 15:30:14,930:INFO:Creating metrics dataframe
2023-04-24 15:30:14,963:INFO:Uploading results into container
2023-04-24 15:30:14,968:INFO:Uploading model into container now
2023-04-24 15:30:14,969:INFO:_master_model_container: 2
2023-04-24 15:30:14,969:INFO:_display_container: 2
2023-04-24 15:30:14,970:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best')
2023-04-24 15:30:14,970:INFO:create_model() successfully completed......................................
2023-04-24 15:30:15,129:INFO:SubProcess create_model() end ==================================
2023-04-24 15:30:15,129:INFO:Creating metrics dataframe
2023-04-24 15:30:15,136:INFO:Initializing Random Forest Classifier
2023-04-24 15:30:15,136:INFO:Total runtime is 0.33586533466974894 minutes
2023-04-24 15:30:15,139:INFO:SubProcess create_model() called ==================================
2023-04-24 15:30:15,139:INFO:Initializing create_model()
2023-04-24 15:30:15,139:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd73595efd0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 15:30:15,139:INFO:Checking exceptions
2023-04-24 15:30:15,139:INFO:Importing libraries
2023-04-24 15:30:15,139:INFO:Copying training dataset
2023-04-24 15:30:15,198:INFO:Defining folds
2023-04-24 15:30:15,198:INFO:Declaring metric variables
2023-04-24 15:30:15,201:INFO:Importing untrained model
2023-04-24 15:30:15,204:INFO:Random Forest Classifier Imported successfully
2023-04-24 15:30:15,208:INFO:Starting cross validation
2023-04-24 15:30:15,222:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:30:17,630:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:231: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-24 15:30:30,552:INFO:Calculating mean and std
2023-04-24 15:30:30,562:INFO:Creating metrics dataframe
2023-04-24 15:30:30,618:INFO:Uploading results into container
2023-04-24 15:30:30,621:INFO:Uploading model into container now
2023-04-24 15:30:30,625:INFO:_master_model_container: 3
2023-04-24 15:30:30,626:INFO:_display_container: 2
2023-04-24 15:30:30,627:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False)
2023-04-24 15:30:30,627:INFO:create_model() successfully completed......................................
2023-04-24 15:30:30,787:INFO:SubProcess create_model() end ==================================
2023-04-24 15:30:30,787:INFO:Creating metrics dataframe
2023-04-24 15:30:30,793:INFO:Initializing Ada Boost Classifier
2023-04-24 15:30:30,793:INFO:Total runtime is 0.5968202312787374 minutes
2023-04-24 15:30:30,796:INFO:SubProcess create_model() called ==================================
2023-04-24 15:30:30,796:INFO:Initializing create_model()
2023-04-24 15:30:30,796:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd73595efd0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 15:30:30,796:INFO:Checking exceptions
2023-04-24 15:30:30,796:INFO:Importing libraries
2023-04-24 15:30:30,798:INFO:Copying training dataset
2023-04-24 15:30:30,868:INFO:Defining folds
2023-04-24 15:30:30,868:INFO:Declaring metric variables
2023-04-24 15:30:30,872:INFO:Importing untrained model
2023-04-24 15:30:30,874:INFO:Ada Boost Classifier Imported successfully
2023-04-24 15:30:30,879:INFO:Starting cross validation
2023-04-24 15:30:30,889:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:30:43,451:INFO:Calculating mean and std
2023-04-24 15:30:43,463:INFO:Creating metrics dataframe
2023-04-24 15:30:43,510:INFO:Uploading results into container
2023-04-24 15:30:43,511:INFO:Uploading model into container now
2023-04-24 15:30:43,511:INFO:_master_model_container: 4
2023-04-24 15:30:43,511:INFO:_display_container: 2
2023-04-24 15:30:43,512:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216)
2023-04-24 15:30:43,512:INFO:create_model() successfully completed......................................
2023-04-24 15:30:43,667:INFO:SubProcess create_model() end ==================================
2023-04-24 15:30:43,667:INFO:Creating metrics dataframe
2023-04-24 15:30:43,678:INFO:Initializing Light Gradient Boosting Machine
2023-04-24 15:30:43,678:INFO:Total runtime is 0.8115622480710347 minutes
2023-04-24 15:30:43,680:INFO:SubProcess create_model() called ==================================
2023-04-24 15:30:43,680:INFO:Initializing create_model()
2023-04-24 15:30:43,681:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd73595efd0>, model_only=True, return_train_score=False, kwargs={})
2023-04-24 15:30:43,681:INFO:Checking exceptions
2023-04-24 15:30:43,681:INFO:Importing libraries
2023-04-24 15:30:43,681:INFO:Copying training dataset
2023-04-24 15:30:43,710:INFO:Defining folds
2023-04-24 15:30:43,710:INFO:Declaring metric variables
2023-04-24 15:30:43,714:INFO:Importing untrained model
2023-04-24 15:30:43,718:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 15:30:43,723:INFO:Starting cross validation
2023-04-24 15:30:43,735:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:30:47,908:INFO:Calculating mean and std
2023-04-24 15:30:47,909:INFO:Creating metrics dataframe
2023-04-24 15:30:47,942:INFO:Uploading results into container
2023-04-24 15:30:47,943:INFO:Uploading model into container now
2023-04-24 15:30:47,943:INFO:_master_model_container: 5
2023-04-24 15:30:47,943:INFO:_display_container: 2
2023-04-24 15:30:47,944:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-24 15:30:47,944:INFO:create_model() successfully completed......................................
2023-04-24 15:30:48,003:INFO:SubProcess create_model() end ==================================
2023-04-24 15:30:48,003:INFO:Creating metrics dataframe
2023-04-24 15:30:48,017:INFO:Initializing create_model()
2023-04-24 15:30:48,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 15:30:48,018:INFO:Checking exceptions
2023-04-24 15:30:48,019:INFO:Importing libraries
2023-04-24 15:30:48,020:INFO:Copying training dataset
2023-04-24 15:30:48,038:INFO:Defining folds
2023-04-24 15:30:48,038:INFO:Declaring metric variables
2023-04-24 15:30:48,038:INFO:Importing untrained model
2023-04-24 15:30:48,038:INFO:Declaring custom model
2023-04-24 15:30:48,038:INFO:Random Forest Classifier Imported successfully
2023-04-24 15:30:48,045:INFO:Cross validation set to False
2023-04-24 15:30:48,045:INFO:Fitting Model
2023-04-24 15:30:50,790:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False)
2023-04-24 15:30:50,790:INFO:create_model() successfully completed......................................
2023-04-24 15:30:50,863:INFO:_master_model_container: 5
2023-04-24 15:30:50,863:INFO:_display_container: 2
2023-04-24 15:30:50,863:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False)
2023-04-24 15:30:50,863:INFO:compare_models() successfully completed......................................
2023-04-24 15:33:55,213:INFO:Initializing create_model()
2023-04-24 15:33:55,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 15:33:55,237:INFO:Checking exceptions
2023-04-24 15:33:55,265:INFO:Importing libraries
2023-04-24 15:33:55,266:INFO:Copying training dataset
2023-04-24 15:33:55,296:INFO:Defining folds
2023-04-24 15:33:55,297:INFO:Declaring metric variables
2023-04-24 15:33:55,299:INFO:Importing untrained model
2023-04-24 15:33:55,301:INFO:Random Forest Classifier Imported successfully
2023-04-24 15:33:55,307:INFO:Starting cross validation
2023-04-24 15:33:55,330:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:33:57,488:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-24 15:33:57,491:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-24 15:33:57,505:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-24 15:33:57,517:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-24 15:33:57,540:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-04-24 15:34:06,712:INFO:Calculating mean and std
2023-04-24 15:34:06,715:INFO:Creating metrics dataframe
2023-04-24 15:34:06,722:INFO:Finalizing model
2023-04-24 15:34:07,532:INFO:Uploading results into container
2023-04-24 15:34:07,533:INFO:Uploading model into container now
2023-04-24 15:34:07,539:INFO:_master_model_container: 6
2023-04-24 15:34:07,539:INFO:_display_container: 3
2023-04-24 15:34:07,539:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False)
2023-04-24 15:34:07,539:INFO:create_model() successfully completed......................................
2023-04-24 15:34:35,031:INFO:Initializing tune_model()
2023-04-24 15:34:35,033:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 15:34:35,033:INFO:Checking exceptions
2023-04-24 15:34:35,079:INFO:Copying training dataset
2023-04-24 15:34:35,092:INFO:Checking base model
2023-04-24 15:34:35,092:INFO:Base model : Random Forest Classifier
2023-04-24 15:34:35,094:INFO:Declaring metric variables
2023-04-24 15:34:35,097:INFO:Defining Hyperparameters
2023-04-24 15:34:35,164:INFO:Tuning with n_jobs=-1
2023-04-24 15:34:35,164:INFO:Initializing RandomizedSearchCV
2023-04-24 15:34:53,629:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 15:34:53,644:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 15:34:56,053:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 15:34:57,346:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 15:34:57,492:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 15:35:09,042:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 15:35:14,656:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 15:35:18,577:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 15:35:21,004:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 15:35:22,122:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 15:35:23,884:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-24 15:35:24,035:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 15:35:24,806:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 15:35:31,472:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 15:35:32,056:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 15:35:34,994:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 15:35:35,203:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 15:35:38,453:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 15:35:39,088:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-24 15:35:40,636:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:108: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-04-24 15:35:41,563:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 15:35:51,478:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-04-24 15:35:53,564:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-24 15:36:18,348:INFO:best_params: {'actual_estimator__n_estimators': 220, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-04-24 15:36:18,353:INFO:Hyperparameter search completed
2023-04-24 15:36:18,354:INFO:SubProcess create_model() called ==================================
2023-04-24 15:36:18,355:INFO:Initializing create_model()
2023-04-24 15:36:18,355:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd740c2df70>, model_only=True, return_train_score=False, kwargs={'n_estimators': 220, 'min_samples_split': 9, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0001, 'max_features': 'log2', 'max_depth': 7, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-04-24 15:36:18,355:INFO:Checking exceptions
2023-04-24 15:36:18,355:INFO:Importing libraries
2023-04-24 15:36:18,355:INFO:Copying training dataset
2023-04-24 15:36:18,389:INFO:Defining folds
2023-04-24 15:36:18,389:INFO:Declaring metric variables
2023-04-24 15:36:18,393:INFO:Importing untrained model
2023-04-24 15:36:18,393:INFO:Declaring custom model
2023-04-24 15:36:18,397:INFO:Random Forest Classifier Imported successfully
2023-04-24 15:36:18,401:INFO:Starting cross validation
2023-04-24 15:36:18,418:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:36:20,096:INFO:Calculating mean and std
2023-04-24 15:36:20,097:INFO:Creating metrics dataframe
2023-04-24 15:36:20,101:INFO:Finalizing model
2023-04-24 15:36:22,623:INFO:Uploading results into container
2023-04-24 15:36:22,624:INFO:Uploading model into container now
2023-04-24 15:36:22,624:INFO:_master_model_container: 7
2023-04-24 15:36:22,624:INFO:_display_container: 4
2023-04-24 15:36:22,624:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=7, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0001,
                       min_samples_leaf=4, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=220,
                       n_jobs=-1, oob_score=False, random_state=8216, verbose=0,
                       warm_start=False)
2023-04-24 15:36:22,625:INFO:create_model() successfully completed......................................
2023-04-24 15:36:22,764:INFO:SubProcess create_model() end ==================================
2023-04-24 15:36:22,764:INFO:choose_better activated
2023-04-24 15:36:22,766:INFO:SubProcess create_model() called ==================================
2023-04-24 15:36:22,767:INFO:Initializing create_model()
2023-04-24 15:36:22,767:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 15:36:22,767:INFO:Checking exceptions
2023-04-24 15:36:22,768:INFO:Importing libraries
2023-04-24 15:36:22,768:INFO:Copying training dataset
2023-04-24 15:36:22,783:INFO:Defining folds
2023-04-24 15:36:22,783:INFO:Declaring metric variables
2023-04-24 15:36:22,783:INFO:Importing untrained model
2023-04-24 15:36:22,783:INFO:Declaring custom model
2023-04-24 15:36:22,784:INFO:Random Forest Classifier Imported successfully
2023-04-24 15:36:22,784:INFO:Starting cross validation
2023-04-24 15:36:22,791:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:36:24,249:INFO:Calculating mean and std
2023-04-24 15:36:24,250:INFO:Creating metrics dataframe
2023-04-24 15:36:24,253:INFO:Finalizing model
2023-04-24 15:36:24,856:INFO:Uploading results into container
2023-04-24 15:36:24,856:INFO:Uploading model into container now
2023-04-24 15:36:24,856:INFO:_master_model_container: 8
2023-04-24 15:36:24,857:INFO:_display_container: 5
2023-04-24 15:36:24,857:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False)
2023-04-24 15:36:24,857:INFO:create_model() successfully completed......................................
2023-04-24 15:36:24,921:INFO:SubProcess create_model() end ==================================
2023-04-24 15:36:24,922:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False) result for Accuracy is 0.879
2023-04-24 15:36:24,922:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=7, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0001,
                       min_samples_leaf=4, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=220,
                       n_jobs=-1, oob_score=False, random_state=8216, verbose=0,
                       warm_start=False) result for Accuracy is 0.87
2023-04-24 15:36:24,922:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False) is best model
2023-04-24 15:36:24,922:INFO:choose_better completed
2023-04-24 15:36:24,922:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-24 15:36:24,929:INFO:_master_model_container: 8
2023-04-24 15:36:24,929:INFO:_display_container: 4
2023-04-24 15:36:24,930:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False)
2023-04-24 15:36:24,930:INFO:tune_model() successfully completed......................................
2023-04-24 15:56:53,332:INFO:Initializing create_model()
2023-04-24 15:56:53,333:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=lr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 15:56:53,333:INFO:Checking exceptions
2023-04-24 15:56:53,360:INFO:Importing libraries
2023-04-24 15:56:53,361:INFO:Copying training dataset
2023-04-24 15:56:53,386:INFO:Defining folds
2023-04-24 15:56:53,386:INFO:Declaring metric variables
2023-04-24 15:56:53,389:INFO:Importing untrained model
2023-04-24 15:56:53,391:INFO:Logistic Regression Imported successfully
2023-04-24 15:56:53,396:INFO:Starting cross validation
2023-04-24 15:56:53,406:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:56:59,247:INFO:Calculating mean and std
2023-04-24 15:56:59,250:INFO:Creating metrics dataframe
2023-04-24 15:56:59,257:INFO:Finalizing model
2023-04-24 15:57:00,942:INFO:Uploading results into container
2023-04-24 15:57:00,942:INFO:Uploading model into container now
2023-04-24 15:57:00,948:INFO:_master_model_container: 9
2023-04-24 15:57:00,948:INFO:_display_container: 5
2023-04-24 15:57:00,948:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 15:57:00,948:INFO:create_model() successfully completed......................................
2023-04-24 15:57:01,127:INFO:Initializing tune_model()
2023-04-24 15:57:01,127:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 15:57:01,127:INFO:Checking exceptions
2023-04-24 15:57:01,149:INFO:Copying training dataset
2023-04-24 15:57:01,171:INFO:Checking base model
2023-04-24 15:57:01,171:INFO:Base model : Logistic Regression
2023-04-24 15:57:01,174:INFO:Declaring metric variables
2023-04-24 15:57:01,176:INFO:Defining Hyperparameters
2023-04-24 15:57:01,248:INFO:Tuning with n_jobs=-1
2023-04-24 15:57:01,248:INFO:Initializing RandomizedSearchCV
2023-04-24 15:57:14,688:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 0.041}
2023-04-24 15:57:14,691:INFO:Hyperparameter search completed
2023-04-24 15:57:14,691:INFO:SubProcess create_model() called ==================================
2023-04-24 15:57:14,692:INFO:Initializing create_model()
2023-04-24 15:57:14,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd740399790>, model_only=True, return_train_score=False, kwargs={'class_weight': {}, 'C': 0.041})
2023-04-24 15:57:14,692:INFO:Checking exceptions
2023-04-24 15:57:14,693:INFO:Importing libraries
2023-04-24 15:57:14,693:INFO:Copying training dataset
2023-04-24 15:57:14,721:INFO:Defining folds
2023-04-24 15:57:14,722:INFO:Declaring metric variables
2023-04-24 15:57:14,726:INFO:Importing untrained model
2023-04-24 15:57:14,726:INFO:Declaring custom model
2023-04-24 15:57:14,728:INFO:Logistic Regression Imported successfully
2023-04-24 15:57:14,732:INFO:Starting cross validation
2023-04-24 15:57:14,750:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:57:15,919:INFO:Calculating mean and std
2023-04-24 15:57:15,921:INFO:Creating metrics dataframe
2023-04-24 15:57:15,926:INFO:Finalizing model
2023-04-24 15:57:16,881:INFO:Uploading results into container
2023-04-24 15:57:16,882:INFO:Uploading model into container now
2023-04-24 15:57:16,882:INFO:_master_model_container: 10
2023-04-24 15:57:16,882:INFO:_display_container: 6
2023-04-24 15:57:16,882:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 15:57:16,883:INFO:create_model() successfully completed......................................
2023-04-24 15:57:17,007:INFO:SubProcess create_model() end ==================================
2023-04-24 15:57:17,007:INFO:choose_better activated
2023-04-24 15:57:17,010:INFO:SubProcess create_model() called ==================================
2023-04-24 15:57:17,011:INFO:Initializing create_model()
2023-04-24 15:57:17,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 15:57:17,011:INFO:Checking exceptions
2023-04-24 15:57:17,012:INFO:Importing libraries
2023-04-24 15:57:17,013:INFO:Copying training dataset
2023-04-24 15:57:17,027:INFO:Defining folds
2023-04-24 15:57:17,028:INFO:Declaring metric variables
2023-04-24 15:57:17,028:INFO:Importing untrained model
2023-04-24 15:57:17,028:INFO:Declaring custom model
2023-04-24 15:57:17,028:INFO:Logistic Regression Imported successfully
2023-04-24 15:57:17,028:INFO:Starting cross validation
2023-04-24 15:57:17,035:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:57:18,231:INFO:Calculating mean and std
2023-04-24 15:57:18,234:INFO:Creating metrics dataframe
2023-04-24 15:57:18,247:INFO:Finalizing model
2023-04-24 15:57:18,797:INFO:Uploading results into container
2023-04-24 15:57:18,798:INFO:Uploading model into container now
2023-04-24 15:57:18,798:INFO:_master_model_container: 11
2023-04-24 15:57:18,798:INFO:_display_container: 7
2023-04-24 15:57:18,799:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 15:57:18,799:INFO:create_model() successfully completed......................................
2023-04-24 15:57:18,876:INFO:SubProcess create_model() end ==================================
2023-04-24 15:57:18,876:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8485
2023-04-24 15:57:18,877:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8537
2023-04-24 15:57:18,877:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-04-24 15:57:18,877:INFO:choose_better completed
2023-04-24 15:57:18,883:INFO:_master_model_container: 11
2023-04-24 15:57:18,883:INFO:_display_container: 6
2023-04-24 15:57:18,883:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 15:57:18,883:INFO:tune_model() successfully completed......................................
2023-04-24 15:57:19,035:INFO:Initializing plot_model()
2023-04-24 15:57:19,035:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 15:57:19,035:INFO:Checking exceptions
2023-04-24 15:57:19,046:INFO:Preloading libraries
2023-04-24 15:57:19,046:INFO:Copying training dataset
2023-04-24 15:57:19,046:INFO:Plot type: feature
2023-04-24 15:57:19,229:INFO:Saving 'Feature Importance.png'
2023-04-24 15:57:19,338:INFO:Visual Rendered Successfully
2023-04-24 15:57:19,399:INFO:plot_model() successfully completed......................................
2023-04-24 15:57:19,400:INFO:Initializing plot_model()
2023-04-24 15:57:19,400:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 15:57:19,400:INFO:Checking exceptions
2023-04-24 15:57:19,411:INFO:Preloading libraries
2023-04-24 15:57:19,411:INFO:Copying training dataset
2023-04-24 15:57:19,411:INFO:Plot type: auc
2023-04-24 15:57:19,715:INFO:Fitting Model
2023-04-24 15:57:19,716:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-04-24 15:57:19,717:INFO:Scoring test/hold-out set
2023-04-24 15:57:19,754:INFO:Saving 'AUC.png'
2023-04-24 15:57:19,862:INFO:Visual Rendered Successfully
2023-04-24 15:57:19,928:INFO:plot_model() successfully completed......................................
2023-04-24 15:57:19,928:INFO:Initializing plot_model()
2023-04-24 15:57:19,928:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 15:57:19,928:INFO:Checking exceptions
2023-04-24 15:57:19,940:INFO:Preloading libraries
2023-04-24 15:57:19,940:INFO:Copying training dataset
2023-04-24 15:57:19,940:INFO:Plot type: confusion_matrix
2023-04-24 15:57:20,228:INFO:Fitting Model
2023-04-24 15:57:20,228:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-04-24 15:57:20,229:INFO:Scoring test/hold-out set
2023-04-24 15:57:20,245:INFO:Saving 'Confusion Matrix.png'
2023-04-24 15:57:20,302:INFO:Visual Rendered Successfully
2023-04-24 15:57:20,363:INFO:plot_model() successfully completed......................................
2023-04-24 15:57:20,372:INFO:Initializing save_model()
2023-04-24 15:57:20,372:INFO:save_model(model=LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/lr/Model_Results/Model_Objects/lr, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                                                               n_jobs=1,
                                                               random_state=8216,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-24 15:57:20,372:INFO:Adding model into prep_pipe
2023-04-24 15:57:20,424:INFO:/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/lr/Model_Results/Model_Objects/lr.pkl saved in current working directory
2023-04-24 15:57:20,433:INFO:Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('trained_model',
                 LogisticRegression(C=0.041, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=8216,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2023-04-24 15:57:20,433:INFO:save_model() successfully completed......................................
2023-04-24 15:57:20,562:INFO:Initializing create_model()
2023-04-24 15:57:20,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=dt, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 15:57:20,563:INFO:Checking exceptions
2023-04-24 15:57:20,581:INFO:Importing libraries
2023-04-24 15:57:20,581:INFO:Copying training dataset
2023-04-24 15:57:20,619:INFO:Defining folds
2023-04-24 15:57:20,619:INFO:Declaring metric variables
2023-04-24 15:57:20,622:INFO:Importing untrained model
2023-04-24 15:57:20,626:INFO:Decision Tree Classifier Imported successfully
2023-04-24 15:57:20,631:INFO:Starting cross validation
2023-04-24 15:57:20,642:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:57:22,784:INFO:Calculating mean and std
2023-04-24 15:57:22,791:INFO:Creating metrics dataframe
2023-04-24 15:57:22,803:INFO:Finalizing model
2023-04-24 15:57:24,328:INFO:Uploading results into container
2023-04-24 15:57:24,329:INFO:Uploading model into container now
2023-04-24 15:57:24,335:INFO:_master_model_container: 12
2023-04-24 15:57:24,335:INFO:_display_container: 7
2023-04-24 15:57:24,335:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best')
2023-04-24 15:57:24,335:INFO:create_model() successfully completed......................................
2023-04-24 15:57:24,512:INFO:Initializing tune_model()
2023-04-24 15:57:24,512:INFO:tune_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 15:57:24,512:INFO:Checking exceptions
2023-04-24 15:57:24,537:INFO:Copying training dataset
2023-04-24 15:57:24,552:INFO:Checking base model
2023-04-24 15:57:24,552:INFO:Base model : Decision Tree Classifier
2023-04-24 15:57:24,554:INFO:Declaring metric variables
2023-04-24 15:57:24,557:INFO:Defining Hyperparameters
2023-04-24 15:57:24,636:INFO:Tuning with n_jobs=-1
2023-04-24 15:57:24,636:INFO:Initializing RandomizedSearchCV
2023-04-24 15:57:33,564:INFO:best_params: {'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 13, 'actual_estimator__criterion': 'entropy'}
2023-04-24 15:57:33,567:INFO:Hyperparameter search completed
2023-04-24 15:57:33,567:INFO:SubProcess create_model() called ==================================
2023-04-24 15:57:33,568:INFO:Initializing create_model()
2023-04-24 15:57:33,568:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd7356a4be0>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0, 'max_features': 1.0, 'max_depth': 13, 'criterion': 'entropy'})
2023-04-24 15:57:33,568:INFO:Checking exceptions
2023-04-24 15:57:33,569:INFO:Importing libraries
2023-04-24 15:57:33,569:INFO:Copying training dataset
2023-04-24 15:57:33,603:INFO:Defining folds
2023-04-24 15:57:33,603:INFO:Declaring metric variables
2023-04-24 15:57:33,608:INFO:Importing untrained model
2023-04-24 15:57:33,608:INFO:Declaring custom model
2023-04-24 15:57:33,612:INFO:Decision Tree Classifier Imported successfully
2023-04-24 15:57:33,620:INFO:Starting cross validation
2023-04-24 15:57:33,634:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:57:34,844:INFO:Calculating mean and std
2023-04-24 15:57:34,846:INFO:Creating metrics dataframe
2023-04-24 15:57:34,850:INFO:Finalizing model
2023-04-24 15:57:36,246:INFO:Uploading results into container
2023-04-24 15:57:36,246:INFO:Uploading model into container now
2023-04-24 15:57:36,247:INFO:_master_model_container: 13
2023-04-24 15:57:36,247:INFO:_display_container: 8
2023-04-24 15:57:36,247:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best')
2023-04-24 15:57:36,247:INFO:create_model() successfully completed......................................
2023-04-24 15:57:36,393:INFO:SubProcess create_model() end ==================================
2023-04-24 15:57:36,393:INFO:choose_better activated
2023-04-24 15:57:36,395:INFO:SubProcess create_model() called ==================================
2023-04-24 15:57:36,395:INFO:Initializing create_model()
2023-04-24 15:57:36,396:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 15:57:36,396:INFO:Checking exceptions
2023-04-24 15:57:36,397:INFO:Importing libraries
2023-04-24 15:57:36,397:INFO:Copying training dataset
2023-04-24 15:57:36,413:INFO:Defining folds
2023-04-24 15:57:36,413:INFO:Declaring metric variables
2023-04-24 15:57:36,413:INFO:Importing untrained model
2023-04-24 15:57:36,413:INFO:Declaring custom model
2023-04-24 15:57:36,413:INFO:Decision Tree Classifier Imported successfully
2023-04-24 15:57:36,414:INFO:Starting cross validation
2023-04-24 15:57:36,421:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:57:37,435:INFO:Calculating mean and std
2023-04-24 15:57:37,435:INFO:Creating metrics dataframe
2023-04-24 15:57:37,438:INFO:Finalizing model
2023-04-24 15:57:37,968:INFO:Uploading results into container
2023-04-24 15:57:37,968:INFO:Uploading model into container now
2023-04-24 15:57:37,969:INFO:_master_model_container: 14
2023-04-24 15:57:37,969:INFO:_display_container: 9
2023-04-24 15:57:37,969:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best')
2023-04-24 15:57:37,969:INFO:create_model() successfully completed......................................
2023-04-24 15:57:38,035:INFO:SubProcess create_model() end ==================================
2023-04-24 15:57:38,035:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best') result for Accuracy is 0.783
2023-04-24 15:57:38,036:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best') result for Accuracy is 0.8315
2023-04-24 15:57:38,036:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best') is best model
2023-04-24 15:57:38,036:INFO:choose_better completed
2023-04-24 15:57:38,041:INFO:_master_model_container: 14
2023-04-24 15:57:38,041:INFO:_display_container: 8
2023-04-24 15:57:38,042:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best')
2023-04-24 15:57:38,042:INFO:tune_model() successfully completed......................................
2023-04-24 15:57:38,195:INFO:Initializing plot_model()
2023-04-24 15:57:38,195:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 15:57:38,195:INFO:Checking exceptions
2023-04-24 15:57:38,202:INFO:Preloading libraries
2023-04-24 15:57:38,203:INFO:Copying training dataset
2023-04-24 15:57:38,203:INFO:Plot type: feature
2023-04-24 15:57:38,203:WARNING:No coef_ found. Trying feature_importances_
2023-04-24 15:57:38,309:INFO:Saving 'Feature Importance.png'
2023-04-24 15:57:38,393:INFO:Visual Rendered Successfully
2023-04-24 15:57:38,455:INFO:plot_model() successfully completed......................................
2023-04-24 15:57:38,455:INFO:Initializing plot_model()
2023-04-24 15:57:38,455:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 15:57:38,455:INFO:Checking exceptions
2023-04-24 15:57:38,461:INFO:Preloading libraries
2023-04-24 15:57:38,462:INFO:Copying training dataset
2023-04-24 15:57:38,462:INFO:Plot type: auc
2023-04-24 15:57:38,761:INFO:Fitting Model
2023-04-24 15:57:38,762:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2023-04-24 15:57:38,763:INFO:Scoring test/hold-out set
2023-04-24 15:57:38,791:INFO:Saving 'AUC.png'
2023-04-24 15:57:38,888:INFO:Visual Rendered Successfully
2023-04-24 15:57:38,957:INFO:plot_model() successfully completed......................................
2023-04-24 15:57:38,957:INFO:Initializing plot_model()
2023-04-24 15:57:38,957:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 15:57:38,958:INFO:Checking exceptions
2023-04-24 15:57:38,977:INFO:Preloading libraries
2023-04-24 15:57:38,978:INFO:Copying training dataset
2023-04-24 15:57:38,978:INFO:Plot type: confusion_matrix
2023-04-24 15:57:39,325:INFO:Fitting Model
2023-04-24 15:57:39,326:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2023-04-24 15:57:39,327:INFO:Scoring test/hold-out set
2023-04-24 15:57:39,349:INFO:Saving 'Confusion Matrix.png'
2023-04-24 15:57:39,415:INFO:Visual Rendered Successfully
2023-04-24 15:57:39,504:INFO:plot_model() successfully completed......................................
2023-04-24 15:57:39,518:INFO:Initializing save_model()
2023-04-24 15:57:39,518:INFO:save_model(model=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), model_name=/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/dt/Model_Results/Model_Objects/dt, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                                                               n_jobs=1,
                                                               random_state=8216,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-24 15:57:39,518:INFO:Adding model into prep_pipe
2023-04-24 15:57:39,566:INFO:/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/dt/Model_Results/Model_Objects/dt.pkl saved in current working directory
2023-04-24 15:57:39,574:INFO:Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('trained_model',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='entropy', max_depth=13,
                                        max_features=1.0, max_leaf_nodes=None,
                                        min_impurity_decrease=0,
                                        min_samples_leaf=4,
                                        min_samples_split=10,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=8216, splitter='best'))],
         verbose=False)
2023-04-24 15:57:39,574:INFO:save_model() successfully completed......................................
2023-04-24 15:57:39,707:INFO:Initializing create_model()
2023-04-24 15:57:39,707:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 15:57:39,707:INFO:Checking exceptions
2023-04-24 15:57:39,724:INFO:Importing libraries
2023-04-24 15:57:39,724:INFO:Copying training dataset
2023-04-24 15:57:39,748:INFO:Defining folds
2023-04-24 15:57:39,748:INFO:Declaring metric variables
2023-04-24 15:57:39,750:INFO:Importing untrained model
2023-04-24 15:57:39,753:INFO:Random Forest Classifier Imported successfully
2023-04-24 15:57:39,757:INFO:Starting cross validation
2023-04-24 15:57:39,765:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:57:41,243:INFO:Calculating mean and std
2023-04-24 15:57:41,248:INFO:Creating metrics dataframe
2023-04-24 15:57:41,256:INFO:Finalizing model
2023-04-24 15:57:41,956:INFO:Uploading results into container
2023-04-24 15:57:41,957:INFO:Uploading model into container now
2023-04-24 15:57:41,963:INFO:_master_model_container: 15
2023-04-24 15:57:41,963:INFO:_display_container: 9
2023-04-24 15:57:41,963:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False)
2023-04-24 15:57:41,963:INFO:create_model() successfully completed......................................
2023-04-24 15:57:42,054:INFO:Initializing tune_model()
2023-04-24 15:57:42,054:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 15:57:42,054:INFO:Checking exceptions
2023-04-24 15:57:42,077:INFO:Copying training dataset
2023-04-24 15:57:42,089:INFO:Checking base model
2023-04-24 15:57:42,089:INFO:Base model : Random Forest Classifier
2023-04-24 15:57:42,092:INFO:Declaring metric variables
2023-04-24 15:57:42,094:INFO:Defining Hyperparameters
2023-04-24 15:57:42,177:INFO:Tuning with n_jobs=-1
2023-04-24 15:57:42,177:INFO:Initializing RandomizedSearchCV
2023-04-24 15:57:51,490:INFO:best_params: {'actual_estimator__n_estimators': 220, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-04-24 15:57:51,496:INFO:Hyperparameter search completed
2023-04-24 15:57:51,497:INFO:SubProcess create_model() called ==================================
2023-04-24 15:57:51,498:INFO:Initializing create_model()
2023-04-24 15:57:51,498:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd7104a6bb0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 220, 'min_samples_split': 9, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0001, 'max_features': 'log2', 'max_depth': 7, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-04-24 15:57:51,498:INFO:Checking exceptions
2023-04-24 15:57:51,499:INFO:Importing libraries
2023-04-24 15:57:51,499:INFO:Copying training dataset
2023-04-24 15:57:51,540:INFO:Defining folds
2023-04-24 15:57:51,540:INFO:Declaring metric variables
2023-04-24 15:57:51,545:INFO:Importing untrained model
2023-04-24 15:57:51,545:INFO:Declaring custom model
2023-04-24 15:57:51,548:INFO:Random Forest Classifier Imported successfully
2023-04-24 15:57:51,553:INFO:Starting cross validation
2023-04-24 15:57:51,565:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:57:53,180:INFO:Calculating mean and std
2023-04-24 15:57:53,181:INFO:Creating metrics dataframe
2023-04-24 15:57:53,190:INFO:Finalizing model
2023-04-24 15:57:53,943:INFO:Uploading results into container
2023-04-24 15:57:53,944:INFO:Uploading model into container now
2023-04-24 15:57:53,944:INFO:_master_model_container: 16
2023-04-24 15:57:53,944:INFO:_display_container: 10
2023-04-24 15:57:53,945:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=7, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0001,
                       min_samples_leaf=4, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=220,
                       n_jobs=-1, oob_score=False, random_state=8216, verbose=0,
                       warm_start=False)
2023-04-24 15:57:53,945:INFO:create_model() successfully completed......................................
2023-04-24 15:57:54,095:INFO:SubProcess create_model() end ==================================
2023-04-24 15:57:54,095:INFO:choose_better activated
2023-04-24 15:57:54,098:INFO:SubProcess create_model() called ==================================
2023-04-24 15:57:54,098:INFO:Initializing create_model()
2023-04-24 15:57:54,098:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 15:57:54,098:INFO:Checking exceptions
2023-04-24 15:57:54,100:INFO:Importing libraries
2023-04-24 15:57:54,100:INFO:Copying training dataset
2023-04-24 15:57:54,125:INFO:Defining folds
2023-04-24 15:57:54,126:INFO:Declaring metric variables
2023-04-24 15:57:54,126:INFO:Importing untrained model
2023-04-24 15:57:54,126:INFO:Declaring custom model
2023-04-24 15:57:54,126:INFO:Random Forest Classifier Imported successfully
2023-04-24 15:57:54,126:INFO:Starting cross validation
2023-04-24 15:57:54,134:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:57:57,266:INFO:Calculating mean and std
2023-04-24 15:57:57,269:INFO:Creating metrics dataframe
2023-04-24 15:57:57,311:INFO:Finalizing model
2023-04-24 15:57:58,338:INFO:Uploading results into container
2023-04-24 15:57:58,339:INFO:Uploading model into container now
2023-04-24 15:57:58,339:INFO:_master_model_container: 17
2023-04-24 15:57:58,339:INFO:_display_container: 11
2023-04-24 15:57:58,340:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False)
2023-04-24 15:57:58,340:INFO:create_model() successfully completed......................................
2023-04-24 15:57:58,529:INFO:SubProcess create_model() end ==================================
2023-04-24 15:57:58,530:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False) result for Accuracy is 0.879
2023-04-24 15:57:58,531:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=7, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0001,
                       min_samples_leaf=4, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=220,
                       n_jobs=-1, oob_score=False, random_state=8216, verbose=0,
                       warm_start=False) result for Accuracy is 0.87
2023-04-24 15:57:58,531:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False) is best model
2023-04-24 15:57:58,531:INFO:choose_better completed
2023-04-24 15:57:58,533:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-24 15:57:58,547:INFO:_master_model_container: 17
2023-04-24 15:57:58,547:INFO:_display_container: 10
2023-04-24 15:57:58,548:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False)
2023-04-24 15:57:58,548:INFO:tune_model() successfully completed......................................
2023-04-24 15:57:58,712:INFO:Initializing plot_model()
2023-04-24 15:57:58,712:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 15:57:58,712:INFO:Checking exceptions
2023-04-24 15:57:58,739:INFO:Preloading libraries
2023-04-24 15:57:58,781:INFO:Copying training dataset
2023-04-24 15:57:58,781:INFO:Plot type: feature
2023-04-24 15:57:58,782:WARNING:No coef_ found. Trying feature_importances_
2023-04-24 15:57:58,906:INFO:Saving 'Feature Importance.png'
2023-04-24 15:57:59,004:INFO:Visual Rendered Successfully
2023-04-24 15:57:59,071:INFO:plot_model() successfully completed......................................
2023-04-24 15:57:59,072:INFO:Initializing plot_model()
2023-04-24 15:57:59,072:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 15:57:59,072:INFO:Checking exceptions
2023-04-24 15:57:59,090:INFO:Preloading libraries
2023-04-24 15:57:59,124:INFO:Copying training dataset
2023-04-24 15:57:59,124:INFO:Plot type: auc
2023-04-24 15:57:59,437:INFO:Fitting Model
2023-04-24 15:57:59,438:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-04-24 15:57:59,439:INFO:Scoring test/hold-out set
2023-04-24 15:57:59,589:INFO:Saving 'AUC.png'
2023-04-24 15:57:59,697:INFO:Visual Rendered Successfully
2023-04-24 15:57:59,761:INFO:plot_model() successfully completed......................................
2023-04-24 15:57:59,762:INFO:Initializing plot_model()
2023-04-24 15:57:59,762:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 15:57:59,762:INFO:Checking exceptions
2023-04-24 15:57:59,777:INFO:Preloading libraries
2023-04-24 15:57:59,801:INFO:Copying training dataset
2023-04-24 15:57:59,802:INFO:Plot type: confusion_matrix
2023-04-24 15:58:00,110:INFO:Fitting Model
2023-04-24 15:58:00,110:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-04-24 15:58:00,111:INFO:Scoring test/hold-out set
2023-04-24 15:58:00,232:INFO:Saving 'Confusion Matrix.png'
2023-04-24 15:58:00,286:INFO:Visual Rendered Successfully
2023-04-24 15:58:00,353:INFO:plot_model() successfully completed......................................
2023-04-24 15:58:00,362:INFO:Initializing save_model()
2023-04-24 15:58:00,362:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), model_name=/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/rf/Model_Results/Model_Objects/rf, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                                                               n_jobs=1,
                                                               random_state=8216,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-24 15:58:00,362:INFO:Adding model into prep_pipe
2023-04-24 15:58:00,442:INFO:/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/rf/Model_Results/Model_Objects/rf.pkl saved in current working directory
2023-04-24 15:58:00,450:INFO:Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='auto',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=8216,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-04-24 15:58:00,450:INFO:save_model() successfully completed......................................
2023-04-24 15:58:00,591:INFO:Initializing create_model()
2023-04-24 15:58:00,591:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=ada, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 15:58:00,591:INFO:Checking exceptions
2023-04-24 15:58:00,610:INFO:Importing libraries
2023-04-24 15:58:00,610:INFO:Copying training dataset
2023-04-24 15:58:00,626:INFO:Defining folds
2023-04-24 15:58:00,626:INFO:Declaring metric variables
2023-04-24 15:58:00,628:INFO:Importing untrained model
2023-04-24 15:58:00,630:INFO:Ada Boost Classifier Imported successfully
2023-04-24 15:58:00,635:INFO:Starting cross validation
2023-04-24 15:58:00,643:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:58:06,015:INFO:Calculating mean and std
2023-04-24 15:58:06,017:INFO:Creating metrics dataframe
2023-04-24 15:58:06,022:INFO:Finalizing model
2023-04-24 15:58:11,145:INFO:Uploading results into container
2023-04-24 15:58:11,145:INFO:Uploading model into container now
2023-04-24 15:58:11,151:INFO:_master_model_container: 18
2023-04-24 15:58:11,151:INFO:_display_container: 11
2023-04-24 15:58:11,151:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216)
2023-04-24 15:58:11,151:INFO:create_model() successfully completed......................................
2023-04-24 15:58:11,221:INFO:Initializing tune_model()
2023-04-24 15:58:11,221:INFO:tune_model(estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 15:58:11,221:INFO:Checking exceptions
2023-04-24 15:58:11,244:INFO:Copying training dataset
2023-04-24 15:58:11,255:INFO:Checking base model
2023-04-24 15:58:11,256:INFO:Base model : Ada Boost Classifier
2023-04-24 15:58:11,258:INFO:Declaring metric variables
2023-04-24 15:58:11,260:INFO:Defining Hyperparameters
2023-04-24 15:58:11,334:INFO:Tuning with n_jobs=-1
2023-04-24 15:58:11,334:INFO:Initializing RandomizedSearchCV
2023-04-24 15:59:38,718:INFO:best_params: {'actual_estimator__n_estimators': 150, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__algorithm': 'SAMME.R'}
2023-04-24 15:59:38,722:INFO:Hyperparameter search completed
2023-04-24 15:59:38,722:INFO:SubProcess create_model() called ==================================
2023-04-24 15:59:38,723:INFO:Initializing create_model()
2023-04-24 15:59:38,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd72a2cdee0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 150, 'learning_rate': 0.4, 'algorithm': 'SAMME.R'})
2023-04-24 15:59:38,723:INFO:Checking exceptions
2023-04-24 15:59:38,723:INFO:Importing libraries
2023-04-24 15:59:38,723:INFO:Copying training dataset
2023-04-24 15:59:38,749:INFO:Defining folds
2023-04-24 15:59:38,749:INFO:Declaring metric variables
2023-04-24 15:59:38,754:INFO:Importing untrained model
2023-04-24 15:59:38,755:INFO:Declaring custom model
2023-04-24 15:59:38,757:INFO:Ada Boost Classifier Imported successfully
2023-04-24 15:59:38,762:INFO:Starting cross validation
2023-04-24 15:59:38,774:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:59:40,544:INFO:Calculating mean and std
2023-04-24 15:59:40,547:INFO:Creating metrics dataframe
2023-04-24 15:59:40,553:INFO:Finalizing model
2023-04-24 15:59:54,706:INFO:Uploading results into container
2023-04-24 15:59:54,707:INFO:Uploading model into container now
2023-04-24 15:59:54,708:INFO:_master_model_container: 19
2023-04-24 15:59:54,708:INFO:_display_container: 12
2023-04-24 15:59:54,708:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216)
2023-04-24 15:59:54,708:INFO:create_model() successfully completed......................................
2023-04-24 15:59:54,826:INFO:SubProcess create_model() end ==================================
2023-04-24 15:59:54,826:INFO:choose_better activated
2023-04-24 15:59:54,828:INFO:SubProcess create_model() called ==================================
2023-04-24 15:59:54,829:INFO:Initializing create_model()
2023-04-24 15:59:54,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 15:59:54,829:INFO:Checking exceptions
2023-04-24 15:59:54,830:INFO:Importing libraries
2023-04-24 15:59:54,830:INFO:Copying training dataset
2023-04-24 15:59:54,844:INFO:Defining folds
2023-04-24 15:59:54,844:INFO:Declaring metric variables
2023-04-24 15:59:54,844:INFO:Importing untrained model
2023-04-24 15:59:54,844:INFO:Declaring custom model
2023-04-24 15:59:54,844:INFO:Ada Boost Classifier Imported successfully
2023-04-24 15:59:54,844:INFO:Starting cross validation
2023-04-24 15:59:54,851:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 15:59:55,969:INFO:Calculating mean and std
2023-04-24 15:59:55,970:INFO:Creating metrics dataframe
2023-04-24 15:59:55,971:INFO:Finalizing model
2023-04-24 15:59:56,573:INFO:Uploading results into container
2023-04-24 15:59:56,573:INFO:Uploading model into container now
2023-04-24 15:59:56,574:INFO:_master_model_container: 20
2023-04-24 15:59:56,574:INFO:_display_container: 13
2023-04-24 15:59:56,574:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216)
2023-04-24 15:59:56,574:INFO:create_model() successfully completed......................................
2023-04-24 15:59:56,640:INFO:SubProcess create_model() end ==================================
2023-04-24 15:59:56,640:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216) result for Accuracy is 0.8476
2023-04-24 15:59:56,641:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216) result for Accuracy is 0.8492
2023-04-24 15:59:56,641:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216) is best model
2023-04-24 15:59:56,641:INFO:choose_better completed
2023-04-24 15:59:56,646:INFO:_master_model_container: 20
2023-04-24 15:59:56,646:INFO:_display_container: 12
2023-04-24 15:59:56,647:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216)
2023-04-24 15:59:56,647:INFO:tune_model() successfully completed......................................
2023-04-24 15:59:56,803:INFO:Initializing plot_model()
2023-04-24 15:59:56,803:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 15:59:56,803:INFO:Checking exceptions
2023-04-24 15:59:56,812:INFO:Preloading libraries
2023-04-24 15:59:56,820:INFO:Copying training dataset
2023-04-24 15:59:56,820:INFO:Plot type: feature
2023-04-24 15:59:56,821:WARNING:No coef_ found. Trying feature_importances_
2023-04-24 15:59:56,933:INFO:Saving 'Feature Importance.png'
2023-04-24 15:59:57,020:INFO:Visual Rendered Successfully
2023-04-24 15:59:57,082:INFO:plot_model() successfully completed......................................
2023-04-24 15:59:57,083:INFO:Initializing plot_model()
2023-04-24 15:59:57,083:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 15:59:57,083:INFO:Checking exceptions
2023-04-24 15:59:57,091:INFO:Preloading libraries
2023-04-24 15:59:57,099:INFO:Copying training dataset
2023-04-24 15:59:57,099:INFO:Plot type: auc
2023-04-24 15:59:57,427:INFO:Fitting Model
2023-04-24 15:59:57,427:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2023-04-24 15:59:57,428:INFO:Scoring test/hold-out set
2023-04-24 15:59:58,176:INFO:Saving 'AUC.png'
2023-04-24 15:59:58,285:INFO:Visual Rendered Successfully
2023-04-24 15:59:58,349:INFO:plot_model() successfully completed......................................
2023-04-24 15:59:58,350:INFO:Initializing plot_model()
2023-04-24 15:59:58,350:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 15:59:58,350:INFO:Checking exceptions
2023-04-24 15:59:58,358:INFO:Preloading libraries
2023-04-24 15:59:58,365:INFO:Copying training dataset
2023-04-24 15:59:58,366:INFO:Plot type: confusion_matrix
2023-04-24 15:59:58,657:INFO:Fitting Model
2023-04-24 15:59:58,657:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2023-04-24 15:59:58,657:INFO:Scoring test/hold-out set
2023-04-24 15:59:59,400:INFO:Saving 'Confusion Matrix.png'
2023-04-24 15:59:59,452:INFO:Visual Rendered Successfully
2023-04-24 15:59:59,515:INFO:plot_model() successfully completed......................................
2023-04-24 15:59:59,525:INFO:Initializing save_model()
2023-04-24 15:59:59,525:INFO:save_model(model=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216), model_name=/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/ada/Model_Results/Model_Objects/ada, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                                                               n_jobs=1,
                                                               random_state=8216,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-24 15:59:59,525:INFO:Adding model into prep_pipe
2023-04-24 15:59:59,604:INFO:/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/ada/Model_Results/Model_Objects/ada.pkl saved in current working directory
2023-04-24 15:59:59,611:INFO:Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('trained_model',
                 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
                                    learning_rate=0.4, n_estimators=150,
                                    random_state=8216))],
         verbose=False)
2023-04-24 15:59:59,611:INFO:save_model() successfully completed......................................
2023-04-24 15:59:59,753:INFO:Initializing create_model()
2023-04-24 15:59:59,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 15:59:59,753:INFO:Checking exceptions
2023-04-24 15:59:59,768:INFO:Importing libraries
2023-04-24 15:59:59,768:INFO:Copying training dataset
2023-04-24 15:59:59,784:INFO:Defining folds
2023-04-24 15:59:59,784:INFO:Declaring metric variables
2023-04-24 15:59:59,786:INFO:Importing untrained model
2023-04-24 15:59:59,789:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 15:59:59,793:INFO:Starting cross validation
2023-04-24 15:59:59,802:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:00:03,145:INFO:Calculating mean and std
2023-04-24 16:00:03,147:INFO:Creating metrics dataframe
2023-04-24 16:00:03,151:INFO:Finalizing model
2023-04-24 16:00:07,048:INFO:Uploading results into container
2023-04-24 16:00:07,048:INFO:Uploading model into container now
2023-04-24 16:00:07,054:INFO:_master_model_container: 21
2023-04-24 16:00:07,054:INFO:_display_container: 13
2023-04-24 16:00:07,054:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-24 16:00:07,054:INFO:create_model() successfully completed......................................
2023-04-24 16:00:07,132:INFO:Initializing tune_model()
2023-04-24 16:00:07,133:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 16:00:07,133:INFO:Checking exceptions
2023-04-24 16:00:07,152:INFO:Copying training dataset
2023-04-24 16:00:07,169:INFO:Checking base model
2023-04-24 16:00:07,169:INFO:Base model : Light Gradient Boosting Machine
2023-04-24 16:00:07,172:INFO:Declaring metric variables
2023-04-24 16:00:07,174:INFO:Defining Hyperparameters
2023-04-24 16:00:07,247:INFO:Tuning with n_jobs=-1
2023-04-24 16:00:07,247:INFO:Initializing RandomizedSearchCV
2023-04-24 16:00:23,559:INFO:best_params: {'actual_estimator__reg_lambda': 0.01, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 21, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 1.0}
2023-04-24 16:00:23,563:INFO:Hyperparameter search completed
2023-04-24 16:00:23,564:INFO:SubProcess create_model() called ==================================
2023-04-24 16:00:23,565:INFO:Initializing create_model()
2023-04-24 16:00:23,565:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd72a5c1580>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.01, 'reg_alpha': 0.0005, 'num_leaves': 256, 'n_estimators': 190, 'min_split_gain': 0.3, 'min_child_samples': 21, 'learning_rate': 0.01, 'feature_fraction': 0.6, 'bagging_freq': 5, 'bagging_fraction': 1.0})
2023-04-24 16:00:23,565:INFO:Checking exceptions
2023-04-24 16:00:23,565:INFO:Importing libraries
2023-04-24 16:00:23,565:INFO:Copying training dataset
2023-04-24 16:00:23,611:INFO:Defining folds
2023-04-24 16:00:23,611:INFO:Declaring metric variables
2023-04-24 16:00:23,616:INFO:Importing untrained model
2023-04-24 16:00:23,616:INFO:Declaring custom model
2023-04-24 16:00:23,619:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 16:00:23,624:INFO:Starting cross validation
2023-04-24 16:00:23,637:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:00:26,330:INFO:Calculating mean and std
2023-04-24 16:00:26,332:INFO:Creating metrics dataframe
2023-04-24 16:00:26,336:INFO:Finalizing model
2023-04-24 16:01:15,678:INFO:Uploading results into container
2023-04-24 16:01:15,679:INFO:Uploading model into container now
2023-04-24 16:01:15,679:INFO:_master_model_container: 22
2023-04-24 16:01:15,679:INFO:_display_container: 14
2023-04-24 16:01:15,680:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-04-24 16:01:15,680:INFO:create_model() successfully completed......................................
2023-04-24 16:01:15,822:INFO:SubProcess create_model() end ==================================
2023-04-24 16:01:15,823:INFO:choose_better activated
2023-04-24 16:01:15,825:INFO:SubProcess create_model() called ==================================
2023-04-24 16:01:15,825:INFO:Initializing create_model()
2023-04-24 16:01:15,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:01:15,825:INFO:Checking exceptions
2023-04-24 16:01:15,827:INFO:Importing libraries
2023-04-24 16:01:15,827:INFO:Copying training dataset
2023-04-24 16:01:15,845:INFO:Defining folds
2023-04-24 16:01:15,845:INFO:Declaring metric variables
2023-04-24 16:01:15,845:INFO:Importing untrained model
2023-04-24 16:01:15,845:INFO:Declaring custom model
2023-04-24 16:01:15,846:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 16:01:15,846:INFO:Starting cross validation
2023-04-24 16:01:15,857:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:01:17,410:INFO:Calculating mean and std
2023-04-24 16:01:17,410:INFO:Creating metrics dataframe
2023-04-24 16:01:17,412:INFO:Finalizing model
2023-04-24 16:01:18,102:INFO:Uploading results into container
2023-04-24 16:01:18,103:INFO:Uploading model into container now
2023-04-24 16:01:18,103:INFO:_master_model_container: 23
2023-04-24 16:01:18,103:INFO:_display_container: 15
2023-04-24 16:01:18,104:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-24 16:01:18,104:INFO:create_model() successfully completed......................................
2023-04-24 16:01:18,169:INFO:SubProcess create_model() end ==================================
2023-04-24 16:01:18,170:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.811
2023-04-24 16:01:18,170:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) result for Accuracy is 0.881
2023-04-24 16:01:18,170:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) is best model
2023-04-24 16:01:18,170:INFO:choose_better completed
2023-04-24 16:01:18,176:INFO:_master_model_container: 23
2023-04-24 16:01:18,176:INFO:_display_container: 14
2023-04-24 16:01:18,176:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-04-24 16:01:18,176:INFO:tune_model() successfully completed......................................
2023-04-24 16:01:18,343:INFO:Initializing plot_model()
2023-04-24 16:01:18,343:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:01:18,343:INFO:Checking exceptions
2023-04-24 16:01:18,351:INFO:Preloading libraries
2023-04-24 16:01:18,413:INFO:Copying training dataset
2023-04-24 16:01:18,413:INFO:Plot type: feature
2023-04-24 16:01:18,413:WARNING:No coef_ found. Trying feature_importances_
2023-04-24 16:01:18,516:INFO:Saving 'Feature Importance.png'
2023-04-24 16:01:18,602:INFO:Visual Rendered Successfully
2023-04-24 16:01:18,671:INFO:plot_model() successfully completed......................................
2023-04-24 16:01:18,672:INFO:Initializing plot_model()
2023-04-24 16:01:18,672:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:01:18,672:INFO:Checking exceptions
2023-04-24 16:01:18,680:INFO:Preloading libraries
2023-04-24 16:01:18,728:INFO:Copying training dataset
2023-04-24 16:01:18,728:INFO:Plot type: auc
2023-04-24 16:01:19,040:INFO:Fitting Model
2023-04-24 16:01:19,041:INFO:Scoring test/hold-out set
2023-04-24 16:01:19,300:INFO:Saving 'AUC.png'
2023-04-24 16:01:19,407:INFO:Visual Rendered Successfully
2023-04-24 16:01:19,478:INFO:plot_model() successfully completed......................................
2023-04-24 16:01:19,479:INFO:Initializing plot_model()
2023-04-24 16:01:19,479:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:01:19,479:INFO:Checking exceptions
2023-04-24 16:01:19,485:INFO:Preloading libraries
2023-04-24 16:01:19,535:INFO:Copying training dataset
2023-04-24 16:01:19,535:INFO:Plot type: confusion_matrix
2023-04-24 16:01:19,831:INFO:Fitting Model
2023-04-24 16:01:19,832:INFO:Scoring test/hold-out set
2023-04-24 16:01:20,097:INFO:Saving 'Confusion Matrix.png'
2023-04-24 16:01:20,150:INFO:Visual Rendered Successfully
2023-04-24 16:01:20,217:INFO:plot_model() successfully completed......................................
2023-04-24 16:01:20,271:INFO:Initializing save_model()
2023-04-24 16:01:20,271:INFO:save_model(model=LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), model_name=/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/lightgbm/Model_Results/Model_Objects/lightgbm, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                                                               n_jobs=1,
                                                               random_state=8216,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-24 16:01:20,271:INFO:Adding model into prep_pipe
2023-04-24 16:01:20,348:INFO:/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/lightgbm/Model_Results/Model_Objects/lightgbm.pkl saved in current working directory
2023-04-24 16:01:20,357:INFO:Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.01,
                                max_depth=-1, min_child_samples=21,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=190, n_jobs=-1, num_leaves=256,
                                objective=None, random_state=8216,
                                reg_alpha=0.0005, reg_lambda=0.01,
                                silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-04-24 16:01:20,357:INFO:save_model() successfully completed......................................
2023-04-24 16:33:40,527:INFO:Initializing create_model()
2023-04-24 16:33:40,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=lr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:33:40,529:INFO:Checking exceptions
2023-04-24 16:33:40,580:INFO:Importing libraries
2023-04-24 16:33:40,581:INFO:Copying training dataset
2023-04-24 16:33:40,637:INFO:Defining folds
2023-04-24 16:33:40,637:INFO:Declaring metric variables
2023-04-24 16:33:40,640:INFO:Importing untrained model
2023-04-24 16:33:40,643:INFO:Logistic Regression Imported successfully
2023-04-24 16:33:40,647:INFO:Starting cross validation
2023-04-24 16:33:40,663:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:33:45,913:INFO:Calculating mean and std
2023-04-24 16:33:45,915:INFO:Creating metrics dataframe
2023-04-24 16:33:45,921:INFO:Finalizing model
2023-04-24 16:33:46,585:INFO:Uploading results into container
2023-04-24 16:33:46,586:INFO:Uploading model into container now
2023-04-24 16:33:46,593:INFO:_master_model_container: 24
2023-04-24 16:33:46,593:INFO:_display_container: 15
2023-04-24 16:33:46,593:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 16:33:46,593:INFO:create_model() successfully completed......................................
2023-04-24 16:33:46,734:INFO:Initializing tune_model()
2023-04-24 16:33:46,734:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 16:33:46,734:INFO:Checking exceptions
2023-04-24 16:33:46,756:INFO:Copying training dataset
2023-04-24 16:33:46,772:INFO:Checking base model
2023-04-24 16:33:46,772:INFO:Base model : Logistic Regression
2023-04-24 16:33:46,774:INFO:Declaring metric variables
2023-04-24 16:33:46,776:INFO:Defining Hyperparameters
2023-04-24 16:33:46,849:INFO:Tuning with n_jobs=-1
2023-04-24 16:33:46,849:INFO:Initializing RandomizedSearchCV
2023-04-24 16:33:55,092:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 0.041}
2023-04-24 16:33:55,095:INFO:Hyperparameter search completed
2023-04-24 16:33:55,095:INFO:SubProcess create_model() called ==================================
2023-04-24 16:33:55,096:INFO:Initializing create_model()
2023-04-24 16:33:55,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd742cfdb50>, model_only=True, return_train_score=False, kwargs={'class_weight': {}, 'C': 0.041})
2023-04-24 16:33:55,096:INFO:Checking exceptions
2023-04-24 16:33:55,096:INFO:Importing libraries
2023-04-24 16:33:55,096:INFO:Copying training dataset
2023-04-24 16:33:55,126:INFO:Defining folds
2023-04-24 16:33:55,126:INFO:Declaring metric variables
2023-04-24 16:33:55,130:INFO:Importing untrained model
2023-04-24 16:33:55,130:INFO:Declaring custom model
2023-04-24 16:33:55,132:INFO:Logistic Regression Imported successfully
2023-04-24 16:33:55,136:INFO:Starting cross validation
2023-04-24 16:33:55,149:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:33:56,174:INFO:Calculating mean and std
2023-04-24 16:33:56,175:INFO:Creating metrics dataframe
2023-04-24 16:33:56,179:INFO:Finalizing model
2023-04-24 16:33:56,869:INFO:Uploading results into container
2023-04-24 16:33:56,870:INFO:Uploading model into container now
2023-04-24 16:33:56,870:INFO:_master_model_container: 25
2023-04-24 16:33:56,870:INFO:_display_container: 16
2023-04-24 16:33:56,870:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 16:33:56,870:INFO:create_model() successfully completed......................................
2023-04-24 16:33:56,991:INFO:SubProcess create_model() end ==================================
2023-04-24 16:33:56,991:INFO:choose_better activated
2023-04-24 16:33:56,993:INFO:SubProcess create_model() called ==================================
2023-04-24 16:33:56,994:INFO:Initializing create_model()
2023-04-24 16:33:56,994:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:33:56,994:INFO:Checking exceptions
2023-04-24 16:33:56,995:INFO:Importing libraries
2023-04-24 16:33:56,995:INFO:Copying training dataset
2023-04-24 16:33:57,009:INFO:Defining folds
2023-04-24 16:33:57,009:INFO:Declaring metric variables
2023-04-24 16:33:57,009:INFO:Importing untrained model
2023-04-24 16:33:57,009:INFO:Declaring custom model
2023-04-24 16:33:57,009:INFO:Logistic Regression Imported successfully
2023-04-24 16:33:57,009:INFO:Starting cross validation
2023-04-24 16:33:57,016:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:33:58,046:INFO:Calculating mean and std
2023-04-24 16:33:58,047:INFO:Creating metrics dataframe
2023-04-24 16:33:58,048:INFO:Finalizing model
2023-04-24 16:33:58,576:INFO:Uploading results into container
2023-04-24 16:33:58,577:INFO:Uploading model into container now
2023-04-24 16:33:58,577:INFO:_master_model_container: 26
2023-04-24 16:33:58,577:INFO:_display_container: 17
2023-04-24 16:33:58,577:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 16:33:58,577:INFO:create_model() successfully completed......................................
2023-04-24 16:33:58,637:INFO:SubProcess create_model() end ==================================
2023-04-24 16:33:58,638:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8485
2023-04-24 16:33:58,638:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8537
2023-04-24 16:33:58,638:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-04-24 16:33:58,638:INFO:choose_better completed
2023-04-24 16:33:58,643:INFO:_master_model_container: 26
2023-04-24 16:33:58,643:INFO:_display_container: 16
2023-04-24 16:33:58,643:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 16:33:58,644:INFO:tune_model() successfully completed......................................
2023-04-24 16:33:58,807:INFO:Initializing plot_model()
2023-04-24 16:33:58,807:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:33:58,807:INFO:Checking exceptions
2023-04-24 16:33:58,813:INFO:Preloading libraries
2023-04-24 16:33:58,813:INFO:Copying training dataset
2023-04-24 16:33:58,813:INFO:Plot type: feature
2023-04-24 16:33:58,995:INFO:Saving 'Feature Importance.png'
2023-04-24 16:33:59,078:INFO:Visual Rendered Successfully
2023-04-24 16:33:59,142:INFO:plot_model() successfully completed......................................
2023-04-24 16:33:59,143:INFO:Initializing plot_model()
2023-04-24 16:33:59,143:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:33:59,143:INFO:Checking exceptions
2023-04-24 16:33:59,149:INFO:Preloading libraries
2023-04-24 16:33:59,150:INFO:Copying training dataset
2023-04-24 16:33:59,150:INFO:Plot type: auc
2023-04-24 16:33:59,454:INFO:Fitting Model
2023-04-24 16:33:59,457:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-04-24 16:33:59,457:INFO:Scoring test/hold-out set
2023-04-24 16:33:59,497:INFO:Saving 'AUC.png'
2023-04-24 16:33:59,611:INFO:Visual Rendered Successfully
2023-04-24 16:33:59,676:INFO:plot_model() successfully completed......................................
2023-04-24 16:33:59,676:INFO:Initializing plot_model()
2023-04-24 16:33:59,676:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:33:59,676:INFO:Checking exceptions
2023-04-24 16:33:59,682:INFO:Preloading libraries
2023-04-24 16:33:59,682:INFO:Copying training dataset
2023-04-24 16:33:59,683:INFO:Plot type: confusion_matrix
2023-04-24 16:34:00,000:INFO:Fitting Model
2023-04-24 16:34:00,001:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-04-24 16:34:00,001:INFO:Scoring test/hold-out set
2023-04-24 16:34:00,022:INFO:Saving 'Confusion Matrix.png'
2023-04-24 16:34:00,080:INFO:Visual Rendered Successfully
2023-04-24 16:34:00,142:INFO:plot_model() successfully completed......................................
2023-04-24 16:50:11,285:INFO:Initializing create_model()
2023-04-24 16:50:11,286:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=lr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:50:11,286:INFO:Checking exceptions
2023-04-24 16:50:11,316:INFO:Importing libraries
2023-04-24 16:50:11,316:INFO:Copying training dataset
2023-04-24 16:50:11,350:INFO:Defining folds
2023-04-24 16:50:11,350:INFO:Declaring metric variables
2023-04-24 16:50:11,353:INFO:Importing untrained model
2023-04-24 16:50:11,355:INFO:Logistic Regression Imported successfully
2023-04-24 16:50:11,360:INFO:Starting cross validation
2023-04-24 16:50:11,372:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:50:16,430:INFO:Calculating mean and std
2023-04-24 16:50:16,433:INFO:Creating metrics dataframe
2023-04-24 16:50:16,438:INFO:Finalizing model
2023-04-24 16:50:17,058:INFO:Uploading results into container
2023-04-24 16:50:17,058:INFO:Uploading model into container now
2023-04-24 16:50:17,064:INFO:_master_model_container: 27
2023-04-24 16:50:17,064:INFO:_display_container: 17
2023-04-24 16:50:17,065:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 16:50:17,065:INFO:create_model() successfully completed......................................
2023-04-24 16:50:17,190:INFO:Initializing tune_model()
2023-04-24 16:50:17,190:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 16:50:17,190:INFO:Checking exceptions
2023-04-24 16:50:17,212:INFO:Copying training dataset
2023-04-24 16:50:17,231:INFO:Checking base model
2023-04-24 16:50:17,231:INFO:Base model : Logistic Regression
2023-04-24 16:50:17,233:INFO:Declaring metric variables
2023-04-24 16:50:17,236:INFO:Defining Hyperparameters
2023-04-24 16:50:17,306:INFO:Tuning with n_jobs=-1
2023-04-24 16:50:17,306:INFO:Initializing RandomizedSearchCV
2023-04-24 16:50:24,354:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 0.041}
2023-04-24 16:50:24,355:INFO:Hyperparameter search completed
2023-04-24 16:50:24,356:INFO:SubProcess create_model() called ==================================
2023-04-24 16:50:24,356:INFO:Initializing create_model()
2023-04-24 16:50:24,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd7356af640>, model_only=True, return_train_score=False, kwargs={'class_weight': {}, 'C': 0.041})
2023-04-24 16:50:24,356:INFO:Checking exceptions
2023-04-24 16:50:24,356:INFO:Importing libraries
2023-04-24 16:50:24,356:INFO:Copying training dataset
2023-04-24 16:50:24,375:INFO:Defining folds
2023-04-24 16:50:24,376:INFO:Declaring metric variables
2023-04-24 16:50:24,378:INFO:Importing untrained model
2023-04-24 16:50:24,378:INFO:Declaring custom model
2023-04-24 16:50:24,381:INFO:Logistic Regression Imported successfully
2023-04-24 16:50:24,385:INFO:Starting cross validation
2023-04-24 16:50:24,397:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:50:25,363:INFO:Calculating mean and std
2023-04-24 16:50:25,364:INFO:Creating metrics dataframe
2023-04-24 16:50:25,368:INFO:Finalizing model
2023-04-24 16:50:25,964:INFO:Uploading results into container
2023-04-24 16:50:25,964:INFO:Uploading model into container now
2023-04-24 16:50:25,965:INFO:_master_model_container: 28
2023-04-24 16:50:25,965:INFO:_display_container: 18
2023-04-24 16:50:25,965:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 16:50:25,965:INFO:create_model() successfully completed......................................
2023-04-24 16:50:26,040:INFO:SubProcess create_model() end ==================================
2023-04-24 16:50:26,041:INFO:choose_better activated
2023-04-24 16:50:26,043:INFO:SubProcess create_model() called ==================================
2023-04-24 16:50:26,043:INFO:Initializing create_model()
2023-04-24 16:50:26,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:50:26,043:INFO:Checking exceptions
2023-04-24 16:50:26,044:INFO:Importing libraries
2023-04-24 16:50:26,044:INFO:Copying training dataset
2023-04-24 16:50:26,058:INFO:Defining folds
2023-04-24 16:50:26,058:INFO:Declaring metric variables
2023-04-24 16:50:26,058:INFO:Importing untrained model
2023-04-24 16:50:26,058:INFO:Declaring custom model
2023-04-24 16:50:26,059:INFO:Logistic Regression Imported successfully
2023-04-24 16:50:26,059:INFO:Starting cross validation
2023-04-24 16:50:26,066:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:50:27,025:INFO:Calculating mean and std
2023-04-24 16:50:27,026:INFO:Creating metrics dataframe
2023-04-24 16:50:27,027:INFO:Finalizing model
2023-04-24 16:50:27,536:INFO:Uploading results into container
2023-04-24 16:50:27,536:INFO:Uploading model into container now
2023-04-24 16:50:27,536:INFO:_master_model_container: 29
2023-04-24 16:50:27,536:INFO:_display_container: 19
2023-04-24 16:50:27,537:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 16:50:27,537:INFO:create_model() successfully completed......................................
2023-04-24 16:50:27,596:INFO:SubProcess create_model() end ==================================
2023-04-24 16:50:27,597:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8485
2023-04-24 16:50:27,597:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8537
2023-04-24 16:50:27,597:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-04-24 16:50:27,597:INFO:choose_better completed
2023-04-24 16:50:27,602:INFO:_master_model_container: 29
2023-04-24 16:50:27,602:INFO:_display_container: 18
2023-04-24 16:50:27,603:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 16:50:27,603:INFO:tune_model() successfully completed......................................
2023-04-24 16:50:27,752:INFO:Initializing plot_model()
2023-04-24 16:50:27,752:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:50:27,752:INFO:Checking exceptions
2023-04-24 16:50:27,758:INFO:Preloading libraries
2023-04-24 16:50:27,758:INFO:Copying training dataset
2023-04-24 16:50:27,758:INFO:Plot type: feature
2023-04-24 16:50:27,936:INFO:Saving 'Feature Importance.png'
2023-04-24 16:50:28,026:INFO:Visual Rendered Successfully
2023-04-24 16:50:28,089:INFO:plot_model() successfully completed......................................
2023-04-24 16:50:28,089:INFO:Initializing plot_model()
2023-04-24 16:50:28,089:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:50:28,089:INFO:Checking exceptions
2023-04-24 16:50:28,096:INFO:Preloading libraries
2023-04-24 16:50:28,096:INFO:Copying training dataset
2023-04-24 16:50:28,096:INFO:Plot type: auc
2023-04-24 16:50:28,435:INFO:Fitting Model
2023-04-24 16:50:28,436:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-04-24 16:50:28,436:INFO:Scoring test/hold-out set
2023-04-24 16:50:28,474:INFO:Saving 'AUC.png'
2023-04-24 16:50:28,597:INFO:Visual Rendered Successfully
2023-04-24 16:50:28,664:INFO:plot_model() successfully completed......................................
2023-04-24 16:50:28,664:INFO:Initializing plot_model()
2023-04-24 16:50:28,664:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:50:28,664:INFO:Checking exceptions
2023-04-24 16:50:28,670:INFO:Preloading libraries
2023-04-24 16:50:28,671:INFO:Copying training dataset
2023-04-24 16:50:28,671:INFO:Plot type: confusion_matrix
2023-04-24 16:50:28,967:INFO:Fitting Model
2023-04-24 16:50:28,967:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-04-24 16:50:28,968:INFO:Scoring test/hold-out set
2023-04-24 16:50:28,984:INFO:Saving 'Confusion Matrix.png'
2023-04-24 16:50:29,037:INFO:Visual Rendered Successfully
2023-04-24 16:50:29,098:INFO:plot_model() successfully completed......................................
2023-04-24 16:50:56,694:INFO:Initializing create_model()
2023-04-24 16:50:56,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=lr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:50:56,695:INFO:Checking exceptions
2023-04-24 16:50:56,719:INFO:Importing libraries
2023-04-24 16:50:56,719:INFO:Copying training dataset
2023-04-24 16:50:56,739:INFO:Defining folds
2023-04-24 16:50:56,739:INFO:Declaring metric variables
2023-04-24 16:50:56,742:INFO:Importing untrained model
2023-04-24 16:50:56,745:INFO:Logistic Regression Imported successfully
2023-04-24 16:50:56,748:INFO:Starting cross validation
2023-04-24 16:50:56,757:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:50:57,896:INFO:Calculating mean and std
2023-04-24 16:50:57,897:INFO:Creating metrics dataframe
2023-04-24 16:50:57,900:INFO:Finalizing model
2023-04-24 16:50:58,462:INFO:Uploading results into container
2023-04-24 16:50:58,463:INFO:Uploading model into container now
2023-04-24 16:50:58,469:INFO:_master_model_container: 30
2023-04-24 16:50:58,469:INFO:_display_container: 19
2023-04-24 16:50:58,469:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 16:50:58,470:INFO:create_model() successfully completed......................................
2023-04-24 16:50:58,531:INFO:Initializing tune_model()
2023-04-24 16:50:58,532:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 16:50:58,532:INFO:Checking exceptions
2023-04-24 16:50:58,551:INFO:Copying training dataset
2023-04-24 16:50:58,571:INFO:Checking base model
2023-04-24 16:50:58,571:INFO:Base model : Logistic Regression
2023-04-24 16:50:58,574:INFO:Declaring metric variables
2023-04-24 16:50:58,576:INFO:Defining Hyperparameters
2023-04-24 16:50:58,644:INFO:Tuning with n_jobs=-1
2023-04-24 16:50:58,644:INFO:Initializing RandomizedSearchCV
2023-04-24 16:51:05,170:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 0.041}
2023-04-24 16:51:05,180:INFO:Hyperparameter search completed
2023-04-24 16:51:05,180:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:05,181:INFO:Initializing create_model()
2023-04-24 16:51:05,181:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd700263cd0>, model_only=True, return_train_score=False, kwargs={'class_weight': {}, 'C': 0.041})
2023-04-24 16:51:05,181:INFO:Checking exceptions
2023-04-24 16:51:05,181:INFO:Importing libraries
2023-04-24 16:51:05,182:INFO:Copying training dataset
2023-04-24 16:51:05,216:INFO:Defining folds
2023-04-24 16:51:05,216:INFO:Declaring metric variables
2023-04-24 16:51:05,219:INFO:Importing untrained model
2023-04-24 16:51:05,220:INFO:Declaring custom model
2023-04-24 16:51:05,222:INFO:Logistic Regression Imported successfully
2023-04-24 16:51:05,226:INFO:Starting cross validation
2023-04-24 16:51:05,251:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:06,232:INFO:Calculating mean and std
2023-04-24 16:51:06,234:INFO:Creating metrics dataframe
2023-04-24 16:51:06,238:INFO:Finalizing model
2023-04-24 16:51:06,817:INFO:Uploading results into container
2023-04-24 16:51:06,817:INFO:Uploading model into container now
2023-04-24 16:51:06,818:INFO:_master_model_container: 31
2023-04-24 16:51:06,818:INFO:_display_container: 20
2023-04-24 16:51:06,818:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 16:51:06,818:INFO:create_model() successfully completed......................................
2023-04-24 16:51:06,940:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:06,941:INFO:choose_better activated
2023-04-24 16:51:06,943:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:06,943:INFO:Initializing create_model()
2023-04-24 16:51:06,943:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:06,943:INFO:Checking exceptions
2023-04-24 16:51:06,944:INFO:Importing libraries
2023-04-24 16:51:06,944:INFO:Copying training dataset
2023-04-24 16:51:06,957:INFO:Defining folds
2023-04-24 16:51:06,958:INFO:Declaring metric variables
2023-04-24 16:51:06,958:INFO:Importing untrained model
2023-04-24 16:51:06,958:INFO:Declaring custom model
2023-04-24 16:51:06,958:INFO:Logistic Regression Imported successfully
2023-04-24 16:51:06,958:INFO:Starting cross validation
2023-04-24 16:51:06,966:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:07,953:INFO:Calculating mean and std
2023-04-24 16:51:07,953:INFO:Creating metrics dataframe
2023-04-24 16:51:07,954:INFO:Finalizing model
2023-04-24 16:51:08,494:INFO:Uploading results into container
2023-04-24 16:51:08,495:INFO:Uploading model into container now
2023-04-24 16:51:08,495:INFO:_master_model_container: 32
2023-04-24 16:51:08,495:INFO:_display_container: 21
2023-04-24 16:51:08,495:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 16:51:08,495:INFO:create_model() successfully completed......................................
2023-04-24 16:51:08,556:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:08,557:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8485
2023-04-24 16:51:08,557:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8537
2023-04-24 16:51:08,557:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-04-24 16:51:08,557:INFO:choose_better completed
2023-04-24 16:51:08,563:INFO:_master_model_container: 32
2023-04-24 16:51:08,563:INFO:_display_container: 20
2023-04-24 16:51:08,563:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 16:51:08,563:INFO:tune_model() successfully completed......................................
2023-04-24 16:51:08,736:INFO:Initializing plot_model()
2023-04-24 16:51:08,736:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:51:08,736:INFO:Checking exceptions
2023-04-24 16:51:08,744:INFO:Preloading libraries
2023-04-24 16:51:08,744:INFO:Copying training dataset
2023-04-24 16:51:08,744:INFO:Plot type: feature
2023-04-24 16:51:08,914:INFO:Saving 'Feature Importance.png'
2023-04-24 16:51:08,992:INFO:Visual Rendered Successfully
2023-04-24 16:51:09,053:INFO:plot_model() successfully completed......................................
2023-04-24 16:51:09,053:INFO:Initializing plot_model()
2023-04-24 16:51:09,053:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:51:09,053:INFO:Checking exceptions
2023-04-24 16:51:09,060:INFO:Preloading libraries
2023-04-24 16:51:09,060:INFO:Copying training dataset
2023-04-24 16:51:09,060:INFO:Plot type: auc
2023-04-24 16:51:09,363:INFO:Fitting Model
2023-04-24 16:51:09,363:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-04-24 16:51:09,364:INFO:Scoring test/hold-out set
2023-04-24 16:51:09,402:INFO:Saving 'AUC.png'
2023-04-24 16:51:09,510:INFO:Visual Rendered Successfully
2023-04-24 16:51:09,572:INFO:plot_model() successfully completed......................................
2023-04-24 16:51:09,572:INFO:Initializing plot_model()
2023-04-24 16:51:09,572:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:51:09,572:INFO:Checking exceptions
2023-04-24 16:51:09,578:INFO:Preloading libraries
2023-04-24 16:51:09,578:INFO:Copying training dataset
2023-04-24 16:51:09,578:INFO:Plot type: confusion_matrix
2023-04-24 16:51:09,867:INFO:Fitting Model
2023-04-24 16:51:09,868:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-04-24 16:51:09,868:INFO:Scoring test/hold-out set
2023-04-24 16:51:09,884:INFO:Saving 'Confusion Matrix.png'
2023-04-24 16:51:09,938:INFO:Visual Rendered Successfully
2023-04-24 16:51:10,002:INFO:plot_model() successfully completed......................................
2023-04-24 16:51:10,004:INFO:Initializing create_model()
2023-04-24 16:51:10,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=dt, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:10,004:INFO:Checking exceptions
2023-04-24 16:51:10,020:INFO:Importing libraries
2023-04-24 16:51:10,020:INFO:Copying training dataset
2023-04-24 16:51:10,037:INFO:Defining folds
2023-04-24 16:51:10,037:INFO:Declaring metric variables
2023-04-24 16:51:10,040:INFO:Importing untrained model
2023-04-24 16:51:10,042:INFO:Decision Tree Classifier Imported successfully
2023-04-24 16:51:10,046:INFO:Starting cross validation
2023-04-24 16:51:10,054:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:11,045:INFO:Calculating mean and std
2023-04-24 16:51:11,046:INFO:Creating metrics dataframe
2023-04-24 16:51:11,050:INFO:Finalizing model
2023-04-24 16:51:11,625:INFO:Uploading results into container
2023-04-24 16:51:11,626:INFO:Uploading model into container now
2023-04-24 16:51:11,652:INFO:_master_model_container: 33
2023-04-24 16:51:11,653:INFO:_display_container: 21
2023-04-24 16:51:11,653:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best')
2023-04-24 16:51:11,653:INFO:create_model() successfully completed......................................
2023-04-24 16:51:11,718:INFO:Initializing tune_model()
2023-04-24 16:51:11,718:INFO:tune_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 16:51:11,718:INFO:Checking exceptions
2023-04-24 16:51:11,738:INFO:Copying training dataset
2023-04-24 16:51:11,749:INFO:Checking base model
2023-04-24 16:51:11,749:INFO:Base model : Decision Tree Classifier
2023-04-24 16:51:11,751:INFO:Declaring metric variables
2023-04-24 16:51:11,753:INFO:Defining Hyperparameters
2023-04-24 16:51:11,826:INFO:Tuning with n_jobs=-1
2023-04-24 16:51:11,826:INFO:Initializing RandomizedSearchCV
2023-04-24 16:51:18,081:INFO:best_params: {'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 13, 'actual_estimator__criterion': 'entropy'}
2023-04-24 16:51:18,083:INFO:Hyperparameter search completed
2023-04-24 16:51:18,084:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:18,084:INFO:Initializing create_model()
2023-04-24 16:51:18,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd735ce90d0>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0, 'max_features': 1.0, 'max_depth': 13, 'criterion': 'entropy'})
2023-04-24 16:51:18,084:INFO:Checking exceptions
2023-04-24 16:51:18,085:INFO:Importing libraries
2023-04-24 16:51:18,085:INFO:Copying training dataset
2023-04-24 16:51:18,105:INFO:Defining folds
2023-04-24 16:51:18,106:INFO:Declaring metric variables
2023-04-24 16:51:18,109:INFO:Importing untrained model
2023-04-24 16:51:18,109:INFO:Declaring custom model
2023-04-24 16:51:18,111:INFO:Decision Tree Classifier Imported successfully
2023-04-24 16:51:18,115:INFO:Starting cross validation
2023-04-24 16:51:18,125:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:19,109:INFO:Calculating mean and std
2023-04-24 16:51:19,110:INFO:Creating metrics dataframe
2023-04-24 16:51:19,114:INFO:Finalizing model
2023-04-24 16:51:19,753:INFO:Uploading results into container
2023-04-24 16:51:19,754:INFO:Uploading model into container now
2023-04-24 16:51:19,755:INFO:_master_model_container: 34
2023-04-24 16:51:19,755:INFO:_display_container: 22
2023-04-24 16:51:19,756:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best')
2023-04-24 16:51:19,756:INFO:create_model() successfully completed......................................
2023-04-24 16:51:19,907:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:19,908:INFO:choose_better activated
2023-04-24 16:51:19,910:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:19,910:INFO:Initializing create_model()
2023-04-24 16:51:19,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:19,910:INFO:Checking exceptions
2023-04-24 16:51:19,911:INFO:Importing libraries
2023-04-24 16:51:19,911:INFO:Copying training dataset
2023-04-24 16:51:19,927:INFO:Defining folds
2023-04-24 16:51:19,927:INFO:Declaring metric variables
2023-04-24 16:51:19,927:INFO:Importing untrained model
2023-04-24 16:51:19,927:INFO:Declaring custom model
2023-04-24 16:51:19,927:INFO:Decision Tree Classifier Imported successfully
2023-04-24 16:51:19,928:INFO:Starting cross validation
2023-04-24 16:51:19,934:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:20,984:INFO:Calculating mean and std
2023-04-24 16:51:20,984:INFO:Creating metrics dataframe
2023-04-24 16:51:20,986:INFO:Finalizing model
2023-04-24 16:51:21,487:INFO:Uploading results into container
2023-04-24 16:51:21,488:INFO:Uploading model into container now
2023-04-24 16:51:21,488:INFO:_master_model_container: 35
2023-04-24 16:51:21,488:INFO:_display_container: 23
2023-04-24 16:51:21,489:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best')
2023-04-24 16:51:21,489:INFO:create_model() successfully completed......................................
2023-04-24 16:51:21,549:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:21,550:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best') result for Accuracy is 0.783
2023-04-24 16:51:21,550:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best') result for Accuracy is 0.8315
2023-04-24 16:51:21,550:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best') is best model
2023-04-24 16:51:21,550:INFO:choose_better completed
2023-04-24 16:51:21,556:INFO:_master_model_container: 35
2023-04-24 16:51:21,556:INFO:_display_container: 22
2023-04-24 16:51:21,556:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best')
2023-04-24 16:51:21,556:INFO:tune_model() successfully completed......................................
2023-04-24 16:51:21,718:INFO:Initializing plot_model()
2023-04-24 16:51:21,718:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:51:21,718:INFO:Checking exceptions
2023-04-24 16:51:21,726:INFO:Preloading libraries
2023-04-24 16:51:21,726:INFO:Copying training dataset
2023-04-24 16:51:21,726:INFO:Plot type: feature
2023-04-24 16:51:21,727:WARNING:No coef_ found. Trying feature_importances_
2023-04-24 16:51:21,826:INFO:Saving 'Feature Importance.png'
2023-04-24 16:51:21,906:INFO:Visual Rendered Successfully
2023-04-24 16:51:21,967:INFO:plot_model() successfully completed......................................
2023-04-24 16:51:21,969:INFO:Initializing plot_model()
2023-04-24 16:51:21,969:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:51:21,969:INFO:Checking exceptions
2023-04-24 16:51:21,975:INFO:Preloading libraries
2023-04-24 16:51:21,975:INFO:Copying training dataset
2023-04-24 16:51:21,975:INFO:Plot type: auc
2023-04-24 16:51:22,265:INFO:Fitting Model
2023-04-24 16:51:22,266:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2023-04-24 16:51:22,267:INFO:Scoring test/hold-out set
2023-04-24 16:51:22,296:INFO:Saving 'AUC.png'
2023-04-24 16:51:22,392:INFO:Visual Rendered Successfully
2023-04-24 16:51:22,454:INFO:plot_model() successfully completed......................................
2023-04-24 16:51:22,454:INFO:Initializing plot_model()
2023-04-24 16:51:22,454:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:51:22,454:INFO:Checking exceptions
2023-04-24 16:51:22,460:INFO:Preloading libraries
2023-04-24 16:51:22,460:INFO:Copying training dataset
2023-04-24 16:51:22,460:INFO:Plot type: confusion_matrix
2023-04-24 16:51:22,744:INFO:Fitting Model
2023-04-24 16:51:22,744:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2023-04-24 16:51:22,745:INFO:Scoring test/hold-out set
2023-04-24 16:51:22,764:INFO:Saving 'Confusion Matrix.png'
2023-04-24 16:51:22,815:INFO:Visual Rendered Successfully
2023-04-24 16:51:22,877:INFO:plot_model() successfully completed......................................
2023-04-24 16:51:22,879:INFO:Initializing create_model()
2023-04-24 16:51:22,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:22,879:INFO:Checking exceptions
2023-04-24 16:51:22,894:INFO:Importing libraries
2023-04-24 16:51:22,895:INFO:Copying training dataset
2023-04-24 16:51:22,912:INFO:Defining folds
2023-04-24 16:51:22,912:INFO:Declaring metric variables
2023-04-24 16:51:22,914:INFO:Importing untrained model
2023-04-24 16:51:22,917:INFO:Random Forest Classifier Imported successfully
2023-04-24 16:51:22,921:INFO:Starting cross validation
2023-04-24 16:51:22,931:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:24,343:INFO:Calculating mean and std
2023-04-24 16:51:24,345:INFO:Creating metrics dataframe
2023-04-24 16:51:24,349:INFO:Finalizing model
2023-04-24 16:51:24,893:INFO:Uploading results into container
2023-04-24 16:51:24,894:INFO:Uploading model into container now
2023-04-24 16:51:24,899:INFO:_master_model_container: 36
2023-04-24 16:51:24,899:INFO:_display_container: 23
2023-04-24 16:51:24,899:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False)
2023-04-24 16:51:24,899:INFO:create_model() successfully completed......................................
2023-04-24 16:51:24,962:INFO:Initializing tune_model()
2023-04-24 16:51:24,962:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 16:51:24,963:INFO:Checking exceptions
2023-04-24 16:51:24,984:INFO:Copying training dataset
2023-04-24 16:51:24,995:INFO:Checking base model
2023-04-24 16:51:24,995:INFO:Base model : Random Forest Classifier
2023-04-24 16:51:24,998:INFO:Declaring metric variables
2023-04-24 16:51:25,000:INFO:Defining Hyperparameters
2023-04-24 16:51:25,068:INFO:Tuning with n_jobs=-1
2023-04-24 16:51:25,068:INFO:Initializing RandomizedSearchCV
2023-04-24 16:51:31,912:INFO:best_params: {'actual_estimator__n_estimators': 220, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-04-24 16:51:31,916:INFO:Hyperparameter search completed
2023-04-24 16:51:31,916:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:31,917:INFO:Initializing create_model()
2023-04-24 16:51:31,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd720a61be0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 220, 'min_samples_split': 9, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0001, 'max_features': 'log2', 'max_depth': 7, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-04-24 16:51:31,917:INFO:Checking exceptions
2023-04-24 16:51:31,917:INFO:Importing libraries
2023-04-24 16:51:31,917:INFO:Copying training dataset
2023-04-24 16:51:31,944:INFO:Defining folds
2023-04-24 16:51:31,944:INFO:Declaring metric variables
2023-04-24 16:51:31,948:INFO:Importing untrained model
2023-04-24 16:51:31,948:INFO:Declaring custom model
2023-04-24 16:51:31,950:INFO:Random Forest Classifier Imported successfully
2023-04-24 16:51:31,955:INFO:Starting cross validation
2023-04-24 16:51:31,974:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:33,420:INFO:Calculating mean and std
2023-04-24 16:51:33,421:INFO:Creating metrics dataframe
2023-04-24 16:51:33,425:INFO:Finalizing model
2023-04-24 16:51:34,090:INFO:Uploading results into container
2023-04-24 16:51:34,091:INFO:Uploading model into container now
2023-04-24 16:51:34,091:INFO:_master_model_container: 37
2023-04-24 16:51:34,091:INFO:_display_container: 24
2023-04-24 16:51:34,092:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=7, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0001,
                       min_samples_leaf=4, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=220,
                       n_jobs=-1, oob_score=False, random_state=8216, verbose=0,
                       warm_start=False)
2023-04-24 16:51:34,092:INFO:create_model() successfully completed......................................
2023-04-24 16:51:34,232:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:34,232:INFO:choose_better activated
2023-04-24 16:51:34,234:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:34,235:INFO:Initializing create_model()
2023-04-24 16:51:34,235:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:34,235:INFO:Checking exceptions
2023-04-24 16:51:34,236:INFO:Importing libraries
2023-04-24 16:51:34,236:INFO:Copying training dataset
2023-04-24 16:51:34,250:INFO:Defining folds
2023-04-24 16:51:34,251:INFO:Declaring metric variables
2023-04-24 16:51:34,251:INFO:Importing untrained model
2023-04-24 16:51:34,251:INFO:Declaring custom model
2023-04-24 16:51:34,251:INFO:Random Forest Classifier Imported successfully
2023-04-24 16:51:34,251:INFO:Starting cross validation
2023-04-24 16:51:34,260:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:35,577:INFO:Calculating mean and std
2023-04-24 16:51:35,577:INFO:Creating metrics dataframe
2023-04-24 16:51:35,579:INFO:Finalizing model
2023-04-24 16:51:36,154:INFO:Uploading results into container
2023-04-24 16:51:36,154:INFO:Uploading model into container now
2023-04-24 16:51:36,155:INFO:_master_model_container: 38
2023-04-24 16:51:36,155:INFO:_display_container: 25
2023-04-24 16:51:36,155:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False)
2023-04-24 16:51:36,155:INFO:create_model() successfully completed......................................
2023-04-24 16:51:36,217:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:36,217:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False) result for Accuracy is 0.879
2023-04-24 16:51:36,218:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=7, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0001,
                       min_samples_leaf=4, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=220,
                       n_jobs=-1, oob_score=False, random_state=8216, verbose=0,
                       warm_start=False) result for Accuracy is 0.87
2023-04-24 16:51:36,218:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False) is best model
2023-04-24 16:51:36,218:INFO:choose_better completed
2023-04-24 16:51:36,218:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-24 16:51:36,224:INFO:_master_model_container: 38
2023-04-24 16:51:36,224:INFO:_display_container: 24
2023-04-24 16:51:36,224:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False)
2023-04-24 16:51:36,224:INFO:tune_model() successfully completed......................................
2023-04-24 16:51:36,393:INFO:Initializing plot_model()
2023-04-24 16:51:36,393:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:51:36,393:INFO:Checking exceptions
2023-04-24 16:51:36,410:INFO:Preloading libraries
2023-04-24 16:51:36,443:INFO:Copying training dataset
2023-04-24 16:51:36,444:INFO:Plot type: feature
2023-04-24 16:51:36,444:WARNING:No coef_ found. Trying feature_importances_
2023-04-24 16:51:36,570:INFO:Saving 'Feature Importance.png'
2023-04-24 16:51:36,654:INFO:Visual Rendered Successfully
2023-04-24 16:51:36,719:INFO:plot_model() successfully completed......................................
2023-04-24 16:51:36,719:INFO:Initializing plot_model()
2023-04-24 16:51:36,719:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:51:36,719:INFO:Checking exceptions
2023-04-24 16:51:36,735:INFO:Preloading libraries
2023-04-24 16:51:36,758:INFO:Copying training dataset
2023-04-24 16:51:36,758:INFO:Plot type: auc
2023-04-24 16:51:37,061:INFO:Fitting Model
2023-04-24 16:51:37,062:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-04-24 16:51:37,063:INFO:Scoring test/hold-out set
2023-04-24 16:51:37,187:INFO:Saving 'AUC.png'
2023-04-24 16:51:37,283:INFO:Visual Rendered Successfully
2023-04-24 16:51:37,347:INFO:plot_model() successfully completed......................................
2023-04-24 16:51:37,347:INFO:Initializing plot_model()
2023-04-24 16:51:37,347:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:51:37,347:INFO:Checking exceptions
2023-04-24 16:51:37,364:INFO:Preloading libraries
2023-04-24 16:51:37,391:INFO:Copying training dataset
2023-04-24 16:51:37,391:INFO:Plot type: confusion_matrix
2023-04-24 16:51:37,678:INFO:Fitting Model
2023-04-24 16:51:37,678:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-04-24 16:51:37,679:INFO:Scoring test/hold-out set
2023-04-24 16:51:37,793:INFO:Saving 'Confusion Matrix.png'
2023-04-24 16:51:37,847:INFO:Visual Rendered Successfully
2023-04-24 16:51:37,911:INFO:plot_model() successfully completed......................................
2023-04-24 16:51:37,927:INFO:Initializing create_model()
2023-04-24 16:51:37,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=ada, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:37,927:INFO:Checking exceptions
2023-04-24 16:51:37,942:INFO:Importing libraries
2023-04-24 16:51:37,943:INFO:Copying training dataset
2023-04-24 16:51:37,959:INFO:Defining folds
2023-04-24 16:51:37,959:INFO:Declaring metric variables
2023-04-24 16:51:37,962:INFO:Importing untrained model
2023-04-24 16:51:37,964:INFO:Ada Boost Classifier Imported successfully
2023-04-24 16:51:37,968:INFO:Starting cross validation
2023-04-24 16:51:37,976:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:39,168:INFO:Calculating mean and std
2023-04-24 16:51:39,170:INFO:Creating metrics dataframe
2023-04-24 16:51:39,174:INFO:Finalizing model
2023-04-24 16:51:39,734:INFO:Uploading results into container
2023-04-24 16:51:39,735:INFO:Uploading model into container now
2023-04-24 16:51:39,741:INFO:_master_model_container: 39
2023-04-24 16:51:39,741:INFO:_display_container: 25
2023-04-24 16:51:39,741:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216)
2023-04-24 16:51:39,741:INFO:create_model() successfully completed......................................
2023-04-24 16:51:39,805:INFO:Initializing tune_model()
2023-04-24 16:51:39,805:INFO:tune_model(estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 16:51:39,805:INFO:Checking exceptions
2023-04-24 16:51:39,826:INFO:Copying training dataset
2023-04-24 16:51:39,838:INFO:Checking base model
2023-04-24 16:51:39,838:INFO:Base model : Ada Boost Classifier
2023-04-24 16:51:39,840:INFO:Declaring metric variables
2023-04-24 16:51:39,842:INFO:Defining Hyperparameters
2023-04-24 16:51:39,912:INFO:Tuning with n_jobs=-1
2023-04-24 16:51:39,913:INFO:Initializing RandomizedSearchCV
2023-04-24 16:51:47,594:INFO:best_params: {'actual_estimator__n_estimators': 150, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__algorithm': 'SAMME.R'}
2023-04-24 16:51:47,598:INFO:Hyperparameter search completed
2023-04-24 16:51:47,598:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:47,599:INFO:Initializing create_model()
2023-04-24 16:51:47,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd7449175e0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 150, 'learning_rate': 0.4, 'algorithm': 'SAMME.R'})
2023-04-24 16:51:47,599:INFO:Checking exceptions
2023-04-24 16:51:47,599:INFO:Importing libraries
2023-04-24 16:51:47,599:INFO:Copying training dataset
2023-04-24 16:51:47,634:INFO:Defining folds
2023-04-24 16:51:47,634:INFO:Declaring metric variables
2023-04-24 16:51:47,638:INFO:Importing untrained model
2023-04-24 16:51:47,638:INFO:Declaring custom model
2023-04-24 16:51:47,641:INFO:Ada Boost Classifier Imported successfully
2023-04-24 16:51:47,644:INFO:Starting cross validation
2023-04-24 16:51:47,661:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:49,206:INFO:Calculating mean and std
2023-04-24 16:51:49,207:INFO:Creating metrics dataframe
2023-04-24 16:51:49,211:INFO:Finalizing model
2023-04-24 16:51:49,871:INFO:Uploading results into container
2023-04-24 16:51:49,872:INFO:Uploading model into container now
2023-04-24 16:51:49,872:INFO:_master_model_container: 40
2023-04-24 16:51:49,872:INFO:_display_container: 26
2023-04-24 16:51:49,874:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216)
2023-04-24 16:51:49,874:INFO:create_model() successfully completed......................................
2023-04-24 16:51:50,001:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:50,001:INFO:choose_better activated
2023-04-24 16:51:50,003:INFO:SubProcess create_model() called ==================================
2023-04-24 16:51:50,004:INFO:Initializing create_model()
2023-04-24 16:51:50,004:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:50,004:INFO:Checking exceptions
2023-04-24 16:51:50,005:INFO:Importing libraries
2023-04-24 16:51:50,005:INFO:Copying training dataset
2023-04-24 16:51:50,018:INFO:Defining folds
2023-04-24 16:51:50,018:INFO:Declaring metric variables
2023-04-24 16:51:50,018:INFO:Importing untrained model
2023-04-24 16:51:50,018:INFO:Declaring custom model
2023-04-24 16:51:50,018:INFO:Ada Boost Classifier Imported successfully
2023-04-24 16:51:50,019:INFO:Starting cross validation
2023-04-24 16:51:50,025:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:51,210:INFO:Calculating mean and std
2023-04-24 16:51:51,210:INFO:Creating metrics dataframe
2023-04-24 16:51:51,212:INFO:Finalizing model
2023-04-24 16:51:51,713:INFO:Uploading results into container
2023-04-24 16:51:51,714:INFO:Uploading model into container now
2023-04-24 16:51:51,714:INFO:_master_model_container: 41
2023-04-24 16:51:51,714:INFO:_display_container: 27
2023-04-24 16:51:51,714:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216)
2023-04-24 16:51:51,714:INFO:create_model() successfully completed......................................
2023-04-24 16:51:51,778:INFO:SubProcess create_model() end ==================================
2023-04-24 16:51:51,779:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216) result for Accuracy is 0.8476
2023-04-24 16:51:51,779:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216) result for Accuracy is 0.8492
2023-04-24 16:51:51,779:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216) is best model
2023-04-24 16:51:51,779:INFO:choose_better completed
2023-04-24 16:51:51,785:INFO:_master_model_container: 41
2023-04-24 16:51:51,785:INFO:_display_container: 26
2023-04-24 16:51:51,785:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216)
2023-04-24 16:51:51,785:INFO:tune_model() successfully completed......................................
2023-04-24 16:51:51,945:INFO:Initializing plot_model()
2023-04-24 16:51:51,945:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:51:51,945:INFO:Checking exceptions
2023-04-24 16:51:51,956:INFO:Preloading libraries
2023-04-24 16:51:51,963:INFO:Copying training dataset
2023-04-24 16:51:51,963:INFO:Plot type: feature
2023-04-24 16:51:51,964:WARNING:No coef_ found. Trying feature_importances_
2023-04-24 16:51:52,058:INFO:Saving 'Feature Importance.png'
2023-04-24 16:51:52,144:INFO:Visual Rendered Successfully
2023-04-24 16:51:52,207:INFO:plot_model() successfully completed......................................
2023-04-24 16:51:52,208:INFO:Initializing plot_model()
2023-04-24 16:51:52,208:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:51:52,208:INFO:Checking exceptions
2023-04-24 16:51:52,218:INFO:Preloading libraries
2023-04-24 16:51:52,225:INFO:Copying training dataset
2023-04-24 16:51:52,225:INFO:Plot type: auc
2023-04-24 16:51:52,522:INFO:Fitting Model
2023-04-24 16:51:52,523:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2023-04-24 16:51:52,523:INFO:Scoring test/hold-out set
2023-04-24 16:51:53,279:INFO:Saving 'AUC.png'
2023-04-24 16:51:53,388:INFO:Visual Rendered Successfully
2023-04-24 16:51:53,451:INFO:plot_model() successfully completed......................................
2023-04-24 16:51:53,452:INFO:Initializing plot_model()
2023-04-24 16:51:53,452:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:51:53,452:INFO:Checking exceptions
2023-04-24 16:51:53,460:INFO:Preloading libraries
2023-04-24 16:51:53,467:INFO:Copying training dataset
2023-04-24 16:51:53,467:INFO:Plot type: confusion_matrix
2023-04-24 16:51:53,756:INFO:Fitting Model
2023-04-24 16:51:53,757:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2023-04-24 16:51:53,757:INFO:Scoring test/hold-out set
2023-04-24 16:51:54,480:INFO:Saving 'Confusion Matrix.png'
2023-04-24 16:51:54,531:INFO:Visual Rendered Successfully
2023-04-24 16:51:54,594:INFO:plot_model() successfully completed......................................
2023-04-24 16:51:54,600:INFO:Initializing create_model()
2023-04-24 16:51:54,600:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:51:54,600:INFO:Checking exceptions
2023-04-24 16:51:54,616:INFO:Importing libraries
2023-04-24 16:51:54,616:INFO:Copying training dataset
2023-04-24 16:51:54,630:INFO:Defining folds
2023-04-24 16:51:54,630:INFO:Declaring metric variables
2023-04-24 16:51:54,633:INFO:Importing untrained model
2023-04-24 16:51:54,635:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 16:51:54,639:INFO:Starting cross validation
2023-04-24 16:51:54,648:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:51:56,777:INFO:Calculating mean and std
2023-04-24 16:51:56,779:INFO:Creating metrics dataframe
2023-04-24 16:51:56,786:INFO:Finalizing model
2023-04-24 16:51:57,319:INFO:Uploading results into container
2023-04-24 16:51:57,320:INFO:Uploading model into container now
2023-04-24 16:51:57,325:INFO:_master_model_container: 42
2023-04-24 16:51:57,326:INFO:_display_container: 27
2023-04-24 16:51:57,326:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-24 16:51:57,326:INFO:create_model() successfully completed......................................
2023-04-24 16:51:57,391:INFO:Initializing tune_model()
2023-04-24 16:51:57,392:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 16:51:57,392:INFO:Checking exceptions
2023-04-24 16:51:57,414:INFO:Copying training dataset
2023-04-24 16:51:57,424:INFO:Checking base model
2023-04-24 16:51:57,424:INFO:Base model : Light Gradient Boosting Machine
2023-04-24 16:51:57,427:INFO:Declaring metric variables
2023-04-24 16:51:57,429:INFO:Defining Hyperparameters
2023-04-24 16:51:57,501:INFO:Tuning with n_jobs=-1
2023-04-24 16:51:57,502:INFO:Initializing RandomizedSearchCV
2023-04-24 16:52:04,916:INFO:best_params: {'actual_estimator__reg_lambda': 0.01, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 21, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 1.0}
2023-04-24 16:52:04,919:INFO:Hyperparameter search completed
2023-04-24 16:52:04,919:INFO:SubProcess create_model() called ==================================
2023-04-24 16:52:04,920:INFO:Initializing create_model()
2023-04-24 16:52:04,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd69252c5e0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.01, 'reg_alpha': 0.0005, 'num_leaves': 256, 'n_estimators': 190, 'min_split_gain': 0.3, 'min_child_samples': 21, 'learning_rate': 0.01, 'feature_fraction': 0.6, 'bagging_freq': 5, 'bagging_fraction': 1.0})
2023-04-24 16:52:04,920:INFO:Checking exceptions
2023-04-24 16:52:04,921:INFO:Importing libraries
2023-04-24 16:52:04,921:INFO:Copying training dataset
2023-04-24 16:52:04,944:INFO:Defining folds
2023-04-24 16:52:04,944:INFO:Declaring metric variables
2023-04-24 16:52:04,947:INFO:Importing untrained model
2023-04-24 16:52:04,947:INFO:Declaring custom model
2023-04-24 16:52:04,950:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 16:52:04,954:INFO:Starting cross validation
2023-04-24 16:52:04,969:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:52:07,272:INFO:Calculating mean and std
2023-04-24 16:52:07,273:INFO:Creating metrics dataframe
2023-04-24 16:52:07,277:INFO:Finalizing model
2023-04-24 16:52:07,957:INFO:Uploading results into container
2023-04-24 16:52:07,957:INFO:Uploading model into container now
2023-04-24 16:52:07,958:INFO:_master_model_container: 43
2023-04-24 16:52:07,958:INFO:_display_container: 28
2023-04-24 16:52:07,958:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-04-24 16:52:07,958:INFO:create_model() successfully completed......................................
2023-04-24 16:52:08,091:INFO:SubProcess create_model() end ==================================
2023-04-24 16:52:08,091:INFO:choose_better activated
2023-04-24 16:52:08,094:INFO:SubProcess create_model() called ==================================
2023-04-24 16:52:08,094:INFO:Initializing create_model()
2023-04-24 16:52:08,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 16:52:08,094:INFO:Checking exceptions
2023-04-24 16:52:08,095:INFO:Importing libraries
2023-04-24 16:52:08,095:INFO:Copying training dataset
2023-04-24 16:52:08,108:INFO:Defining folds
2023-04-24 16:52:08,108:INFO:Declaring metric variables
2023-04-24 16:52:08,108:INFO:Importing untrained model
2023-04-24 16:52:08,108:INFO:Declaring custom model
2023-04-24 16:52:08,109:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 16:52:08,109:INFO:Starting cross validation
2023-04-24 16:52:08,116:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 16:52:09,500:INFO:Calculating mean and std
2023-04-24 16:52:09,501:INFO:Creating metrics dataframe
2023-04-24 16:52:09,502:INFO:Finalizing model
2023-04-24 16:52:10,034:INFO:Uploading results into container
2023-04-24 16:52:10,035:INFO:Uploading model into container now
2023-04-24 16:52:10,035:INFO:_master_model_container: 44
2023-04-24 16:52:10,035:INFO:_display_container: 29
2023-04-24 16:52:10,036:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-24 16:52:10,036:INFO:create_model() successfully completed......................................
2023-04-24 16:52:10,103:INFO:SubProcess create_model() end ==================================
2023-04-24 16:52:10,104:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.811
2023-04-24 16:52:10,104:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) result for Accuracy is 0.881
2023-04-24 16:52:10,104:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) is best model
2023-04-24 16:52:10,104:INFO:choose_better completed
2023-04-24 16:52:10,110:INFO:_master_model_container: 44
2023-04-24 16:52:10,110:INFO:_display_container: 28
2023-04-24 16:52:10,110:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-04-24 16:52:10,110:INFO:tune_model() successfully completed......................................
2023-04-24 16:52:10,275:INFO:Initializing plot_model()
2023-04-24 16:52:10,275:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:52:10,276:INFO:Checking exceptions
2023-04-24 16:52:10,284:INFO:Preloading libraries
2023-04-24 16:52:10,324:INFO:Copying training dataset
2023-04-24 16:52:10,325:INFO:Plot type: feature
2023-04-24 16:52:10,325:WARNING:No coef_ found. Trying feature_importances_
2023-04-24 16:52:10,421:INFO:Saving 'Feature Importance.png'
2023-04-24 16:52:10,502:INFO:Visual Rendered Successfully
2023-04-24 16:52:10,567:INFO:plot_model() successfully completed......................................
2023-04-24 16:52:10,568:INFO:Initializing plot_model()
2023-04-24 16:52:10,568:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:52:10,568:INFO:Checking exceptions
2023-04-24 16:52:10,574:INFO:Preloading libraries
2023-04-24 16:52:10,631:INFO:Copying training dataset
2023-04-24 16:52:10,631:INFO:Plot type: auc
2023-04-24 16:52:10,936:INFO:Fitting Model
2023-04-24 16:52:10,937:INFO:Scoring test/hold-out set
2023-04-24 16:52:11,183:INFO:Saving 'AUC.png'
2023-04-24 16:52:11,290:INFO:Visual Rendered Successfully
2023-04-24 16:52:11,355:INFO:plot_model() successfully completed......................................
2023-04-24 16:52:11,356:INFO:Initializing plot_model()
2023-04-24 16:52:11,356:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 16:52:11,356:INFO:Checking exceptions
2023-04-24 16:52:11,362:INFO:Preloading libraries
2023-04-24 16:52:11,412:INFO:Copying training dataset
2023-04-24 16:52:11,413:INFO:Plot type: confusion_matrix
2023-04-24 16:52:11,705:INFO:Fitting Model
2023-04-24 16:52:11,706:INFO:Scoring test/hold-out set
2023-04-24 16:52:11,955:INFO:Saving 'Confusion Matrix.png'
2023-04-24 16:52:12,011:INFO:Visual Rendered Successfully
2023-04-24 16:52:12,077:INFO:plot_model() successfully completed......................................
2023-04-24 17:44:59,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 17:44:59,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 17:44:59,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 17:44:59,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 17:44:59,484:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-24 17:45:37,992:INFO:Initializing load_model()
2023-04-24 17:45:37,993:INFO:load_model(model_name=/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/Light Gradient Boosting Machine/Model_Results/Model_Objects/lightgbm, platform=None, authentication=None, verbose=True)
2023-04-24 17:51:43,485:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 17:51:43,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 17:51:43,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 17:51:43,486:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 17:51:43,830:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-24 17:51:49,846:INFO:Initializing load_model()
2023-04-24 17:51:49,847:INFO:load_model(model_name=/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/rf/Model_Results/Model_Objects/rf.pickle, platform=None, authentication=None, verbose=True)
2023-04-24 17:52:41,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 17:52:41,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 17:52:41,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 17:52:41,870:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 17:52:42,219:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-24 17:52:50,339:INFO:Initializing load_model()
2023-04-24 17:52:50,340:INFO:load_model(model_name=/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/rf/Model_Results/Model_Objects/rf, platform=None, authentication=None, verbose=True)
2023-04-24 17:55:59,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 17:55:59,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 17:55:59,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 17:55:59,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 17:56:00,411:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-24 18:08:45,500:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.
Feature names unseen at fit time:
- Credit_Mix
- Occupation
- Payment_Behaviour
- Payment_of_Min_Amount
Feature names seen at fit time, yet now missing:
- Credit_Mix_Bad
- Credit_Mix_Good
- Credit_Mix_Standard
- Credit_Mix__
- Occupation_Accountant
- ...

  warnings.warn(message, FutureWarning)

2023-04-24 18:22:46,903:INFO:Initializing get_config()
2023-04-24 18:22:46,908:INFO:get_config(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, variable=X_train)
2023-04-24 18:22:46,916:INFO:Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
2023-04-24 18:22:46,920:WARNING:/opt/anaconda3/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/pycaret_experiment.py:322: UserWarning: Variable: 'X_train' used to return the transformed values in PyCaret 2.x. From PyCaret 3.x, this will return the raw values. If you need the transformed values, call get_config with 'X_train_transformed' instead.
  warnings.warn(msg)  # print on screen

2023-04-24 18:22:46,998:INFO:Variable:  returned as       Age    Occupation  Annual_Income  Monthly_Inhand_Salary  \
12135  49  Entrepreneur  123299.117188            4194.170898   
46110  37      Engineer   57227.039062            4561.919922   
68528  35      Engineer    9743.959961             889.996643   
48736  17    Journalist    8205.139648             962.761658   
694    22       _______   66105.398438            5653.783203   
...    ..           ...            ...                    ...   
97149  34       Manager   24873.099609            1848.758301   
89704  38  Entrepreneur   76519.296875            6277.608398   
7724   50        Doctor   24667.160156            2284.596680   
45557  21     Developer   17137.570312            1617.130859   
72271  33     Scientist   16218.320312            1098.526611   

       Num_Bank_Accounts  Num_Credit_Card  Interest_Rate  Num_of_Loan  \
12135                  2                2              8          100   
46110                  9                9             16            7   
68528                  8                7              4            4   
48736                  9                9             34            8   
694                    6                8             31            5   
...                  ...              ...            ...          ...   
97149                  3                6              8            3   
89704                  5                7             10            4   
7724                   8                6             16            3   
45557                  8                7             34            9   
72271                  6                6             21            5   

                                            Type_of_Loan Delay_from_due_date  \
12135  Not Specified, Credit-Builder Loan, and Credit...                  10   
46110  Not Specified, Credit-Builder Loan, Auto Loan,...                  39   
68528  Payday Loan, Debt Consolidation Loan, Not Spec...                  20   
48736  Auto Loan, Auto Loan, Payday Loan, Home Equity...                  36   
694    Mortgage Loan, Auto Loan, Not Specified, Stude...                  26   
...                                                  ...                 ...   
97149        Auto Loan, Mortgage Loan, and Not Specified                  23   
89704  Student Loan, Home Equity Loan, Auto Loan, and...                   5   
7724   Debt Consolidation Loan, Mortgage Loan, and Ho...                   8   
45557  Debt Consolidation Loan, Student Loan, Debt Co...                  22   
72271  Mortgage Loan, Home Equity Loan, Credit-Builde...                  48   

       ...  Num_Credit_Inquiries Credit_Mix  Outstanding_Debt  \
12135  ...                   7.0       Good        845.469971   
46110  ...                   9.0        Bad       3902.969971   
68528  ...                   0.0          _        625.729980   
48736  ...                   6.0        Bad       3176.860107   
694    ...                  12.0        Bad       1549.560059   
...    ...                   ...        ...               ...   
97149  ...                   6.0          _         30.309999   
89704  ...                   3.0       Good        260.850006   
7724   ...                   5.0   Standard        722.020020   
45557  ...                  16.0          _       3680.600098   
72271  ...                  10.0        Bad       4466.330078   

      Credit_Utilization_Ratio  Credit_History_Age  Payment_of_Min_Amount  \
12135                32.322124                 NaN                     No   
46110                37.820419               101.0                    Yes   
68528                28.733507               196.0                     No   
48736                36.307137                 2.0                    Yes   
694                  38.648224               140.0                     NM   
...                        ...                 ...                    ...   
97149                29.124367                67.0                    Yes   
89704                36.584496               380.0                     No   
7724                 27.607992               235.0                    Yes   
45557                30.934248               110.0                    Yes   
72271                32.977642               104.0                    Yes   

       Total_EMI_per_month Amount_invested_monthly  \
12135    289.4723048639328                     NaN   
46110   220.27681374800392              182.419662   
68528    18.85845156233991               66.285095   
48736    53.99910271431013               86.661674   
694     214.07212305606225              274.572662   
...                    ...                     ...   
97149    39.84069977161735               56.810616   
89704    228.5434193935592              189.472275   
7724     49.23739807081449               67.565186   
45557    119.5320319672674              122.757576   
72271     64.5331137101069               52.077778   

                      Payment_Behaviour  Monthly_Balance  
12135   High_spent_Large_value_payments       851.332825  
46110    Low_spent_Large_value_payments       323.495514  
68528    Low_spent_Small_value_payments       293.856110  
48736   Low_spent_Medium_value_payments       235.615387  
694      Low_spent_Small_value_payments       366.733551  
...                                 ...              ...  
97149   Low_spent_Medium_value_payments       368.224518  
89704  High_spent_Medium_value_payments       459.745148  
7724   High_spent_Medium_value_payments       361.657074  
45557    Low_spent_Small_value_payments       209.423477  
72271    Low_spent_Small_value_payments       283.241791  

[70000 rows x 22 columns]
2023-04-24 18:22:46,998:INFO:get_config() successfully completed......................................
2023-04-24 18:29:04,143:INFO:Initializing create_model()
2023-04-24 18:29:04,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=lr, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 18:29:04,143:INFO:Checking exceptions
2023-04-24 18:29:04,194:INFO:Importing libraries
2023-04-24 18:29:04,195:INFO:Copying training dataset
2023-04-24 18:29:04,245:INFO:Defining folds
2023-04-24 18:29:04,245:INFO:Declaring metric variables
2023-04-24 18:29:04,248:INFO:Importing untrained model
2023-04-24 18:29:04,253:INFO:Logistic Regression Imported successfully
2023-04-24 18:29:04,259:INFO:Starting cross validation
2023-04-24 18:29:04,638:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 18:29:09,907:INFO:Calculating mean and std
2023-04-24 18:29:09,909:INFO:Creating metrics dataframe
2023-04-24 18:29:09,915:INFO:Finalizing model
2023-04-24 18:29:10,859:INFO:Uploading results into container
2023-04-24 18:29:10,860:INFO:Uploading model into container now
2023-04-24 18:29:10,866:INFO:_master_model_container: 45
2023-04-24 18:29:10,867:INFO:_display_container: 29
2023-04-24 18:29:10,867:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 18:29:10,867:INFO:create_model() successfully completed......................................
2023-04-24 18:29:10,983:INFO:Initializing tune_model()
2023-04-24 18:29:10,983:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 18:29:10,983:INFO:Checking exceptions
2023-04-24 18:29:11,010:INFO:Copying training dataset
2023-04-24 18:29:11,058:INFO:Checking base model
2023-04-24 18:29:11,058:INFO:Base model : Logistic Regression
2023-04-24 18:29:11,061:INFO:Declaring metric variables
2023-04-24 18:29:11,063:INFO:Defining Hyperparameters
2023-04-24 18:29:11,161:INFO:Tuning with n_jobs=-1
2023-04-24 18:29:11,161:INFO:Initializing RandomizedSearchCV
2023-04-24 18:29:18,930:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 0.041}
2023-04-24 18:29:18,933:INFO:Hyperparameter search completed
2023-04-24 18:29:18,933:INFO:SubProcess create_model() called ==================================
2023-04-24 18:29:18,934:INFO:Initializing create_model()
2023-04-24 18:29:18,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd6e8e27be0>, model_only=True, return_train_score=False, kwargs={'class_weight': {}, 'C': 0.041})
2023-04-24 18:29:18,934:INFO:Checking exceptions
2023-04-24 18:29:18,935:INFO:Importing libraries
2023-04-24 18:29:18,935:INFO:Copying training dataset
2023-04-24 18:29:18,968:INFO:Defining folds
2023-04-24 18:29:18,969:INFO:Declaring metric variables
2023-04-24 18:29:18,973:INFO:Importing untrained model
2023-04-24 18:29:18,973:INFO:Declaring custom model
2023-04-24 18:29:18,976:INFO:Logistic Regression Imported successfully
2023-04-24 18:29:18,981:INFO:Starting cross validation
2023-04-24 18:29:18,994:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 18:29:20,064:INFO:Calculating mean and std
2023-04-24 18:29:20,065:INFO:Creating metrics dataframe
2023-04-24 18:29:20,069:INFO:Finalizing model
2023-04-24 18:29:22,264:INFO:Uploading results into container
2023-04-24 18:29:22,274:INFO:Uploading model into container now
2023-04-24 18:29:22,277:INFO:_master_model_container: 46
2023-04-24 18:29:22,277:INFO:_display_container: 30
2023-04-24 18:29:22,278:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 18:29:22,278:INFO:create_model() successfully completed......................................
2023-04-24 18:29:22,834:INFO:SubProcess create_model() end ==================================
2023-04-24 18:29:22,836:INFO:choose_better activated
2023-04-24 18:29:22,842:INFO:SubProcess create_model() called ==================================
2023-04-24 18:29:22,844:INFO:Initializing create_model()
2023-04-24 18:29:22,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 18:29:22,844:INFO:Checking exceptions
2023-04-24 18:29:22,854:INFO:Importing libraries
2023-04-24 18:29:22,854:INFO:Copying training dataset
2023-04-24 18:29:22,909:INFO:Defining folds
2023-04-24 18:29:22,909:INFO:Declaring metric variables
2023-04-24 18:29:22,909:INFO:Importing untrained model
2023-04-24 18:29:22,909:INFO:Declaring custom model
2023-04-24 18:29:22,909:INFO:Logistic Regression Imported successfully
2023-04-24 18:29:22,910:INFO:Starting cross validation
2023-04-24 18:29:22,945:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 18:29:24,805:INFO:Calculating mean and std
2023-04-24 18:29:24,807:INFO:Creating metrics dataframe
2023-04-24 18:29:24,821:INFO:Finalizing model
2023-04-24 18:29:25,845:INFO:Uploading results into container
2023-04-24 18:29:25,846:INFO:Uploading model into container now
2023-04-24 18:29:25,848:INFO:_master_model_container: 47
2023-04-24 18:29:25,848:INFO:_display_container: 31
2023-04-24 18:29:25,849:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 18:29:25,849:INFO:create_model() successfully completed......................................
2023-04-24 18:29:26,122:INFO:SubProcess create_model() end ==================================
2023-04-24 18:29:26,123:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8485
2023-04-24 18:29:26,123:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8537
2023-04-24 18:29:26,123:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-04-24 18:29:26,123:INFO:choose_better completed
2023-04-24 18:29:26,136:INFO:_master_model_container: 47
2023-04-24 18:29:26,136:INFO:_display_container: 30
2023-04-24 18:29:26,136:INFO:LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-24 18:29:26,136:INFO:tune_model() successfully completed......................................
2023-04-24 18:29:26,356:INFO:Initializing plot_model()
2023-04-24 18:29:26,356:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 18:29:26,356:INFO:Checking exceptions
2023-04-24 18:29:26,377:INFO:Preloading libraries
2023-04-24 18:29:26,378:INFO:Copying training dataset
2023-04-24 18:29:26,378:INFO:Plot type: feature
2023-04-24 18:29:26,648:INFO:Saving 'Feature Importance.png'
2023-04-24 18:29:26,748:INFO:Visual Rendered Successfully
2023-04-24 18:29:26,838:INFO:plot_model() successfully completed......................................
2023-04-24 18:29:26,839:INFO:Initializing plot_model()
2023-04-24 18:29:26,839:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 18:29:26,839:INFO:Checking exceptions
2023-04-24 18:29:26,848:INFO:Preloading libraries
2023-04-24 18:29:26,848:INFO:Copying training dataset
2023-04-24 18:29:26,848:INFO:Plot type: auc
2023-04-24 18:29:27,195:INFO:Fitting Model
2023-04-24 18:29:27,196:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-04-24 18:29:27,197:INFO:Scoring test/hold-out set
2023-04-24 18:29:27,237:INFO:Saving 'AUC.png'
2023-04-24 18:29:27,357:INFO:Visual Rendered Successfully
2023-04-24 18:29:27,449:INFO:plot_model() successfully completed......................................
2023-04-24 18:29:27,449:INFO:Initializing plot_model()
2023-04-24 18:29:27,449:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 18:29:27,449:INFO:Checking exceptions
2023-04-24 18:29:27,455:INFO:Preloading libraries
2023-04-24 18:29:27,455:INFO:Copying training dataset
2023-04-24 18:29:27,455:INFO:Plot type: confusion_matrix
2023-04-24 18:29:27,768:INFO:Fitting Model
2023-04-24 18:29:27,768:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-04-24 18:29:27,769:INFO:Scoring test/hold-out set
2023-04-24 18:29:27,788:INFO:Saving 'Confusion Matrix.png'
2023-04-24 18:29:27,843:INFO:Visual Rendered Successfully
2023-04-24 18:29:27,928:INFO:plot_model() successfully completed......................................
2023-04-24 18:29:27,937:INFO:Initializing save_model()
2023-04-24 18:29:27,937:INFO:save_model(model=LogisticRegression(C=0.041, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8216, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/lr/Model_Results/Model_Objects/lr, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                                                               n_jobs=1,
                                                               random_state=8216,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-24 18:29:27,937:INFO:Adding model into prep_pipe
2023-04-24 18:29:27,984:INFO:/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/lr/Model_Results/Model_Objects/lr.pkl saved in current working directory
2023-04-24 18:29:27,991:INFO:Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('trained_model',
                 LogisticRegression(C=0.041, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=8216,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2023-04-24 18:29:27,991:INFO:save_model() successfully completed......................................
2023-04-24 18:29:28,173:INFO:Initializing create_model()
2023-04-24 18:29:28,173:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=dt, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 18:29:28,173:INFO:Checking exceptions
2023-04-24 18:29:28,191:INFO:Importing libraries
2023-04-24 18:29:28,191:INFO:Copying training dataset
2023-04-24 18:29:28,207:INFO:Defining folds
2023-04-24 18:29:28,208:INFO:Declaring metric variables
2023-04-24 18:29:28,210:INFO:Importing untrained model
2023-04-24 18:29:28,212:INFO:Decision Tree Classifier Imported successfully
2023-04-24 18:29:28,218:INFO:Starting cross validation
2023-04-24 18:29:28,231:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 18:29:29,389:INFO:Calculating mean and std
2023-04-24 18:29:29,391:INFO:Creating metrics dataframe
2023-04-24 18:29:29,395:INFO:Finalizing model
2023-04-24 18:29:30,001:INFO:Uploading results into container
2023-04-24 18:29:30,002:INFO:Uploading model into container now
2023-04-24 18:29:30,007:INFO:_master_model_container: 48
2023-04-24 18:29:30,007:INFO:_display_container: 31
2023-04-24 18:29:30,008:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best')
2023-04-24 18:29:30,008:INFO:create_model() successfully completed......................................
2023-04-24 18:29:30,100:INFO:Initializing tune_model()
2023-04-24 18:29:30,100:INFO:tune_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 18:29:30,100:INFO:Checking exceptions
2023-04-24 18:29:30,121:INFO:Copying training dataset
2023-04-24 18:29:30,135:INFO:Checking base model
2023-04-24 18:29:30,135:INFO:Base model : Decision Tree Classifier
2023-04-24 18:29:30,137:INFO:Declaring metric variables
2023-04-24 18:29:30,140:INFO:Defining Hyperparameters
2023-04-24 18:29:30,236:INFO:Tuning with n_jobs=-1
2023-04-24 18:29:30,236:INFO:Initializing RandomizedSearchCV
2023-04-24 18:29:36,833:INFO:best_params: {'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 13, 'actual_estimator__criterion': 'entropy'}
2023-04-24 18:29:36,835:INFO:Hyperparameter search completed
2023-04-24 18:29:36,835:INFO:SubProcess create_model() called ==================================
2023-04-24 18:29:36,835:INFO:Initializing create_model()
2023-04-24 18:29:36,835:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd6ebbfe2b0>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 10, 'min_samples_leaf': 4, 'min_impurity_decrease': 0, 'max_features': 1.0, 'max_depth': 13, 'criterion': 'entropy'})
2023-04-24 18:29:36,835:INFO:Checking exceptions
2023-04-24 18:29:36,836:INFO:Importing libraries
2023-04-24 18:29:36,836:INFO:Copying training dataset
2023-04-24 18:29:36,852:INFO:Defining folds
2023-04-24 18:29:36,852:INFO:Declaring metric variables
2023-04-24 18:29:36,854:INFO:Importing untrained model
2023-04-24 18:29:36,854:INFO:Declaring custom model
2023-04-24 18:29:36,857:INFO:Decision Tree Classifier Imported successfully
2023-04-24 18:29:36,861:INFO:Starting cross validation
2023-04-24 18:29:36,869:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 18:29:37,839:INFO:Calculating mean and std
2023-04-24 18:29:37,840:INFO:Creating metrics dataframe
2023-04-24 18:29:37,844:INFO:Finalizing model
2023-04-24 18:29:38,409:INFO:Uploading results into container
2023-04-24 18:29:38,410:INFO:Uploading model into container now
2023-04-24 18:29:38,410:INFO:_master_model_container: 49
2023-04-24 18:29:38,410:INFO:_display_container: 32
2023-04-24 18:29:38,411:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best')
2023-04-24 18:29:38,411:INFO:create_model() successfully completed......................................
2023-04-24 18:29:38,511:INFO:SubProcess create_model() end ==================================
2023-04-24 18:29:38,511:INFO:choose_better activated
2023-04-24 18:29:38,513:INFO:SubProcess create_model() called ==================================
2023-04-24 18:29:38,514:INFO:Initializing create_model()
2023-04-24 18:29:38,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 18:29:38,514:INFO:Checking exceptions
2023-04-24 18:29:38,515:INFO:Importing libraries
2023-04-24 18:29:38,515:INFO:Copying training dataset
2023-04-24 18:29:38,529:INFO:Defining folds
2023-04-24 18:29:38,529:INFO:Declaring metric variables
2023-04-24 18:29:38,530:INFO:Importing untrained model
2023-04-24 18:29:38,530:INFO:Declaring custom model
2023-04-24 18:29:38,530:INFO:Decision Tree Classifier Imported successfully
2023-04-24 18:29:38,530:INFO:Starting cross validation
2023-04-24 18:29:38,537:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 18:29:39,514:INFO:Calculating mean and std
2023-04-24 18:29:39,514:INFO:Creating metrics dataframe
2023-04-24 18:29:39,516:INFO:Finalizing model
2023-04-24 18:29:40,029:INFO:Uploading results into container
2023-04-24 18:29:40,029:INFO:Uploading model into container now
2023-04-24 18:29:40,030:INFO:_master_model_container: 50
2023-04-24 18:29:40,030:INFO:_display_container: 33
2023-04-24 18:29:40,030:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best')
2023-04-24 18:29:40,030:INFO:create_model() successfully completed......................................
2023-04-24 18:29:40,120:INFO:SubProcess create_model() end ==================================
2023-04-24 18:29:40,121:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best') result for Accuracy is 0.783
2023-04-24 18:29:40,121:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best') result for Accuracy is 0.8315
2023-04-24 18:29:40,122:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best') is best model
2023-04-24 18:29:40,122:INFO:choose_better completed
2023-04-24 18:29:40,128:INFO:_master_model_container: 50
2023-04-24 18:29:40,128:INFO:_display_container: 32
2023-04-24 18:29:40,128:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best')
2023-04-24 18:29:40,128:INFO:tune_model() successfully completed......................................
2023-04-24 18:29:40,316:INFO:Initializing plot_model()
2023-04-24 18:29:40,317:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 18:29:40,317:INFO:Checking exceptions
2023-04-24 18:29:40,325:INFO:Preloading libraries
2023-04-24 18:29:40,326:INFO:Copying training dataset
2023-04-24 18:29:40,326:INFO:Plot type: feature
2023-04-24 18:29:40,326:WARNING:No coef_ found. Trying feature_importances_
2023-04-24 18:29:40,451:INFO:Saving 'Feature Importance.png'
2023-04-24 18:29:40,536:INFO:Visual Rendered Successfully
2023-04-24 18:29:40,622:INFO:plot_model() successfully completed......................................
2023-04-24 18:29:40,622:INFO:Initializing plot_model()
2023-04-24 18:29:40,623:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 18:29:40,623:INFO:Checking exceptions
2023-04-24 18:29:40,629:INFO:Preloading libraries
2023-04-24 18:29:40,630:INFO:Copying training dataset
2023-04-24 18:29:40,630:INFO:Plot type: auc
2023-04-24 18:29:40,938:INFO:Fitting Model
2023-04-24 18:29:40,939:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2023-04-24 18:29:40,939:INFO:Scoring test/hold-out set
2023-04-24 18:29:40,967:INFO:Saving 'AUC.png'
2023-04-24 18:29:41,067:INFO:Visual Rendered Successfully
2023-04-24 18:29:41,152:INFO:plot_model() successfully completed......................................
2023-04-24 18:29:41,152:INFO:Initializing plot_model()
2023-04-24 18:29:41,152:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 18:29:41,152:INFO:Checking exceptions
2023-04-24 18:29:41,158:INFO:Preloading libraries
2023-04-24 18:29:41,159:INFO:Copying training dataset
2023-04-24 18:29:41,159:INFO:Plot type: confusion_matrix
2023-04-24 18:29:41,455:INFO:Fitting Model
2023-04-24 18:29:41,455:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2023-04-24 18:29:41,456:INFO:Scoring test/hold-out set
2023-04-24 18:29:41,475:INFO:Saving 'Confusion Matrix.png'
2023-04-24 18:29:41,528:INFO:Visual Rendered Successfully
2023-04-24 18:29:41,613:INFO:plot_model() successfully completed......................................
2023-04-24 18:29:41,623:INFO:Initializing save_model()
2023-04-24 18:29:41,624:INFO:save_model(model=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=13, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0, min_samples_leaf=4,
                       min_samples_split=10, min_weight_fraction_leaf=0.0,
                       random_state=8216, splitter='best'), model_name=/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/dt/Model_Results/Model_Objects/dt, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                                                               n_jobs=1,
                                                               random_state=8216,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-24 18:29:41,624:INFO:Adding model into prep_pipe
2023-04-24 18:29:41,668:INFO:/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/dt/Model_Results/Model_Objects/dt.pkl saved in current working directory
2023-04-24 18:29:41,675:INFO:Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('trained_model',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='entropy', max_depth=13,
                                        max_features=1.0, max_leaf_nodes=None,
                                        min_impurity_decrease=0,
                                        min_samples_leaf=4,
                                        min_samples_split=10,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=8216, splitter='best'))],
         verbose=False)
2023-04-24 18:29:41,675:INFO:save_model() successfully completed......................................
2023-04-24 18:29:41,861:INFO:Initializing create_model()
2023-04-24 18:29:41,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=rf, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 18:29:41,861:INFO:Checking exceptions
2023-04-24 18:29:41,877:INFO:Importing libraries
2023-04-24 18:29:41,877:INFO:Copying training dataset
2023-04-24 18:29:41,894:INFO:Defining folds
2023-04-24 18:29:41,894:INFO:Declaring metric variables
2023-04-24 18:29:41,898:INFO:Importing untrained model
2023-04-24 18:29:41,902:INFO:Random Forest Classifier Imported successfully
2023-04-24 18:29:41,907:INFO:Starting cross validation
2023-04-24 18:29:41,915:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 18:29:43,204:INFO:Calculating mean and std
2023-04-24 18:29:43,206:INFO:Creating metrics dataframe
2023-04-24 18:29:43,209:INFO:Finalizing model
2023-04-24 18:29:43,831:INFO:Uploading results into container
2023-04-24 18:29:43,832:INFO:Uploading model into container now
2023-04-24 18:29:43,837:INFO:_master_model_container: 51
2023-04-24 18:29:43,837:INFO:_display_container: 33
2023-04-24 18:29:43,837:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False)
2023-04-24 18:29:43,837:INFO:create_model() successfully completed......................................
2023-04-24 18:29:43,925:INFO:Initializing tune_model()
2023-04-24 18:29:43,925:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 18:29:43,926:INFO:Checking exceptions
2023-04-24 18:29:43,947:INFO:Copying training dataset
2023-04-24 18:29:43,963:INFO:Checking base model
2023-04-24 18:29:43,963:INFO:Base model : Random Forest Classifier
2023-04-24 18:29:43,965:INFO:Declaring metric variables
2023-04-24 18:29:43,967:INFO:Defining Hyperparameters
2023-04-24 18:29:44,062:INFO:Tuning with n_jobs=-1
2023-04-24 18:29:44,063:INFO:Initializing RandomizedSearchCV
2023-04-24 18:29:51,064:INFO:best_params: {'actual_estimator__n_estimators': 220, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced_subsample', 'actual_estimator__bootstrap': False}
2023-04-24 18:29:51,065:INFO:Hyperparameter search completed
2023-04-24 18:29:51,065:INFO:SubProcess create_model() called ==================================
2023-04-24 18:29:51,066:INFO:Initializing create_model()
2023-04-24 18:29:51,066:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd73595efd0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 220, 'min_samples_split': 9, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0001, 'max_features': 'log2', 'max_depth': 7, 'criterion': 'gini', 'class_weight': 'balanced_subsample', 'bootstrap': False})
2023-04-24 18:29:51,066:INFO:Checking exceptions
2023-04-24 18:29:51,066:INFO:Importing libraries
2023-04-24 18:29:51,066:INFO:Copying training dataset
2023-04-24 18:29:51,081:INFO:Defining folds
2023-04-24 18:29:51,081:INFO:Declaring metric variables
2023-04-24 18:29:51,083:INFO:Importing untrained model
2023-04-24 18:29:51,083:INFO:Declaring custom model
2023-04-24 18:29:51,086:INFO:Random Forest Classifier Imported successfully
2023-04-24 18:29:51,090:INFO:Starting cross validation
2023-04-24 18:29:51,098:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 18:29:52,489:INFO:Calculating mean and std
2023-04-24 18:29:52,490:INFO:Creating metrics dataframe
2023-04-24 18:29:52,511:INFO:Finalizing model
2023-04-24 18:29:53,086:INFO:Uploading results into container
2023-04-24 18:29:53,087:INFO:Uploading model into container now
2023-04-24 18:29:53,087:INFO:_master_model_container: 52
2023-04-24 18:29:53,087:INFO:_display_container: 34
2023-04-24 18:29:53,088:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=7, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0001,
                       min_samples_leaf=4, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=220,
                       n_jobs=-1, oob_score=False, random_state=8216, verbose=0,
                       warm_start=False)
2023-04-24 18:29:53,088:INFO:create_model() successfully completed......................................
2023-04-24 18:29:53,176:INFO:SubProcess create_model() end ==================================
2023-04-24 18:29:53,176:INFO:choose_better activated
2023-04-24 18:29:53,178:INFO:SubProcess create_model() called ==================================
2023-04-24 18:29:53,178:INFO:Initializing create_model()
2023-04-24 18:29:53,179:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 18:29:53,179:INFO:Checking exceptions
2023-04-24 18:29:53,180:INFO:Importing libraries
2023-04-24 18:29:53,180:INFO:Copying training dataset
2023-04-24 18:29:53,193:INFO:Defining folds
2023-04-24 18:29:53,193:INFO:Declaring metric variables
2023-04-24 18:29:53,193:INFO:Importing untrained model
2023-04-24 18:29:53,193:INFO:Declaring custom model
2023-04-24 18:29:53,193:INFO:Random Forest Classifier Imported successfully
2023-04-24 18:29:53,193:INFO:Starting cross validation
2023-04-24 18:29:53,200:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 18:29:54,516:INFO:Calculating mean and std
2023-04-24 18:29:54,516:INFO:Creating metrics dataframe
2023-04-24 18:29:54,518:INFO:Finalizing model
2023-04-24 18:29:55,087:INFO:Uploading results into container
2023-04-24 18:29:55,088:INFO:Uploading model into container now
2023-04-24 18:29:55,088:INFO:_master_model_container: 53
2023-04-24 18:29:55,088:INFO:_display_container: 35
2023-04-24 18:29:55,088:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False)
2023-04-24 18:29:55,088:INFO:create_model() successfully completed......................................
2023-04-24 18:29:55,175:INFO:SubProcess create_model() end ==================================
2023-04-24 18:29:55,175:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False) result for Accuracy is 0.879
2023-04-24 18:29:55,176:INFO:RandomForestClassifier(bootstrap=False, ccp_alpha=0.0,
                       class_weight='balanced_subsample', criterion='gini',
                       max_depth=7, max_features='log2', max_leaf_nodes=None,
                       max_samples=None, min_impurity_decrease=0.0001,
                       min_samples_leaf=4, min_samples_split=9,
                       min_weight_fraction_leaf=0.0, n_estimators=220,
                       n_jobs=-1, oob_score=False, random_state=8216, verbose=0,
                       warm_start=False) result for Accuracy is 0.87
2023-04-24 18:29:55,176:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False) is best model
2023-04-24 18:29:55,176:INFO:choose_better completed
2023-04-24 18:29:55,176:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-04-24 18:29:55,181:INFO:_master_model_container: 53
2023-04-24 18:29:55,181:INFO:_display_container: 34
2023-04-24 18:29:55,181:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False)
2023-04-24 18:29:55,181:INFO:tune_model() successfully completed......................................
2023-04-24 18:29:55,376:INFO:Initializing plot_model()
2023-04-24 18:29:55,376:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 18:29:55,376:INFO:Checking exceptions
2023-04-24 18:29:55,391:INFO:Preloading libraries
2023-04-24 18:29:55,444:INFO:Copying training dataset
2023-04-24 18:29:55,444:INFO:Plot type: feature
2023-04-24 18:29:55,444:WARNING:No coef_ found. Trying feature_importances_
2023-04-24 18:29:55,567:INFO:Saving 'Feature Importance.png'
2023-04-24 18:29:55,646:INFO:Visual Rendered Successfully
2023-04-24 18:29:55,734:INFO:plot_model() successfully completed......................................
2023-04-24 18:29:55,735:INFO:Initializing plot_model()
2023-04-24 18:29:55,735:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 18:29:55,735:INFO:Checking exceptions
2023-04-24 18:29:55,751:INFO:Preloading libraries
2023-04-24 18:29:55,780:INFO:Copying training dataset
2023-04-24 18:29:55,780:INFO:Plot type: auc
2023-04-24 18:29:56,092:INFO:Fitting Model
2023-04-24 18:29:56,093:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-04-24 18:29:56,094:INFO:Scoring test/hold-out set
2023-04-24 18:29:56,232:INFO:Saving 'AUC.png'
2023-04-24 18:29:56,334:INFO:Visual Rendered Successfully
2023-04-24 18:29:56,425:INFO:plot_model() successfully completed......................................
2023-04-24 18:29:56,426:INFO:Initializing plot_model()
2023-04-24 18:29:56,426:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 18:29:56,426:INFO:Checking exceptions
2023-04-24 18:29:56,441:INFO:Preloading libraries
2023-04-24 18:29:56,465:INFO:Copying training dataset
2023-04-24 18:29:56,465:INFO:Plot type: confusion_matrix
2023-04-24 18:29:56,778:INFO:Fitting Model
2023-04-24 18:29:56,779:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2023-04-24 18:29:56,780:INFO:Scoring test/hold-out set
2023-04-24 18:29:56,897:INFO:Saving 'Confusion Matrix.png'
2023-04-24 18:29:56,950:INFO:Visual Rendered Successfully
2023-04-24 18:29:57,034:INFO:plot_model() successfully completed......................................
2023-04-24 18:29:57,046:INFO:Initializing save_model()
2023-04-24 18:29:57,046:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='auto',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8216, verbose=0, warm_start=False), model_name=/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/rf/Model_Results/Model_Objects/rf, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                                                               n_jobs=1,
                                                               random_state=8216,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-24 18:29:57,046:INFO:Adding model into prep_pipe
2023-04-24 18:29:57,125:INFO:/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/rf/Model_Results/Model_Objects/rf.pkl saved in current working directory
2023-04-24 18:29:57,133:INFO:Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='auto',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=8216,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-04-24 18:29:57,133:INFO:save_model() successfully completed......................................
2023-04-24 18:29:57,354:INFO:Initializing create_model()
2023-04-24 18:29:57,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=ada, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 18:29:57,354:INFO:Checking exceptions
2023-04-24 18:29:57,371:INFO:Importing libraries
2023-04-24 18:29:57,371:INFO:Copying training dataset
2023-04-24 18:29:57,386:INFO:Defining folds
2023-04-24 18:29:57,386:INFO:Declaring metric variables
2023-04-24 18:29:57,388:INFO:Importing untrained model
2023-04-24 18:29:57,391:INFO:Ada Boost Classifier Imported successfully
2023-04-24 18:29:57,395:INFO:Starting cross validation
2023-04-24 18:29:57,404:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 18:29:58,555:INFO:Calculating mean and std
2023-04-24 18:29:58,557:INFO:Creating metrics dataframe
2023-04-24 18:29:58,561:INFO:Finalizing model
2023-04-24 18:29:59,111:INFO:Uploading results into container
2023-04-24 18:29:59,111:INFO:Uploading model into container now
2023-04-24 18:29:59,116:INFO:_master_model_container: 54
2023-04-24 18:29:59,116:INFO:_display_container: 35
2023-04-24 18:29:59,116:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216)
2023-04-24 18:29:59,117:INFO:create_model() successfully completed......................................
2023-04-24 18:29:59,210:INFO:Initializing tune_model()
2023-04-24 18:29:59,210:INFO:tune_model(estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 18:29:59,211:INFO:Checking exceptions
2023-04-24 18:29:59,230:INFO:Copying training dataset
2023-04-24 18:29:59,244:INFO:Checking base model
2023-04-24 18:29:59,244:INFO:Base model : Ada Boost Classifier
2023-04-24 18:29:59,246:INFO:Declaring metric variables
2023-04-24 18:29:59,249:INFO:Defining Hyperparameters
2023-04-24 18:29:59,347:INFO:Tuning with n_jobs=-1
2023-04-24 18:29:59,347:INFO:Initializing RandomizedSearchCV
2023-04-24 18:30:06,936:INFO:best_params: {'actual_estimator__n_estimators': 150, 'actual_estimator__learning_rate': 0.4, 'actual_estimator__algorithm': 'SAMME.R'}
2023-04-24 18:30:06,938:INFO:Hyperparameter search completed
2023-04-24 18:30:06,939:INFO:SubProcess create_model() called ==================================
2023-04-24 18:30:06,939:INFO:Initializing create_model()
2023-04-24 18:30:06,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd6e931bfa0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 150, 'learning_rate': 0.4, 'algorithm': 'SAMME.R'})
2023-04-24 18:30:06,940:INFO:Checking exceptions
2023-04-24 18:30:06,940:INFO:Importing libraries
2023-04-24 18:30:06,940:INFO:Copying training dataset
2023-04-24 18:30:06,975:INFO:Defining folds
2023-04-24 18:30:06,975:INFO:Declaring metric variables
2023-04-24 18:30:06,978:INFO:Importing untrained model
2023-04-24 18:30:06,978:INFO:Declaring custom model
2023-04-24 18:30:06,981:INFO:Ada Boost Classifier Imported successfully
2023-04-24 18:30:06,986:INFO:Starting cross validation
2023-04-24 18:30:07,007:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 18:30:08,567:INFO:Calculating mean and std
2023-04-24 18:30:08,568:INFO:Creating metrics dataframe
2023-04-24 18:30:08,572:INFO:Finalizing model
2023-04-24 18:30:09,188:INFO:Uploading results into container
2023-04-24 18:30:09,188:INFO:Uploading model into container now
2023-04-24 18:30:09,189:INFO:_master_model_container: 55
2023-04-24 18:30:09,189:INFO:_display_container: 36
2023-04-24 18:30:09,189:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216)
2023-04-24 18:30:09,189:INFO:create_model() successfully completed......................................
2023-04-24 18:30:09,295:INFO:SubProcess create_model() end ==================================
2023-04-24 18:30:09,295:INFO:choose_better activated
2023-04-24 18:30:09,298:INFO:SubProcess create_model() called ==================================
2023-04-24 18:30:09,298:INFO:Initializing create_model()
2023-04-24 18:30:09,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 18:30:09,298:INFO:Checking exceptions
2023-04-24 18:30:09,299:INFO:Importing libraries
2023-04-24 18:30:09,299:INFO:Copying training dataset
2023-04-24 18:30:09,314:INFO:Defining folds
2023-04-24 18:30:09,314:INFO:Declaring metric variables
2023-04-24 18:30:09,314:INFO:Importing untrained model
2023-04-24 18:30:09,314:INFO:Declaring custom model
2023-04-24 18:30:09,314:INFO:Ada Boost Classifier Imported successfully
2023-04-24 18:30:09,314:INFO:Starting cross validation
2023-04-24 18:30:09,321:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 18:30:10,484:INFO:Calculating mean and std
2023-04-24 18:30:10,484:INFO:Creating metrics dataframe
2023-04-24 18:30:10,486:INFO:Finalizing model
2023-04-24 18:30:11,002:INFO:Uploading results into container
2023-04-24 18:30:11,002:INFO:Uploading model into container now
2023-04-24 18:30:11,003:INFO:_master_model_container: 56
2023-04-24 18:30:11,003:INFO:_display_container: 37
2023-04-24 18:30:11,003:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216)
2023-04-24 18:30:11,003:INFO:create_model() successfully completed......................................
2023-04-24 18:30:11,088:INFO:SubProcess create_model() end ==================================
2023-04-24 18:30:11,088:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8216) result for Accuracy is 0.8476
2023-04-24 18:30:11,088:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216) result for Accuracy is 0.8492
2023-04-24 18:30:11,089:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216) is best model
2023-04-24 18:30:11,089:INFO:choose_better completed
2023-04-24 18:30:11,094:INFO:_master_model_container: 56
2023-04-24 18:30:11,094:INFO:_display_container: 36
2023-04-24 18:30:11,094:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216)
2023-04-24 18:30:11,094:INFO:tune_model() successfully completed......................................
2023-04-24 18:30:11,291:INFO:Initializing plot_model()
2023-04-24 18:30:11,291:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 18:30:11,291:INFO:Checking exceptions
2023-04-24 18:30:11,300:INFO:Preloading libraries
2023-04-24 18:30:11,308:INFO:Copying training dataset
2023-04-24 18:30:11,308:INFO:Plot type: feature
2023-04-24 18:30:11,309:WARNING:No coef_ found. Trying feature_importances_
2023-04-24 18:30:11,407:INFO:Saving 'Feature Importance.png'
2023-04-24 18:30:11,495:INFO:Visual Rendered Successfully
2023-04-24 18:30:11,582:INFO:plot_model() successfully completed......................................
2023-04-24 18:30:11,582:INFO:Initializing plot_model()
2023-04-24 18:30:11,582:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 18:30:11,582:INFO:Checking exceptions
2023-04-24 18:30:11,590:INFO:Preloading libraries
2023-04-24 18:30:11,597:INFO:Copying training dataset
2023-04-24 18:30:11,597:INFO:Plot type: auc
2023-04-24 18:30:11,897:INFO:Fitting Model
2023-04-24 18:30:11,898:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2023-04-24 18:30:11,899:INFO:Scoring test/hold-out set
2023-04-24 18:30:12,700:INFO:Saving 'AUC.png'
2023-04-24 18:30:12,820:INFO:Visual Rendered Successfully
2023-04-24 18:30:12,914:INFO:plot_model() successfully completed......................................
2023-04-24 18:30:12,914:INFO:Initializing plot_model()
2023-04-24 18:30:12,914:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 18:30:12,914:INFO:Checking exceptions
2023-04-24 18:30:12,922:INFO:Preloading libraries
2023-04-24 18:30:12,930:INFO:Copying training dataset
2023-04-24 18:30:12,930:INFO:Plot type: confusion_matrix
2023-04-24 18:30:13,223:INFO:Fitting Model
2023-04-24 18:30:13,223:WARNING:/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but AdaBoostClassifier was fitted with feature names
  warnings.warn(

2023-04-24 18:30:13,224:INFO:Scoring test/hold-out set
2023-04-24 18:30:13,974:INFO:Saving 'Confusion Matrix.png'
2023-04-24 18:30:14,031:INFO:Visual Rendered Successfully
2023-04-24 18:30:14,140:INFO:plot_model() successfully completed......................................
2023-04-24 18:30:14,149:INFO:Initializing save_model()
2023-04-24 18:30:14,149:INFO:save_model(model=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.4,
                   n_estimators=150, random_state=8216), model_name=/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/ada/Model_Results/Model_Objects/ada, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                                                               n_jobs=1,
                                                               random_state=8216,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-24 18:30:14,149:INFO:Adding model into prep_pipe
2023-04-24 18:30:14,233:INFO:/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/ada/Model_Results/Model_Objects/ada.pkl saved in current working directory
2023-04-24 18:30:14,241:INFO:Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1)))),
                ('trained_model',
                 AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,
                                    learning_rate=0.4, n_estimators=150,
                                    random_state=8216))],
         verbose=False)
2023-04-24 18:30:14,241:INFO:save_model() successfully completed......................................
2023-04-24 18:30:14,437:INFO:Initializing create_model()
2023-04-24 18:30:14,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=lightgbm, fold=5, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 18:30:14,438:INFO:Checking exceptions
2023-04-24 18:30:14,453:INFO:Importing libraries
2023-04-24 18:30:14,454:INFO:Copying training dataset
2023-04-24 18:30:14,470:INFO:Defining folds
2023-04-24 18:30:14,470:INFO:Declaring metric variables
2023-04-24 18:30:14,473:INFO:Importing untrained model
2023-04-24 18:30:14,475:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 18:30:14,480:INFO:Starting cross validation
2023-04-24 18:30:14,487:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 18:30:16,585:INFO:Calculating mean and std
2023-04-24 18:30:16,586:INFO:Creating metrics dataframe
2023-04-24 18:30:16,590:INFO:Finalizing model
2023-04-24 18:30:17,123:INFO:Uploading results into container
2023-04-24 18:30:17,123:INFO:Uploading model into container now
2023-04-24 18:30:17,129:INFO:_master_model_container: 57
2023-04-24 18:30:17,129:INFO:_display_container: 37
2023-04-24 18:30:17,129:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-24 18:30:17,130:INFO:create_model() successfully completed......................................
2023-04-24 18:30:17,218:INFO:Initializing tune_model()
2023-04-24 18:30:17,218:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=5, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>)
2023-04-24 18:30:17,218:INFO:Checking exceptions
2023-04-24 18:30:17,238:INFO:Copying training dataset
2023-04-24 18:30:17,248:INFO:Checking base model
2023-04-24 18:30:17,248:INFO:Base model : Light Gradient Boosting Machine
2023-04-24 18:30:17,253:INFO:Declaring metric variables
2023-04-24 18:30:17,257:INFO:Defining Hyperparameters
2023-04-24 18:30:17,396:INFO:Tuning with n_jobs=-1
2023-04-24 18:30:17,396:INFO:Initializing RandomizedSearchCV
2023-04-24 18:30:24,513:INFO:best_params: {'actual_estimator__reg_lambda': 0.01, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 256, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 21, 'actual_estimator__learning_rate': 0.01, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 1.0}
2023-04-24 18:30:24,515:INFO:Hyperparameter search completed
2023-04-24 18:30:24,516:INFO:SubProcess create_model() called ==================================
2023-04-24 18:30:24,516:INFO:Initializing create_model()
2023-04-24 18:30:24,516:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fd6e9f674c0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.01, 'reg_alpha': 0.0005, 'num_leaves': 256, 'n_estimators': 190, 'min_split_gain': 0.3, 'min_child_samples': 21, 'learning_rate': 0.01, 'feature_fraction': 0.6, 'bagging_freq': 5, 'bagging_fraction': 1.0})
2023-04-24 18:30:24,516:INFO:Checking exceptions
2023-04-24 18:30:24,516:INFO:Importing libraries
2023-04-24 18:30:24,517:INFO:Copying training dataset
2023-04-24 18:30:24,540:INFO:Defining folds
2023-04-24 18:30:24,540:INFO:Declaring metric variables
2023-04-24 18:30:24,543:INFO:Importing untrained model
2023-04-24 18:30:24,543:INFO:Declaring custom model
2023-04-24 18:30:24,546:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 18:30:24,550:INFO:Starting cross validation
2023-04-24 18:30:24,560:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 18:30:26,802:INFO:Calculating mean and std
2023-04-24 18:30:26,803:INFO:Creating metrics dataframe
2023-04-24 18:30:26,808:INFO:Finalizing model
2023-04-24 18:30:27,497:INFO:Uploading results into container
2023-04-24 18:30:27,498:INFO:Uploading model into container now
2023-04-24 18:30:27,498:INFO:_master_model_container: 58
2023-04-24 18:30:27,498:INFO:_display_container: 38
2023-04-24 18:30:27,499:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-04-24 18:30:27,499:INFO:create_model() successfully completed......................................
2023-04-24 18:30:27,630:INFO:SubProcess create_model() end ==================================
2023-04-24 18:30:27,630:INFO:choose_better activated
2023-04-24 18:30:27,633:INFO:SubProcess create_model() called ==================================
2023-04-24 18:30:27,633:INFO:Initializing create_model()
2023-04-24 18:30:27,633:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-24 18:30:27,633:INFO:Checking exceptions
2023-04-24 18:30:27,634:INFO:Importing libraries
2023-04-24 18:30:27,634:INFO:Copying training dataset
2023-04-24 18:30:27,648:INFO:Defining folds
2023-04-24 18:30:27,649:INFO:Declaring metric variables
2023-04-24 18:30:27,649:INFO:Importing untrained model
2023-04-24 18:30:27,649:INFO:Declaring custom model
2023-04-24 18:30:27,649:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-24 18:30:27,649:INFO:Starting cross validation
2023-04-24 18:30:27,656:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=-1
2023-04-24 18:30:28,982:INFO:Calculating mean and std
2023-04-24 18:30:28,982:INFO:Creating metrics dataframe
2023-04-24 18:30:28,984:INFO:Finalizing model
2023-04-24 18:30:29,522:INFO:Uploading results into container
2023-04-24 18:30:29,522:INFO:Uploading model into container now
2023-04-24 18:30:29,523:INFO:_master_model_container: 59
2023-04-24 18:30:29,523:INFO:_display_container: 39
2023-04-24 18:30:29,523:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-24 18:30:29,523:INFO:create_model() successfully completed......................................
2023-04-24 18:30:29,623:INFO:SubProcess create_model() end ==================================
2023-04-24 18:30:29,624:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8216, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.811
2023-04-24 18:30:29,624:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) result for Accuracy is 0.881
2023-04-24 18:30:29,624:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) is best model
2023-04-24 18:30:29,624:INFO:choose_better completed
2023-04-24 18:30:29,630:INFO:_master_model_container: 59
2023-04-24 18:30:29,631:INFO:_display_container: 38
2023-04-24 18:30:29,631:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-04-24 18:30:29,631:INFO:tune_model() successfully completed......................................
2023-04-24 18:30:29,835:INFO:Initializing plot_model()
2023-04-24 18:30:29,835:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 18:30:29,835:INFO:Checking exceptions
2023-04-24 18:30:29,842:INFO:Preloading libraries
2023-04-24 18:30:29,900:INFO:Copying training dataset
2023-04-24 18:30:29,900:INFO:Plot type: feature
2023-04-24 18:30:29,900:WARNING:No coef_ found. Trying feature_importances_
2023-04-24 18:30:29,995:INFO:Saving 'Feature Importance.png'
2023-04-24 18:30:30,073:INFO:Visual Rendered Successfully
2023-04-24 18:30:30,161:INFO:plot_model() successfully completed......................................
2023-04-24 18:30:30,161:INFO:Initializing plot_model()
2023-04-24 18:30:30,162:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 18:30:30,162:INFO:Checking exceptions
2023-04-24 18:30:30,168:INFO:Preloading libraries
2023-04-24 18:30:30,222:INFO:Copying training dataset
2023-04-24 18:30:30,222:INFO:Plot type: auc
2023-04-24 18:30:30,531:INFO:Fitting Model
2023-04-24 18:30:30,533:INFO:Scoring test/hold-out set
2023-04-24 18:30:30,797:INFO:Saving 'AUC.png'
2023-04-24 18:30:30,902:INFO:Visual Rendered Successfully
2023-04-24 18:30:30,992:INFO:plot_model() successfully completed......................................
2023-04-24 18:30:30,992:INFO:Initializing plot_model()
2023-04-24 18:30:30,993:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=True, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd735965d00>, system=True)
2023-04-24 18:30:30,993:INFO:Checking exceptions
2023-04-24 18:30:30,998:INFO:Preloading libraries
2023-04-24 18:30:31,042:INFO:Copying training dataset
2023-04-24 18:30:31,042:INFO:Plot type: confusion_matrix
2023-04-24 18:30:31,340:INFO:Fitting Model
2023-04-24 18:30:31,341:INFO:Scoring test/hold-out set
2023-04-24 18:30:31,590:INFO:Saving 'Confusion Matrix.png'
2023-04-24 18:30:31,643:INFO:Visual Rendered Successfully
2023-04-24 18:30:31,737:INFO:plot_model() successfully completed......................................
2023-04-24 18:30:31,747:INFO:Initializing save_model()
2023-04-24 18:30:31,747:INFO:save_model(model=LGBMClassifier(bagging_fraction=1.0, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.01, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=190, n_jobs=-1, num_leaves=256, objective=None,
               random_state=8216, reg_alpha=0.0005, reg_lambda=0.01,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), model_name=/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/lightgbm/Model_Results/Model_Objects/lightgbm, prep_pipe_=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                                                               n_jobs=1,
                                                               random_state=8216,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=MinMaxScaler(clip=False,
                                                             copy=True,
                                                             feature_range=(0,
                                                                            1))))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-04-24 18:30:31,747:INFO:Adding model into prep_pipe
2023-04-24 18:30:31,827:INFO:/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/lightgbm/Model_Results/Model_Objects/lightgbm.pkl saved in current working directory
2023-04-24 18:30:31,836:INFO:Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utili...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.01,
                                max_depth=-1, min_child_samples=21,
                                min_child_weight=0.001, min_split_gain=0.3,
                                n_estimators=190, n_jobs=-1, num_leaves=256,
                                objective=None, random_state=8216,
                                reg_alpha=0.0005, reg_lambda=0.01,
                                silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-04-24 18:30:31,836:INFO:save_model() successfully completed......................................
2023-04-24 18:32:20,348:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 18:32:20,348:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 18:32:20,348:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 18:32:20,348:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-24 18:32:20,828:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-24 18:32:56,926:INFO:Initializing load_model()
2023-04-24 18:32:56,927:INFO:load_model(model_name=/Users/raj2.gaurav/Desktop/supervised_classification/07. Model/rf/Model_Results/Model_Objects/rf, platform=None, authentication=None, verbose=True)
2023-04-24 18:33:03,794:INFO:Initializing predict_model()
2023-04-24 18:33:03,795:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fdcb3d89670>, estimator=Pipeline(memory=FastMemory(location=/var/folders/3p/7q9_hy6x4q58xrz02_n9tvv0fryx5_/T/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Annual_Income',
                                             'Monthly_Inhand_Salary',
                                             'Num_Bank_Accounts',
                                             'Num_Credit_Card', 'Interest_Rate',
                                             'Num_of_Loan',
                                             'Num_of_Delayed_Payment',
                                             'Num_Credit_Inquiries',
                                             'Outstanding_Debt',
                                             'Credit_Utilization_Ratio'...
                                                                   handle_missing='return_nan',
                                                                   random_state=8216))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=8216,
                                                               threshold=0.5))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('trained_model',
                 RandomForestClassifier(n_jobs=-1, random_state=8216))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x7fdca5e7da60>)
2023-04-24 18:33:03,795:INFO:Checking exceptions
2023-04-24 18:33:03,795:INFO:Preloading libraries
2023-04-24 18:33:03,795:INFO:Set up data.
2023-04-24 18:33:03,869:INFO:Set up index.
